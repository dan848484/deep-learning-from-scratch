{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# transpose\n",
    "a = np.array([[0, 1], [2, 3]])\n",
    "a.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 2],\n",
       "        [1, 3]],\n",
       "\n",
       "       [[4, 6],\n",
       "        [5, 7]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[0, 1], [2, 3]], [[4, 5], [6, 7]]])\n",
    "a.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 4],\n",
       "        [2, 6]],\n",
       "\n",
       "       [[1, 5],\n",
       "        [3, 7]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0],\n",
       "       [0, 3, 4, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad([[1, 2], [3, 4]], [(0, 0), (1, 1)], mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10000,     2,     3],\n",
       "       [10000,     5,     6]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "array[:, 0] = 10000\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [4, 4],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [4, 4],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [4, 4],\n",
       "       [1, 1],\n",
       "       [2, 2],\n",
       "       [3, 3],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array(\n",
    "    [\n",
    "        [[[1, 2, 3, 4], [1, 2, 3, 4]], [[1, 2, 3, 4], [1, 2, 3, 4]]],\n",
    "        [[[1, 2, 3, 4], [1, 2, 3, 4]], [[1, 2, 3, 4], [1, 2, 3, 4]]],\n",
    "    ],\n",
    ")\n",
    "\n",
    "array.reshape(2, -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.util import col2im, im2col\n",
    "\n",
    "\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "        # 中間データ（backward時に使用）\n",
    "        self.x = None\n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "\n",
    "        # 重み・バイアスパラメータの勾配\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2 * self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2 * self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0, 2, 3, 1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "\n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "\n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,))\n",
    "\n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2994083518085473\n",
      "=== epoch:1, train acc:0.267, test acc:0.328 ===\n",
      "train loss:2.295147521171212\n",
      "train loss:2.292202156999552\n",
      "train loss:2.285110752027592\n",
      "train loss:2.2731138400256237\n",
      "train loss:2.265909348062124\n",
      "train loss:2.24680021052272\n",
      "train loss:2.240895101797497\n",
      "train loss:2.1854319182020783\n",
      "train loss:2.1686192504713624\n",
      "train loss:2.1491077014731994\n",
      "train loss:2.1124391061222907\n",
      "train loss:2.032659414206755\n",
      "train loss:2.0325774384576056\n",
      "train loss:1.91592261241753\n",
      "train loss:1.8582380256932622\n",
      "train loss:1.7801594688070292\n",
      "train loss:1.6771385380136372\n",
      "train loss:1.694398319814699\n",
      "train loss:1.5231872624987495\n",
      "train loss:1.5025233428163918\n",
      "train loss:1.4249942869992611\n",
      "train loss:1.2867288952986835\n",
      "train loss:1.2411186562785226\n",
      "train loss:1.2567596073394998\n",
      "train loss:1.2180474800503416\n",
      "train loss:1.0259517230425539\n",
      "train loss:0.8462640238289068\n",
      "train loss:0.9176088144555\n",
      "train loss:0.9087201744252912\n",
      "train loss:0.7513773754737417\n",
      "train loss:0.6964857716963266\n",
      "train loss:0.7787609498996474\n",
      "train loss:0.6716033626318211\n",
      "train loss:0.7235057217783399\n",
      "train loss:0.710514175853696\n",
      "train loss:0.7944221256001281\n",
      "train loss:0.7208324141816103\n",
      "train loss:0.6564173021411999\n",
      "train loss:0.7409751677211234\n",
      "train loss:0.5616013182643248\n",
      "train loss:0.5476679739143693\n",
      "train loss:0.5912761747968586\n",
      "train loss:0.7824600569719233\n",
      "train loss:0.5273883432473386\n",
      "train loss:0.7795369000833254\n",
      "train loss:0.6132553343818739\n",
      "train loss:0.6140423368499074\n",
      "train loss:0.4298516092087484\n",
      "train loss:0.4744697323436364\n",
      "train loss:0.7700428417596303\n",
      "train loss:0.398228958441986\n",
      "train loss:0.5497469932131529\n",
      "train loss:0.5925738044358311\n",
      "train loss:0.6367525420286022\n",
      "train loss:0.6454351999518554\n",
      "train loss:0.46340415213838254\n",
      "train loss:0.49164731751603197\n",
      "train loss:0.4439583299700442\n",
      "train loss:0.7008659296689826\n",
      "train loss:0.6010292590817623\n",
      "train loss:0.4432370517685697\n",
      "train loss:0.6452128194686919\n",
      "train loss:0.42353512509064367\n",
      "train loss:0.5212629682248229\n",
      "train loss:0.42434123023077225\n",
      "train loss:0.5410073219736676\n",
      "train loss:0.5165702370122466\n",
      "train loss:0.503268338811986\n",
      "train loss:0.46980859636494543\n",
      "train loss:0.4072413483544601\n",
      "train loss:0.48843750800129887\n",
      "train loss:0.43993221937515853\n",
      "train loss:0.6815823023422121\n",
      "train loss:0.4048417445698146\n",
      "train loss:0.3556485888834001\n",
      "train loss:0.5366471199513414\n",
      "train loss:0.42879557956483194\n",
      "train loss:0.5950514686812087\n",
      "train loss:0.4633397712242189\n",
      "train loss:0.31405241813253093\n",
      "train loss:0.42622401137599153\n",
      "train loss:0.2546709188062125\n",
      "train loss:0.3542103709945583\n",
      "train loss:0.45121989691016573\n",
      "train loss:0.40406693211927996\n",
      "train loss:0.3653883937214318\n",
      "train loss:0.3982861314579846\n",
      "train loss:0.3630890120455239\n",
      "train loss:0.4597163611724293\n",
      "train loss:0.4095390385160801\n",
      "train loss:0.46609580019812435\n",
      "train loss:0.43174682606839426\n",
      "train loss:0.4261059303789302\n",
      "train loss:0.188583060483501\n",
      "train loss:0.3441577172659877\n",
      "train loss:0.2308495042789075\n",
      "train loss:0.4440021970252036\n",
      "train loss:0.43530818370627467\n",
      "train loss:0.29745100306083183\n",
      "train loss:0.4640147975707382\n",
      "train loss:0.37805575710331063\n",
      "train loss:0.37568342527073484\n",
      "train loss:0.41051311413223035\n",
      "train loss:0.48292692456216346\n",
      "train loss:0.2612562940057998\n",
      "train loss:0.31599975739926495\n",
      "train loss:0.4143289084140522\n",
      "train loss:0.21514637650028864\n",
      "train loss:0.3982793706796628\n",
      "train loss:0.3742575966545024\n",
      "train loss:0.2966144351531606\n",
      "train loss:0.41596145963416276\n",
      "train loss:0.3095536967159787\n",
      "train loss:0.3815334915958332\n",
      "train loss:0.33484307348128284\n",
      "train loss:0.22344289732068362\n",
      "train loss:0.4238626779262817\n",
      "train loss:0.4171907761106787\n",
      "train loss:0.4830449674915849\n",
      "train loss:0.3643360937324603\n",
      "train loss:0.4838728416354536\n",
      "train loss:0.2919510110435289\n",
      "train loss:0.2221254393305176\n",
      "train loss:0.3204070570576814\n",
      "train loss:0.40572897676921654\n",
      "train loss:0.43337304550324984\n",
      "train loss:0.4693591381745214\n",
      "train loss:0.22420358364249232\n",
      "train loss:0.23938562979088412\n",
      "train loss:0.2833795820689589\n",
      "train loss:0.5308994472121756\n",
      "train loss:0.3213644578868007\n",
      "train loss:0.3524686573347058\n",
      "train loss:0.26934194322390886\n",
      "train loss:0.4160203659544095\n",
      "train loss:0.28889010206604676\n",
      "train loss:0.3632613427137226\n",
      "train loss:0.24162319930385384\n",
      "train loss:0.42228292466695877\n",
      "train loss:0.36164924934299875\n",
      "train loss:0.33709496725726995\n",
      "train loss:0.35930633912867405\n",
      "train loss:0.5390382967158348\n",
      "train loss:0.460991397095775\n",
      "train loss:0.3222621306325582\n",
      "train loss:0.21765437309001665\n",
      "train loss:0.2538606215196673\n",
      "train loss:0.5353532893129318\n",
      "train loss:0.2801804105454531\n",
      "train loss:0.36691810728999874\n",
      "train loss:0.32441397390532445\n",
      "train loss:0.45862536755968525\n",
      "train loss:0.28763795566087497\n",
      "train loss:0.30049214796601387\n",
      "train loss:0.31964438378159393\n",
      "train loss:0.32661593719899434\n",
      "train loss:0.27895110235391407\n",
      "train loss:0.2212902842301271\n",
      "train loss:0.41915766399094373\n",
      "train loss:0.37584727564943987\n",
      "train loss:0.667739016393092\n",
      "train loss:0.2983159423126619\n",
      "train loss:0.34575357395150697\n",
      "train loss:0.27024328089554395\n",
      "train loss:0.4382131412556209\n",
      "train loss:0.2552411669751827\n",
      "train loss:0.2311717920824313\n",
      "train loss:0.3464769104221391\n",
      "train loss:0.37743814902099154\n",
      "train loss:0.35314943698084567\n",
      "train loss:0.3922070513179247\n",
      "train loss:0.26977210867918067\n",
      "train loss:0.25003925186173565\n",
      "train loss:0.32606721821653795\n",
      "train loss:0.31786129039571076\n",
      "train loss:0.41296489662391617\n",
      "train loss:0.2959160407393896\n",
      "train loss:0.2891315491010911\n",
      "train loss:0.3529186675081509\n",
      "train loss:0.2661460673552637\n",
      "train loss:0.3746392025502999\n",
      "train loss:0.15134658781370375\n",
      "train loss:0.29603717570068183\n",
      "train loss:0.3008118583975806\n",
      "train loss:0.24478743074506426\n",
      "train loss:0.26710356346410735\n",
      "train loss:0.2933582593815049\n",
      "train loss:0.3123203568892208\n",
      "train loss:0.3607691395879247\n",
      "train loss:0.23822672733133504\n",
      "train loss:0.42536994821465773\n",
      "train loss:0.42379634833699564\n",
      "train loss:0.1327474952075117\n",
      "train loss:0.2574535150410522\n",
      "train loss:0.3609062695918741\n",
      "train loss:0.15978932368773718\n",
      "train loss:0.21724380644716537\n",
      "train loss:0.3796356237220604\n",
      "train loss:0.2778654857739382\n",
      "train loss:0.3461253227983447\n",
      "train loss:0.30177959029105833\n",
      "train loss:0.3483209474643924\n",
      "train loss:0.26142428830462383\n",
      "train loss:0.1801195547970902\n",
      "train loss:0.17784607839850547\n",
      "train loss:0.3002007126329906\n",
      "train loss:0.3321956917356236\n",
      "train loss:0.24898118625378562\n",
      "train loss:0.32935709326849893\n",
      "train loss:0.44381484036859625\n",
      "train loss:0.33178763984779563\n",
      "train loss:0.2878435337771899\n",
      "train loss:0.304051703588081\n",
      "train loss:0.3989355854753082\n",
      "train loss:0.207339753657726\n",
      "train loss:0.299803578688725\n",
      "train loss:0.49209547764139616\n",
      "train loss:0.2616556203243884\n",
      "train loss:0.28186181597503224\n",
      "train loss:0.416551710094456\n",
      "train loss:0.38234432699686016\n",
      "train loss:0.28718137366053126\n",
      "train loss:0.2195067630729073\n",
      "train loss:0.45956401802985297\n",
      "train loss:0.45585270811554535\n",
      "train loss:0.32484314249862073\n",
      "train loss:0.24576722564171594\n",
      "train loss:0.25854534319233474\n",
      "train loss:0.28064605723648733\n",
      "train loss:0.2860457108842218\n",
      "train loss:0.30277202843650985\n",
      "train loss:0.2112510516339512\n",
      "train loss:0.23727592235524778\n",
      "train loss:0.3812051107033016\n",
      "train loss:0.32679485881855314\n",
      "train loss:0.318864095801536\n",
      "train loss:0.2084422091499929\n",
      "train loss:0.18411759609116515\n",
      "train loss:0.23727873574798264\n",
      "train loss:0.18974832207228662\n",
      "train loss:0.21446337591783493\n",
      "train loss:0.2141964039017418\n",
      "train loss:0.30323011520830545\n",
      "train loss:0.43223993721084475\n",
      "train loss:0.3161852688125983\n",
      "train loss:0.2621093863015278\n",
      "train loss:0.16635022190406482\n",
      "train loss:0.24782420924938509\n",
      "train loss:0.21873557690152146\n",
      "train loss:0.26011624086533564\n",
      "train loss:0.30127764257992734\n",
      "train loss:0.195682502176571\n",
      "train loss:0.3485561750185667\n",
      "train loss:0.1866931760633851\n",
      "train loss:0.2328218964299719\n",
      "train loss:0.3183671599089821\n",
      "train loss:0.2780829368514324\n",
      "train loss:0.35532933964551594\n",
      "train loss:0.23099709746753316\n",
      "train loss:0.2624480098119676\n",
      "train loss:0.19312043391854147\n",
      "train loss:0.24452693904024156\n",
      "train loss:0.2324947346123996\n",
      "train loss:0.2830255067941215\n",
      "train loss:0.38975391571233836\n",
      "train loss:0.29726753137698214\n",
      "train loss:0.2534958462493325\n",
      "train loss:0.10377372504339286\n",
      "train loss:0.20770354743558664\n",
      "train loss:0.21963325819698062\n",
      "train loss:0.3355360526959796\n",
      "train loss:0.277009802782284\n",
      "train loss:0.29735228725332336\n",
      "train loss:0.3869640662768301\n",
      "train loss:0.257735446821996\n",
      "train loss:0.21538703608895543\n",
      "train loss:0.32573605467256783\n",
      "train loss:0.4646740516557394\n",
      "train loss:0.228975464487387\n",
      "train loss:0.3104610137208166\n",
      "train loss:0.3774761595637415\n",
      "train loss:0.28697461731008017\n",
      "train loss:0.40146465175548934\n",
      "train loss:0.36641131224497847\n",
      "train loss:0.30892591638868977\n",
      "train loss:0.20946279616738608\n",
      "train loss:0.17522046022166948\n",
      "train loss:0.11943778888830694\n",
      "train loss:0.32227597023853266\n",
      "train loss:0.3773512775585317\n",
      "train loss:0.24632601280515135\n",
      "train loss:0.17123872471701362\n",
      "train loss:0.27126349630429664\n",
      "train loss:0.2985027019871616\n",
      "train loss:0.13833947479455683\n",
      "train loss:0.18303917874674558\n",
      "train loss:0.3070550073720215\n",
      "train loss:0.21456742345461358\n",
      "train loss:0.2287280313297414\n",
      "train loss:0.16943912865501967\n",
      "train loss:0.2295590958812957\n",
      "train loss:0.19725303549345835\n",
      "train loss:0.239492330024714\n",
      "train loss:0.2190961220872634\n",
      "train loss:0.2852733636435854\n",
      "train loss:0.13360088513617357\n",
      "train loss:0.21096498486943374\n",
      "train loss:0.21947353355455668\n",
      "train loss:0.16574835461421267\n",
      "train loss:0.17010678645190644\n",
      "train loss:0.18324144613211227\n",
      "train loss:0.2881388117085519\n",
      "train loss:0.17347221787234537\n",
      "train loss:0.18332929308234583\n",
      "train loss:0.1308912336719992\n",
      "train loss:0.2632067091766875\n",
      "train loss:0.18918312942588622\n",
      "train loss:0.2557054296864006\n",
      "train loss:0.21084085842446285\n",
      "train loss:0.23610045931071622\n",
      "train loss:0.29528421459536697\n",
      "train loss:0.27856988888794926\n",
      "train loss:0.3294469518127755\n",
      "train loss:0.2269208767546905\n",
      "train loss:0.17798342799734332\n",
      "train loss:0.29991413461555405\n",
      "train loss:0.19457032183628023\n",
      "train loss:0.13832470865220955\n",
      "train loss:0.24653401913960554\n",
      "train loss:0.22852305851949253\n",
      "train loss:0.23097852066623234\n",
      "train loss:0.2277938349658843\n",
      "train loss:0.193835676889476\n",
      "train loss:0.19444146435140833\n",
      "train loss:0.2122819954231055\n",
      "train loss:0.20199901818806598\n",
      "train loss:0.2163510202173594\n",
      "train loss:0.14347811184549272\n",
      "train loss:0.36548261290505013\n",
      "train loss:0.24900546122052813\n",
      "train loss:0.2979554853125917\n",
      "train loss:0.22159113705955572\n",
      "train loss:0.13268285486219863\n",
      "train loss:0.1687117844706098\n",
      "train loss:0.1265516262174844\n",
      "train loss:0.3180109925241746\n",
      "train loss:0.4027854285299221\n",
      "train loss:0.11290270205020497\n",
      "train loss:0.21340373018594247\n",
      "train loss:0.11014173900456989\n",
      "train loss:0.21122947779206144\n",
      "train loss:0.1942374296423495\n",
      "train loss:0.16972194491581802\n",
      "train loss:0.21967837763211356\n",
      "train loss:0.19685517238160444\n",
      "train loss:0.29512712468684527\n",
      "train loss:0.2015945246168431\n",
      "train loss:0.2815384177033295\n",
      "train loss:0.30499313726886546\n",
      "train loss:0.20328063482523742\n",
      "train loss:0.16846964053412633\n",
      "train loss:0.20535422635812034\n",
      "train loss:0.1562547773199676\n",
      "train loss:0.17793704684830264\n",
      "train loss:0.15840356895568372\n",
      "train loss:0.3436714183346157\n",
      "train loss:0.3492096953129167\n",
      "train loss:0.10773987125273063\n",
      "train loss:0.26776552815558463\n",
      "train loss:0.23931252828557864\n",
      "train loss:0.35835019393227635\n",
      "train loss:0.1299418163544322\n",
      "train loss:0.17255754699925888\n",
      "train loss:0.16720893899620404\n",
      "train loss:0.2530617693467914\n",
      "train loss:0.2389118504171149\n",
      "train loss:0.2499936383436511\n",
      "train loss:0.2924788920438259\n",
      "train loss:0.27804473745351094\n",
      "train loss:0.2049863162779588\n",
      "train loss:0.13306468540408167\n",
      "train loss:0.3103316970000172\n",
      "train loss:0.27552823704767415\n",
      "train loss:0.20978656108530638\n",
      "train loss:0.2541693863654621\n",
      "train loss:0.184270029008074\n",
      "train loss:0.2500072803056656\n",
      "train loss:0.22822360732629665\n",
      "train loss:0.24296520698388777\n",
      "train loss:0.19070430129730526\n",
      "train loss:0.1926385670530694\n",
      "train loss:0.14453088130153705\n",
      "train loss:0.23426138852869677\n",
      "train loss:0.3440124448339575\n",
      "train loss:0.19402747517637542\n",
      "train loss:0.27975090528032615\n",
      "train loss:0.30453053266254154\n",
      "train loss:0.07448521295134958\n",
      "train loss:0.2443973406310695\n",
      "train loss:0.30512015116826\n",
      "train loss:0.3475931433142613\n",
      "train loss:0.13516698428723736\n",
      "train loss:0.33870431057453254\n",
      "train loss:0.3353304804404139\n",
      "train loss:0.09517043675895075\n",
      "train loss:0.24209742894813213\n",
      "train loss:0.2376634259343011\n",
      "train loss:0.14721509945916866\n",
      "train loss:0.1702628582125735\n",
      "train loss:0.2614654562009558\n",
      "train loss:0.19891397149051046\n",
      "train loss:0.253510142341525\n",
      "train loss:0.1711355870085055\n",
      "train loss:0.16454721071471273\n",
      "train loss:0.27148483026192377\n",
      "train loss:0.1385310310533272\n",
      "train loss:0.11859025721540471\n",
      "train loss:0.18463639233266213\n",
      "train loss:0.23871288694310863\n",
      "train loss:0.19692177971239264\n",
      "train loss:0.12376363961185247\n",
      "train loss:0.1310721731519471\n",
      "train loss:0.24435967073360756\n",
      "train loss:0.18026484269333742\n",
      "train loss:0.24338349100411516\n",
      "train loss:0.2781101636769964\n",
      "train loss:0.15730993507929097\n",
      "train loss:0.15852924010893107\n",
      "train loss:0.12608367433780607\n",
      "train loss:0.19854056468120582\n",
      "train loss:0.23387174442873396\n",
      "train loss:0.15971846210411095\n",
      "train loss:0.20596753122517863\n",
      "train loss:0.12700544024628665\n",
      "train loss:0.3146524338590807\n",
      "train loss:0.16086616602433496\n",
      "train loss:0.32601856880726465\n",
      "train loss:0.242055958075631\n",
      "train loss:0.3057059328709175\n",
      "train loss:0.08877515961167357\n",
      "train loss:0.15520798945071843\n",
      "train loss:0.2227481949962716\n",
      "train loss:0.17206176340486087\n",
      "train loss:0.24816721138262943\n",
      "train loss:0.08892478863575634\n",
      "train loss:0.09584787923769729\n",
      "train loss:0.3679479958758423\n",
      "train loss:0.24896349305238702\n",
      "train loss:0.21877199039715273\n",
      "train loss:0.21034674600440276\n",
      "train loss:0.10961195473579774\n",
      "train loss:0.14658429050997548\n",
      "train loss:0.17472795604595234\n",
      "train loss:0.12192579707866788\n",
      "train loss:0.15827125579577792\n",
      "train loss:0.20626854375288303\n",
      "train loss:0.13498052849533507\n",
      "train loss:0.263344911563038\n",
      "train loss:0.1775252308332403\n",
      "train loss:0.19357990967214697\n",
      "train loss:0.209337870415156\n",
      "train loss:0.18360368706110283\n",
      "train loss:0.24153082297346784\n",
      "train loss:0.13610150242853813\n",
      "train loss:0.1677202265542148\n",
      "train loss:0.18438879611069356\n",
      "train loss:0.12300825133535909\n",
      "train loss:0.16337413747301827\n",
      "train loss:0.18522906320956928\n",
      "train loss:0.17382115496706732\n",
      "train loss:0.1304633029111507\n",
      "train loss:0.19543089783838188\n",
      "train loss:0.2426628461251719\n",
      "train loss:0.10823913210314387\n",
      "train loss:0.17624761208574583\n",
      "train loss:0.21390157084404332\n",
      "train loss:0.2188918664780742\n",
      "train loss:0.36335969877162566\n",
      "train loss:0.19417792458302016\n",
      "train loss:0.14499725142476622\n",
      "train loss:0.12025503029702471\n",
      "train loss:0.0782488039857665\n",
      "train loss:0.13998053815023245\n",
      "train loss:0.17395759364477403\n",
      "train loss:0.07387587125305654\n",
      "train loss:0.22816204726588907\n",
      "train loss:0.1970516859768367\n",
      "train loss:0.11732991328073977\n",
      "train loss:0.2129314987568207\n",
      "train loss:0.18087152053129008\n",
      "train loss:0.32881089858753676\n",
      "train loss:0.15966020600037184\n",
      "train loss:0.12389671812619081\n",
      "train loss:0.2066191361088396\n",
      "train loss:0.3178789430578746\n",
      "train loss:0.1958547532001907\n",
      "train loss:0.18537350913311215\n",
      "train loss:0.22547675071484918\n",
      "train loss:0.1543648598302658\n",
      "train loss:0.18075157904924974\n",
      "train loss:0.12681827355881797\n",
      "train loss:0.21825305496663155\n",
      "train loss:0.13063341303406215\n",
      "train loss:0.19177428494396345\n",
      "train loss:0.10130809666496246\n",
      "train loss:0.1873766891030595\n",
      "train loss:0.16781906282528458\n",
      "train loss:0.21011209406446782\n",
      "train loss:0.1532841861333223\n",
      "train loss:0.17853550669012258\n",
      "train loss:0.19778551978537962\n",
      "train loss:0.1939029469533826\n",
      "train loss:0.18784210471582163\n",
      "train loss:0.16368259741653685\n",
      "train loss:0.1484347973532121\n",
      "train loss:0.37314353682456947\n",
      "train loss:0.16782372112771157\n",
      "train loss:0.24202325201481167\n",
      "train loss:0.27001514501104723\n",
      "train loss:0.17953491004779704\n",
      "train loss:0.13535540723675374\n",
      "train loss:0.19237517611626664\n",
      "train loss:0.09163378566900064\n",
      "train loss:0.1241264346288249\n",
      "train loss:0.16976485165141092\n",
      "train loss:0.12009203800695581\n",
      "train loss:0.18613572460841077\n",
      "train loss:0.12228735328538538\n",
      "train loss:0.17479783525282508\n",
      "train loss:0.172440673617057\n",
      "train loss:0.26981976669339874\n",
      "train loss:0.15930282705772153\n",
      "train loss:0.167351433346455\n",
      "train loss:0.20276428803831942\n",
      "train loss:0.1894053774415789\n",
      "train loss:0.13491175591093746\n",
      "train loss:0.26417752837958747\n",
      "train loss:0.17208623534977696\n",
      "train loss:0.16901535904926981\n",
      "train loss:0.18775121287119567\n",
      "train loss:0.11446408827433979\n",
      "train loss:0.22424595726544344\n",
      "train loss:0.2199837247360062\n",
      "train loss:0.18616768804664457\n",
      "train loss:0.22478815493950371\n",
      "train loss:0.2176262536581375\n",
      "train loss:0.12797535917706518\n",
      "train loss:0.19957272063886186\n",
      "train loss:0.12577820938725587\n",
      "train loss:0.12007378864429998\n",
      "train loss:0.08140201174954839\n",
      "train loss:0.31808749084911675\n",
      "train loss:0.061425755522230674\n",
      "train loss:0.11696946684971309\n",
      "train loss:0.24149662352538084\n",
      "train loss:0.17023180476887106\n",
      "train loss:0.13233242334743053\n",
      "train loss:0.1667643986837642\n",
      "train loss:0.20155230970245103\n",
      "train loss:0.1368112938276763\n",
      "train loss:0.19134530644628422\n",
      "train loss:0.14964641825976646\n",
      "train loss:0.15286159773237293\n",
      "train loss:0.10057414024548424\n",
      "train loss:0.10887498532752735\n",
      "train loss:0.1409314306391614\n",
      "train loss:0.12710079119637066\n",
      "train loss:0.1803297481710757\n",
      "train loss:0.17001142266443542\n",
      "train loss:0.15549604255047667\n",
      "train loss:0.11850021843107214\n",
      "train loss:0.12558465189422038\n",
      "train loss:0.13384502395732015\n",
      "train loss:0.19475254625317218\n",
      "train loss:0.17245430711524265\n",
      "train loss:0.1935891094935538\n",
      "train loss:0.20490197577560057\n",
      "train loss:0.11460209621557092\n",
      "train loss:0.1685802465199821\n",
      "train loss:0.1912716208976116\n",
      "train loss:0.18940083920611464\n",
      "train loss:0.2447719406228089\n",
      "train loss:0.15687989272279756\n",
      "train loss:0.06350467617057506\n",
      "train loss:0.18492727960805758\n",
      "train loss:0.21649130372413372\n",
      "train loss:0.05866120458525291\n",
      "train loss:0.10381345646512105\n",
      "train loss:0.34296138425972417\n",
      "train loss:0.12769458369056869\n",
      "train loss:0.1316257058389702\n",
      "train loss:0.2870608624845001\n",
      "train loss:0.08915137711499525\n",
      "train loss:0.06770045466945862\n",
      "train loss:0.15498666318921417\n",
      "train loss:0.06843526587715482\n",
      "train loss:0.27336725425336117\n",
      "train loss:0.17348147730672486\n",
      "train loss:0.17953353182004775\n",
      "train loss:0.1744837473069393\n",
      "=== epoch:2, train acc:0.956, test acc:0.95 ===\n",
      "train loss:0.17306756371408902\n",
      "train loss:0.16078867218017703\n",
      "train loss:0.14569526108110492\n",
      "train loss:0.1392630548715101\n",
      "train loss:0.12496368945962176\n",
      "train loss:0.1281792870810521\n",
      "train loss:0.2506585626903142\n",
      "train loss:0.1308526067109826\n",
      "train loss:0.15644573787425228\n",
      "train loss:0.2272341907265788\n",
      "train loss:0.10201925220363439\n",
      "train loss:0.13929115668619396\n",
      "train loss:0.1713649353146964\n",
      "train loss:0.1743847698088078\n",
      "train loss:0.11404445450723409\n",
      "train loss:0.17706401553653248\n",
      "train loss:0.0497879288334005\n",
      "train loss:0.13056311493627878\n",
      "train loss:0.14863763486150097\n",
      "train loss:0.14792971834922533\n",
      "train loss:0.1876760671892252\n",
      "train loss:0.16946238295920138\n",
      "train loss:0.19049799193190292\n",
      "train loss:0.2284097826731843\n",
      "train loss:0.08372016738650849\n",
      "train loss:0.08980432456954736\n",
      "train loss:0.21563992468628349\n",
      "train loss:0.19990816062762642\n",
      "train loss:0.2686827166861416\n",
      "train loss:0.16169256533784357\n",
      "train loss:0.11880633403198476\n",
      "train loss:0.14003406035197968\n",
      "train loss:0.12690604192105387\n",
      "train loss:0.18848439435792586\n",
      "train loss:0.12888758524086666\n",
      "train loss:0.0797852274301956\n",
      "train loss:0.13318958402555423\n",
      "train loss:0.23562906839022324\n",
      "train loss:0.10197278748507622\n",
      "train loss:0.20048804499919878\n",
      "train loss:0.1041510766213352\n",
      "train loss:0.17180157391439008\n",
      "train loss:0.22079756073899856\n",
      "train loss:0.14397552807703495\n",
      "train loss:0.1840478073113902\n",
      "train loss:0.048812677004637726\n",
      "train loss:0.17828345068110796\n",
      "train loss:0.10614585623436033\n",
      "train loss:0.21229570576422963\n",
      "train loss:0.1340326154876021\n",
      "train loss:0.09077096950799074\n",
      "train loss:0.2838792625352433\n",
      "train loss:0.1287347471915038\n",
      "train loss:0.1684532749489195\n",
      "train loss:0.20146754944739861\n",
      "train loss:0.07067371287373748\n",
      "train loss:0.09223856040354696\n",
      "train loss:0.2315635778846053\n",
      "train loss:0.09717906302527522\n",
      "train loss:0.23540561050861922\n",
      "train loss:0.2397009257803417\n",
      "train loss:0.24132374815696786\n",
      "train loss:0.19501444330223908\n",
      "train loss:0.1063425987778967\n",
      "train loss:0.18949277349360305\n",
      "train loss:0.162520101105027\n",
      "train loss:0.15561320550770627\n",
      "train loss:0.13408727801284878\n",
      "train loss:0.1733480498440268\n",
      "train loss:0.13061681880349202\n",
      "train loss:0.17168427320994803\n",
      "train loss:0.1344292139132749\n",
      "train loss:0.16658878589775916\n",
      "train loss:0.1215651445096655\n",
      "train loss:0.15835200126984586\n",
      "train loss:0.09575831878921955\n",
      "train loss:0.17544331277223701\n",
      "train loss:0.06758947084332928\n",
      "train loss:0.10595570141459851\n",
      "train loss:0.10913568425156722\n",
      "train loss:0.09143350850831998\n",
      "train loss:0.18849828199539548\n",
      "train loss:0.15582917226661444\n",
      "train loss:0.12798211600980708\n",
      "train loss:0.1483823981413367\n",
      "train loss:0.08366665821481302\n",
      "train loss:0.047020781102564774\n",
      "train loss:0.1776881426057038\n",
      "train loss:0.14830301269770957\n",
      "train loss:0.10912278346225196\n",
      "train loss:0.058851241471239574\n",
      "train loss:0.15953983623762702\n",
      "train loss:0.08464792611990662\n",
      "train loss:0.05922616590499348\n",
      "train loss:0.15039387251985525\n",
      "train loss:0.18151165891480772\n",
      "train loss:0.05987751993954962\n",
      "train loss:0.07358595919640104\n",
      "train loss:0.17650540348308363\n",
      "train loss:0.10054542175995142\n",
      "train loss:0.24962833961579997\n",
      "train loss:0.10287596974217159\n",
      "train loss:0.07127166927740507\n",
      "train loss:0.15301416092918582\n",
      "train loss:0.12224899215285012\n",
      "train loss:0.08746899041845962\n",
      "train loss:0.09914996650862654\n",
      "train loss:0.1482930510117049\n",
      "train loss:0.13195709353078125\n",
      "train loss:0.20454903192196394\n",
      "train loss:0.24342894816554947\n",
      "train loss:0.19588578975416482\n",
      "train loss:0.15416188708321454\n",
      "train loss:0.0577432289995379\n",
      "train loss:0.13976348566051813\n",
      "train loss:0.10854890934282196\n",
      "train loss:0.160753506265077\n",
      "train loss:0.091552105032157\n",
      "train loss:0.0578846657095134\n",
      "train loss:0.14993536013918882\n",
      "train loss:0.09305966372752465\n",
      "train loss:0.06328688076902497\n",
      "train loss:0.1276517472898645\n",
      "train loss:0.0714911147196021\n",
      "train loss:0.10711138199532416\n",
      "train loss:0.1259955082139654\n",
      "train loss:0.06982072315103954\n",
      "train loss:0.10354369429215998\n",
      "train loss:0.09230850821296123\n",
      "train loss:0.22415520479186443\n",
      "train loss:0.06611753408827377\n",
      "train loss:0.20767768235954423\n",
      "train loss:0.14316580217695904\n",
      "train loss:0.1302710989191355\n",
      "train loss:0.16309884402906827\n",
      "train loss:0.19191063508467884\n",
      "train loss:0.14679798481943213\n",
      "train loss:0.13104338333719956\n",
      "train loss:0.11816817882696302\n",
      "train loss:0.23762054381274628\n",
      "train loss:0.1581368470010957\n",
      "train loss:0.09336143903629301\n",
      "train loss:0.1043863381530753\n",
      "train loss:0.12445614586671079\n",
      "train loss:0.08976835714374952\n",
      "train loss:0.3269459781151586\n",
      "train loss:0.19313850459254298\n",
      "train loss:0.17659907812171216\n",
      "train loss:0.15211439574961755\n",
      "train loss:0.2551025528452548\n",
      "train loss:0.07768193222796452\n",
      "train loss:0.0874890855447997\n",
      "train loss:0.12514423168405997\n",
      "train loss:0.16215115907173153\n",
      "train loss:0.21823323556906285\n",
      "train loss:0.09480333820695652\n",
      "train loss:0.08902768282947542\n",
      "train loss:0.21307241205426805\n",
      "train loss:0.12524134273907775\n",
      "train loss:0.09210132045308594\n",
      "train loss:0.11156155396700297\n",
      "train loss:0.11860938062297277\n",
      "train loss:0.17305173105213328\n",
      "train loss:0.07790133605063528\n",
      "train loss:0.08671570648256616\n",
      "train loss:0.13887796141303557\n",
      "train loss:0.1614190512341311\n",
      "train loss:0.04900260037865532\n",
      "train loss:0.13635240933788526\n",
      "train loss:0.10180526807383812\n",
      "train loss:0.05206120414697212\n",
      "train loss:0.13863465288492788\n",
      "train loss:0.062077992569598756\n",
      "train loss:0.073685313749368\n",
      "train loss:0.16091035771218956\n",
      "train loss:0.1326660518129773\n",
      "train loss:0.10705184712980394\n",
      "train loss:0.13396603875440763\n",
      "train loss:0.06448969119685931\n",
      "train loss:0.06493442335684733\n",
      "train loss:0.1030283798960125\n",
      "train loss:0.08099912891347104\n",
      "train loss:0.1345785406461265\n",
      "train loss:0.09832645601825364\n",
      "train loss:0.1406160960301605\n",
      "train loss:0.20852412827092096\n",
      "train loss:0.2368421780007969\n",
      "train loss:0.06089599337817295\n",
      "train loss:0.17268953122700892\n",
      "train loss:0.1617102800657684\n",
      "train loss:0.15121880555539616\n",
      "train loss:0.05546675833854836\n",
      "train loss:0.06353066844591877\n",
      "train loss:0.048928430478499776\n",
      "train loss:0.12097084680699269\n",
      "train loss:0.10571555767910025\n",
      "train loss:0.08194358227159602\n",
      "train loss:0.1313563862229999\n",
      "train loss:0.14470726474188922\n",
      "train loss:0.14134706022346732\n",
      "train loss:0.11543768972532019\n",
      "train loss:0.10004491940030681\n",
      "train loss:0.07612658507012356\n",
      "train loss:0.10070603497291224\n",
      "train loss:0.10489989843948308\n",
      "train loss:0.09816623920935033\n",
      "train loss:0.09469529734712148\n",
      "train loss:0.05551744995265565\n",
      "train loss:0.08590456419957748\n",
      "train loss:0.061436782342055365\n",
      "train loss:0.09432018218216108\n",
      "train loss:0.11301412151751868\n",
      "train loss:0.040867671470969105\n",
      "train loss:0.2867841755685313\n",
      "train loss:0.07924733443383263\n",
      "train loss:0.07773622825983412\n",
      "train loss:0.04427129700431315\n",
      "train loss:0.03855499924576841\n",
      "train loss:0.11698205148171294\n",
      "train loss:0.11517977029271392\n",
      "train loss:0.13751427400680435\n",
      "train loss:0.04972767680620617\n",
      "train loss:0.09863111183635259\n",
      "train loss:0.10444871594633472\n",
      "train loss:0.07525130054670975\n",
      "train loss:0.08411457416741396\n",
      "train loss:0.042671123923754516\n",
      "train loss:0.06852066724276379\n",
      "train loss:0.12486745415517725\n",
      "train loss:0.09107906929478193\n",
      "train loss:0.13011637522993935\n",
      "train loss:0.06775283049459271\n",
      "train loss:0.04962383184752865\n",
      "train loss:0.08820561485327681\n",
      "train loss:0.19188698821567363\n",
      "train loss:0.08451606426131943\n",
      "train loss:0.1110128171995631\n",
      "train loss:0.05135383726449045\n",
      "train loss:0.17975053456202134\n",
      "train loss:0.11536550198112233\n",
      "train loss:0.08812538167039595\n",
      "train loss:0.1385505954515228\n",
      "train loss:0.1348121726377495\n",
      "train loss:0.053882212814935763\n",
      "train loss:0.11598092898597777\n",
      "train loss:0.14478434770074677\n",
      "train loss:0.047299462386656436\n",
      "train loss:0.1888766655461016\n",
      "train loss:0.10796765390626067\n",
      "train loss:0.17425712046365452\n",
      "train loss:0.13502953720093902\n",
      "train loss:0.04059731532486914\n",
      "train loss:0.08909771054675264\n",
      "train loss:0.09545043163071702\n",
      "train loss:0.04265037351313833\n",
      "train loss:0.12271178554360467\n",
      "train loss:0.057068938117619795\n",
      "train loss:0.07700030669568013\n",
      "train loss:0.20203853099437805\n",
      "train loss:0.15052182467974703\n",
      "train loss:0.08793390044992937\n",
      "train loss:0.08572934243780683\n",
      "train loss:0.06696752262473815\n",
      "train loss:0.17158025171937047\n",
      "train loss:0.07414335137165949\n",
      "train loss:0.13582566000651558\n",
      "train loss:0.1098221929735216\n",
      "train loss:0.07803381194713219\n",
      "train loss:0.10884729259287809\n",
      "train loss:0.0880699124714008\n",
      "train loss:0.09726265656604896\n",
      "train loss:0.14413740524819008\n",
      "train loss:0.1114792048454385\n",
      "train loss:0.08925321675444313\n",
      "train loss:0.0861330454455123\n",
      "train loss:0.18146891862156203\n",
      "train loss:0.04791330835406805\n",
      "train loss:0.06058331600157165\n",
      "train loss:0.13259625472860082\n",
      "train loss:0.0524048530483502\n",
      "train loss:0.06964201222141458\n",
      "train loss:0.1889944264422844\n",
      "train loss:0.04680462074697313\n",
      "train loss:0.08771850851548767\n",
      "train loss:0.1716033410226254\n",
      "train loss:0.14306280217845402\n",
      "train loss:0.07221707694832055\n",
      "train loss:0.07875682752628578\n",
      "train loss:0.1406751325943056\n",
      "train loss:0.21858323937665797\n",
      "train loss:0.27357945776171627\n",
      "train loss:0.2066270380254895\n",
      "train loss:0.12994654069412362\n",
      "train loss:0.1381291213851306\n",
      "train loss:0.06220759924176855\n",
      "train loss:0.18964091947700612\n",
      "train loss:0.08808001996552323\n",
      "train loss:0.09673307377644269\n",
      "train loss:0.06937377562011926\n",
      "train loss:0.15560692060602407\n",
      "train loss:0.125599308235393\n",
      "train loss:0.10121707669188337\n",
      "train loss:0.10775129857548489\n",
      "train loss:0.10311547126740467\n",
      "train loss:0.15646183510553674\n",
      "train loss:0.06549455366751916\n",
      "train loss:0.058035015710862975\n",
      "train loss:0.10704489353196127\n",
      "train loss:0.12095848628371242\n",
      "train loss:0.11494285741790124\n",
      "train loss:0.14813067529272786\n",
      "train loss:0.14842799233993706\n",
      "train loss:0.08474737536969984\n",
      "train loss:0.12181905964741965\n",
      "train loss:0.04031920371076815\n",
      "train loss:0.09050869309907282\n",
      "train loss:0.07251581137032419\n",
      "train loss:0.1700648336752586\n",
      "train loss:0.04711354944865976\n",
      "train loss:0.05306771599223626\n",
      "train loss:0.09978265670501704\n",
      "train loss:0.0989861312245926\n",
      "train loss:0.11829537974448702\n",
      "train loss:0.19123781614659863\n",
      "train loss:0.043296541739826104\n",
      "train loss:0.13306954205434007\n",
      "train loss:0.04498276016757469\n",
      "train loss:0.17044991298270756\n",
      "train loss:0.1554815445315712\n",
      "train loss:0.05011967718557162\n",
      "train loss:0.07232305810197145\n",
      "train loss:0.1819399320514961\n",
      "train loss:0.20333570668482853\n",
      "train loss:0.07228245654754419\n",
      "train loss:0.041960788308084\n",
      "train loss:0.09052468529441805\n",
      "train loss:0.07084565770806459\n",
      "train loss:0.0993145813971757\n",
      "train loss:0.24392279051135685\n",
      "train loss:0.06352606844333558\n",
      "train loss:0.06547533734951454\n",
      "train loss:0.06271145150053237\n",
      "train loss:0.12310119370477719\n",
      "train loss:0.13241027115873943\n",
      "train loss:0.05418216438072574\n",
      "train loss:0.09300723690748089\n",
      "train loss:0.08091873363209617\n",
      "train loss:0.07577660865847756\n",
      "train loss:0.15221790610428995\n",
      "train loss:0.06670780372739854\n",
      "train loss:0.1492267329590671\n",
      "train loss:0.20176686397715912\n",
      "train loss:0.11770396505901826\n",
      "train loss:0.05132779733370167\n",
      "train loss:0.08905179720892831\n",
      "train loss:0.0882891568285587\n",
      "train loss:0.0425549175033082\n",
      "train loss:0.05574154464998263\n",
      "train loss:0.04631641464711733\n",
      "train loss:0.0626467463671411\n",
      "train loss:0.1477710286486498\n",
      "train loss:0.11155486758519699\n",
      "train loss:0.1936596373156462\n",
      "train loss:0.3188668610484767\n",
      "train loss:0.09470554647652682\n",
      "train loss:0.10068091518645238\n",
      "train loss:0.0712953458994957\n",
      "train loss:0.04723837340597268\n",
      "train loss:0.1230779215575292\n",
      "train loss:0.12196648800297236\n",
      "train loss:0.0811030455974695\n",
      "train loss:0.09200298666707546\n",
      "train loss:0.10106480965907506\n",
      "train loss:0.08385248490547484\n",
      "train loss:0.0996874731112518\n",
      "train loss:0.07990870975539338\n",
      "train loss:0.09542166662850725\n",
      "train loss:0.048533214640954364\n",
      "train loss:0.03887107552777885\n",
      "train loss:0.1244425756338794\n",
      "train loss:0.14725633576065825\n",
      "train loss:0.13341660154900908\n",
      "train loss:0.03330329350162595\n",
      "train loss:0.14780349139363558\n",
      "train loss:0.09171405480139738\n",
      "train loss:0.14678263170009678\n",
      "train loss:0.1481928039678941\n",
      "train loss:0.09640378226828412\n",
      "train loss:0.042461761578380344\n",
      "train loss:0.06042082652018574\n",
      "train loss:0.06318725737534417\n",
      "train loss:0.06288242705121498\n",
      "train loss:0.061750475729846245\n",
      "train loss:0.024822288945729954\n",
      "train loss:0.14351012406024355\n",
      "train loss:0.12204714112932721\n",
      "train loss:0.1891825667466442\n",
      "train loss:0.1097158576649838\n",
      "train loss:0.05110674216934791\n",
      "train loss:0.0940045529073432\n",
      "train loss:0.0606553198053932\n",
      "train loss:0.0806018667835614\n",
      "train loss:0.1067703125351625\n",
      "train loss:0.06130272197539356\n",
      "train loss:0.08911541058498358\n",
      "train loss:0.08384010015321375\n",
      "train loss:0.14199877885404255\n",
      "train loss:0.11503830219687985\n",
      "train loss:0.055809633764233625\n",
      "train loss:0.08137915894153264\n",
      "train loss:0.09810315749297666\n",
      "train loss:0.05399447212117612\n",
      "train loss:0.07364396846090486\n",
      "train loss:0.106237580686771\n",
      "train loss:0.13977529466042163\n",
      "train loss:0.11111326390766978\n",
      "train loss:0.1341448597453879\n",
      "train loss:0.09614660299595798\n",
      "train loss:0.17968862031684601\n",
      "train loss:0.1699838823387143\n",
      "train loss:0.02010797190726971\n",
      "train loss:0.04285109553036543\n",
      "train loss:0.06237703586355936\n",
      "train loss:0.1065339740227078\n",
      "train loss:0.11956028289263998\n",
      "train loss:0.05717612379550738\n",
      "train loss:0.09379764140126251\n",
      "train loss:0.1691279082671339\n",
      "train loss:0.08577534074161751\n",
      "train loss:0.05610552532299322\n",
      "train loss:0.18794376702164936\n",
      "train loss:0.08978195079096904\n",
      "train loss:0.06002812677037608\n",
      "train loss:0.12567121595160657\n",
      "train loss:0.15392219169087057\n",
      "train loss:0.07345687153868154\n",
      "train loss:0.058539005368283895\n",
      "train loss:0.07282196022253848\n",
      "train loss:0.05903927503486267\n",
      "train loss:0.1605194837303655\n",
      "train loss:0.24178431350504812\n",
      "train loss:0.09477889338729233\n",
      "train loss:0.084218746336139\n",
      "train loss:0.05433171948494711\n",
      "train loss:0.09299798603021805\n",
      "train loss:0.12290649651883427\n",
      "train loss:0.07655708305505532\n",
      "train loss:0.10887118274911987\n",
      "train loss:0.15393657122479543\n",
      "train loss:0.0821607388633384\n",
      "train loss:0.05840262268348665\n",
      "train loss:0.0843290656822245\n",
      "train loss:0.0341444386752321\n",
      "train loss:0.09620090385707096\n",
      "train loss:0.05697967155572252\n",
      "train loss:0.08549331817813767\n",
      "train loss:0.06990216841070256\n",
      "train loss:0.06942837271445294\n",
      "train loss:0.020866944890689007\n",
      "train loss:0.12449075542799745\n",
      "train loss:0.11649949208498812\n",
      "train loss:0.09720632272234653\n",
      "train loss:0.10514091191248782\n",
      "train loss:0.1150679624438461\n",
      "train loss:0.10368354363245702\n",
      "train loss:0.11890222384245948\n",
      "train loss:0.046322299150714105\n",
      "train loss:0.0873341256137619\n",
      "train loss:0.1249080348177123\n",
      "train loss:0.08524478929732554\n",
      "train loss:0.07850462017753909\n",
      "train loss:0.17054450210775027\n",
      "train loss:0.07699550169570471\n",
      "train loss:0.0809334891379502\n",
      "train loss:0.04513532780182748\n",
      "train loss:0.08859626611637143\n",
      "train loss:0.09915369070386972\n",
      "train loss:0.0798017038313663\n",
      "train loss:0.041803745197390725\n",
      "train loss:0.08161769388750484\n",
      "train loss:0.07474670227140039\n",
      "train loss:0.053733225507394275\n",
      "train loss:0.05131653680270364\n",
      "train loss:0.06812230657425028\n",
      "train loss:0.13438378917634183\n",
      "train loss:0.11511671837221658\n",
      "train loss:0.17635307615624032\n",
      "train loss:0.04677547762157545\n",
      "train loss:0.04153975295598176\n",
      "train loss:0.045495113802903046\n",
      "train loss:0.06052684117046596\n",
      "train loss:0.05904510229919065\n",
      "train loss:0.07820221919357748\n",
      "train loss:0.15527477723056304\n",
      "train loss:0.10330305010505215\n",
      "train loss:0.026243302499563415\n",
      "train loss:0.05068832364589958\n",
      "train loss:0.08921340575115981\n",
      "train loss:0.11153334166544969\n",
      "train loss:0.09117099963772947\n",
      "train loss:0.13347047038665188\n",
      "train loss:0.06376861859721161\n",
      "train loss:0.06856580828942418\n",
      "train loss:0.13955410295206028\n",
      "train loss:0.09294620367995274\n",
      "train loss:0.05326651492147565\n",
      "train loss:0.06165689927219196\n",
      "train loss:0.04935976576139921\n",
      "train loss:0.06959380581391059\n",
      "train loss:0.09191744902216943\n",
      "train loss:0.09216377482615426\n",
      "train loss:0.01924194960801363\n",
      "train loss:0.07897930089431741\n",
      "train loss:0.2175650655236911\n",
      "train loss:0.09704575342251452\n",
      "train loss:0.15846915371389544\n",
      "train loss:0.11774159193663644\n",
      "train loss:0.09417942739152936\n",
      "train loss:0.030560891850230018\n",
      "train loss:0.06763195963662602\n",
      "train loss:0.18060988456807095\n",
      "train loss:0.03774037359072839\n",
      "train loss:0.04073747812004005\n",
      "train loss:0.10691174672481503\n",
      "train loss:0.03521577882331324\n",
      "train loss:0.10548665782205538\n",
      "train loss:0.04477792018000978\n",
      "train loss:0.16829822252250068\n",
      "train loss:0.11472875850620078\n",
      "train loss:0.03660980906407622\n",
      "train loss:0.12932445382678698\n",
      "train loss:0.12318423471681321\n",
      "train loss:0.04195815898101816\n",
      "train loss:0.03232029622665846\n",
      "train loss:0.06763775267745656\n",
      "train loss:0.22375469529042497\n",
      "train loss:0.14379831323754\n",
      "train loss:0.13292284507656707\n",
      "train loss:0.08625752950564652\n",
      "train loss:0.12350632039396896\n",
      "train loss:0.025063486806038416\n",
      "train loss:0.0689621971308148\n",
      "train loss:0.03666234993290529\n",
      "train loss:0.13828553410151506\n",
      "train loss:0.08119973494345067\n",
      "train loss:0.07068498694952317\n",
      "train loss:0.09506409975852131\n",
      "train loss:0.10580348711453455\n",
      "train loss:0.1198598649171148\n",
      "train loss:0.0419954774935545\n",
      "train loss:0.1099512787629497\n",
      "train loss:0.13812570710450298\n",
      "train loss:0.10495051030430141\n",
      "train loss:0.05236408568873583\n",
      "train loss:0.10105450926266998\n",
      "train loss:0.07589469137519662\n",
      "train loss:0.085691119994115\n",
      "train loss:0.09810856261061379\n",
      "train loss:0.025713693478913786\n",
      "train loss:0.09285818808398236\n",
      "train loss:0.16584414431190514\n",
      "train loss:0.04095314769490414\n",
      "train loss:0.052933403324426205\n",
      "train loss:0.09731040155822984\n",
      "train loss:0.1132522352355376\n",
      "train loss:0.06595926046978284\n",
      "train loss:0.13243404001411213\n",
      "train loss:0.10609545581756238\n",
      "train loss:0.05384950164154947\n",
      "train loss:0.04279377397167738\n",
      "train loss:0.08263114953561512\n",
      "train loss:0.04769856684670355\n",
      "train loss:0.10388130618622228\n",
      "train loss:0.08231658635001247\n",
      "train loss:0.0566846513631585\n",
      "train loss:0.09362642902128405\n",
      "train loss:0.05056779136123156\n",
      "train loss:0.05321466025815297\n",
      "train loss:0.09174913220421917\n",
      "train loss:0.1142323285798569\n",
      "train loss:0.11877940490977922\n",
      "train loss:0.0759350104758841\n",
      "train loss:0.049521762779484606\n",
      "train loss:0.07585475231929677\n",
      "train loss:0.08762076076847616\n",
      "train loss:0.05276840536332705\n",
      "train loss:0.01891871902660439\n",
      "train loss:0.08887244950449143\n",
      "train loss:0.0489832429110053\n",
      "train loss:0.08689293450539591\n",
      "train loss:0.03751336402829289\n",
      "train loss:0.1430927126948796\n",
      "train loss:0.06383367024764844\n",
      "train loss:0.03650980652286246\n",
      "train loss:0.15963921447635868\n",
      "train loss:0.053016218533288015\n",
      "train loss:0.024652275019610457\n",
      "train loss:0.09152646379493926\n",
      "train loss:0.09493579324637133\n",
      "train loss:0.16211488459858114\n",
      "=== epoch:3, train acc:0.968, test acc:0.97 ===\n",
      "train loss:0.07331835865351438\n",
      "train loss:0.04969066108704207\n",
      "train loss:0.11382676067681376\n",
      "train loss:0.053965910736652994\n",
      "train loss:0.061482741484741\n",
      "train loss:0.08484255496493874\n",
      "train loss:0.0433653676273503\n",
      "train loss:0.06386567559564744\n",
      "train loss:0.03729356171983131\n",
      "train loss:0.11690894956248143\n",
      "train loss:0.08637973350310596\n",
      "train loss:0.06423543904472127\n",
      "train loss:0.14503194889378718\n",
      "train loss:0.04715278499259349\n",
      "train loss:0.033368928416529775\n",
      "train loss:0.11013394943533918\n",
      "train loss:0.03209749284891159\n",
      "train loss:0.11461265094204992\n",
      "train loss:0.04476885902925533\n",
      "train loss:0.07730226023580071\n",
      "train loss:0.09891730120197899\n",
      "train loss:0.05374630327261119\n",
      "train loss:0.04084450738025915\n",
      "train loss:0.029046743546868842\n",
      "train loss:0.06254682888835847\n",
      "train loss:0.04109374944935455\n",
      "train loss:0.053987085443908144\n",
      "train loss:0.03608924438683989\n",
      "train loss:0.16158015776935428\n",
      "train loss:0.10374475834855632\n",
      "train loss:0.03719094937919669\n",
      "train loss:0.018063303516732618\n",
      "train loss:0.045527630027364714\n",
      "train loss:0.05393469046003254\n",
      "train loss:0.09817063919829463\n",
      "train loss:0.1141889513699764\n",
      "train loss:0.0945077120963864\n",
      "train loss:0.04078044015849924\n",
      "train loss:0.044323540626509415\n",
      "train loss:0.0580329389963141\n",
      "train loss:0.08893649586549315\n",
      "train loss:0.04913068895876717\n",
      "train loss:0.036939672233021525\n",
      "train loss:0.08791105590909583\n",
      "train loss:0.07820026509973134\n",
      "train loss:0.026510581910882642\n",
      "train loss:0.045004034388408\n",
      "train loss:0.07511357151995925\n",
      "train loss:0.030289162718721455\n",
      "train loss:0.07993830460211834\n",
      "train loss:0.14491832044539776\n",
      "train loss:0.07507763970385918\n",
      "train loss:0.133628358006069\n",
      "train loss:0.05016330401350916\n",
      "train loss:0.046885597911531275\n",
      "train loss:0.02650155229512331\n",
      "train loss:0.10406717340745901\n",
      "train loss:0.047353802892016426\n",
      "train loss:0.04050304167838312\n",
      "train loss:0.05815087488282084\n",
      "train loss:0.08516943392385752\n",
      "train loss:0.0824085025693008\n",
      "train loss:0.10679889906560906\n",
      "train loss:0.06643054441440767\n",
      "train loss:0.15320171340898953\n",
      "train loss:0.05945467123338454\n",
      "train loss:0.08091993352803006\n",
      "train loss:0.06750741347415161\n",
      "train loss:0.09828404418348122\n",
      "train loss:0.027553906719474795\n",
      "train loss:0.06988570473862872\n",
      "train loss:0.02003290699260074\n",
      "train loss:0.0492713392187016\n",
      "train loss:0.048706223680769926\n",
      "train loss:0.06006742981854694\n",
      "train loss:0.06210264739494337\n",
      "train loss:0.09594591143042801\n",
      "train loss:0.046581142454138434\n",
      "train loss:0.033465595109846966\n",
      "train loss:0.057975246801299285\n",
      "train loss:0.05032971591396543\n",
      "train loss:0.0761038247502779\n",
      "train loss:0.11369296241809777\n",
      "train loss:0.05313733810865781\n",
      "train loss:0.09661408950799995\n",
      "train loss:0.05237331127674385\n",
      "train loss:0.07029180109313833\n",
      "train loss:0.09304198816904802\n",
      "train loss:0.04450499823159798\n",
      "train loss:0.06545679897007158\n",
      "train loss:0.03652840108164193\n",
      "train loss:0.05476633197201753\n",
      "train loss:0.04911743433185552\n",
      "train loss:0.14594715876490272\n",
      "train loss:0.12459017381677773\n",
      "train loss:0.06220436744153351\n",
      "train loss:0.039993949954175705\n",
      "train loss:0.07934078952627993\n",
      "train loss:0.04016963036336378\n",
      "train loss:0.025748635867226484\n",
      "train loss:0.12441341003477019\n",
      "train loss:0.04311974101642282\n",
      "train loss:0.09997558300976463\n",
      "train loss:0.14105712772893017\n",
      "train loss:0.08125460931150263\n",
      "train loss:0.08199188123534845\n",
      "train loss:0.04080742929717568\n",
      "train loss:0.09287569479027116\n",
      "train loss:0.09752869446624025\n",
      "train loss:0.05507666274720822\n",
      "train loss:0.01224165228607085\n",
      "train loss:0.040995410913727326\n",
      "train loss:0.034024564715920844\n",
      "train loss:0.13928234221361444\n",
      "train loss:0.03149952375033124\n",
      "train loss:0.06348174310728771\n",
      "train loss:0.04339608134959059\n",
      "train loss:0.018188692001536617\n",
      "train loss:0.025601005632646966\n",
      "train loss:0.05817903710147564\n",
      "train loss:0.08279029296533029\n",
      "train loss:0.05302625693333525\n",
      "train loss:0.02640314825854533\n",
      "train loss:0.02196959447810639\n",
      "train loss:0.046293053459478296\n",
      "train loss:0.04704824894879292\n",
      "train loss:0.062447153022214597\n",
      "train loss:0.03451931806341774\n",
      "train loss:0.058712856604641026\n",
      "train loss:0.054783225222775817\n",
      "train loss:0.07020421766512781\n",
      "train loss:0.055179920900541954\n",
      "train loss:0.04148623266981828\n",
      "train loss:0.02630361342457415\n",
      "train loss:0.022937184144719003\n",
      "train loss:0.08705941835368107\n",
      "train loss:0.051253535633419854\n",
      "train loss:0.13814785746367989\n",
      "train loss:0.09398125929463318\n",
      "train loss:0.035055088709458934\n",
      "train loss:0.044006897784549005\n",
      "train loss:0.062050218381149144\n",
      "train loss:0.13434678008691012\n",
      "train loss:0.08977651718563201\n",
      "train loss:0.09298589133442622\n",
      "train loss:0.05610367556560202\n",
      "train loss:0.10933420784861331\n",
      "train loss:0.028618503074838736\n",
      "train loss:0.0871649731783147\n",
      "train loss:0.15559121687790256\n",
      "train loss:0.1451062090334476\n",
      "train loss:0.08702314631389774\n",
      "train loss:0.09369979083474149\n",
      "train loss:0.059140134191307425\n",
      "train loss:0.05271655294837485\n",
      "train loss:0.09592613721959956\n",
      "train loss:0.024561785524943255\n",
      "train loss:0.06852579165764518\n",
      "train loss:0.033100668795197664\n",
      "train loss:0.06910396797816193\n",
      "train loss:0.04436373426136582\n",
      "train loss:0.06719390454901478\n",
      "train loss:0.02535278022760158\n",
      "train loss:0.06875920251903382\n",
      "train loss:0.0664857331035161\n",
      "train loss:0.0413371735334251\n",
      "train loss:0.039382205373857546\n",
      "train loss:0.09563673450095404\n",
      "train loss:0.18621398140684842\n",
      "train loss:0.060261521120693724\n",
      "train loss:0.16958993445443604\n",
      "train loss:0.037297726554406656\n",
      "train loss:0.025250986706753138\n",
      "train loss:0.041673303334282645\n",
      "train loss:0.03749355242221\n",
      "train loss:0.07918847638811875\n",
      "train loss:0.04204632056334151\n",
      "train loss:0.0911914115257019\n",
      "train loss:0.045707282475331325\n",
      "train loss:0.045024452577837944\n",
      "train loss:0.060331598233790695\n",
      "train loss:0.12152057644803364\n",
      "train loss:0.05677299888093678\n",
      "train loss:0.05399875636783336\n",
      "train loss:0.06910048841624958\n",
      "train loss:0.10387056512861696\n",
      "train loss:0.05828084429119937\n",
      "train loss:0.054703256632489955\n",
      "train loss:0.08557015212514461\n",
      "train loss:0.06389881111802427\n",
      "train loss:0.14174668338943056\n",
      "train loss:0.029075832978213114\n",
      "train loss:0.07263351123515614\n",
      "train loss:0.06674842044445589\n",
      "train loss:0.0678252578990069\n",
      "train loss:0.06192435963089467\n",
      "train loss:0.07207295128172508\n",
      "train loss:0.05796213220378837\n",
      "train loss:0.07548515025380215\n",
      "train loss:0.08096208609373264\n",
      "train loss:0.0700792504441311\n",
      "train loss:0.04520957778329219\n",
      "train loss:0.1603467769981895\n",
      "train loss:0.12155786328675797\n",
      "train loss:0.09966431738515168\n",
      "train loss:0.053904198443065425\n",
      "train loss:0.07624114914006026\n",
      "train loss:0.1275455580292092\n",
      "train loss:0.047639532386012214\n",
      "train loss:0.043799714631825075\n",
      "train loss:0.07003436377821591\n",
      "train loss:0.08482652455398704\n",
      "train loss:0.08098099957564571\n",
      "train loss:0.03436107449181016\n",
      "train loss:0.06763915938025238\n",
      "train loss:0.0411825477795749\n",
      "train loss:0.04991266640536706\n",
      "train loss:0.03614319490087722\n",
      "train loss:0.09957641221896579\n",
      "train loss:0.04945980633304261\n",
      "train loss:0.0660936272910899\n",
      "train loss:0.042630584566254334\n",
      "train loss:0.031124123200557394\n",
      "train loss:0.015596174050203722\n",
      "train loss:0.13690944334212796\n",
      "train loss:0.020582545401757617\n",
      "train loss:0.07813221115052588\n",
      "train loss:0.07023071342997589\n",
      "train loss:0.05232088980222661\n",
      "train loss:0.1017797083365391\n",
      "train loss:0.04690714275682839\n",
      "train loss:0.032727794097039006\n",
      "train loss:0.024332142589008843\n",
      "train loss:0.042414163349237796\n",
      "train loss:0.04785917612982751\n",
      "train loss:0.10425182309408053\n",
      "train loss:0.04351670408685195\n",
      "train loss:0.10570186471573045\n",
      "train loss:0.08483471810258349\n",
      "train loss:0.05644635263598806\n",
      "train loss:0.07511491357946767\n",
      "train loss:0.06654681088575778\n",
      "train loss:0.03261580222696861\n",
      "train loss:0.01877819249517631\n",
      "train loss:0.023101789678460678\n",
      "train loss:0.04318368550701103\n",
      "train loss:0.1241114064475152\n",
      "train loss:0.05705704707534563\n",
      "train loss:0.06370967491963321\n",
      "train loss:0.08149282807315882\n",
      "train loss:0.06047510171422257\n",
      "train loss:0.0547644675940146\n",
      "train loss:0.04767916728559149\n",
      "train loss:0.11114038646089569\n",
      "train loss:0.1946991858272235\n",
      "train loss:0.020368904510174878\n",
      "train loss:0.020783277708829748\n",
      "train loss:0.15351989154167645\n",
      "train loss:0.021956141964661845\n",
      "train loss:0.10157999774626819\n",
      "train loss:0.10061368339530309\n",
      "train loss:0.07502188691593763\n",
      "train loss:0.05018673265987959\n",
      "train loss:0.040110090171891065\n",
      "train loss:0.07816085319234872\n",
      "train loss:0.08417951563589325\n",
      "train loss:0.042708993472268385\n",
      "train loss:0.14665309065991433\n",
      "train loss:0.12078132843022846\n",
      "train loss:0.047370482847561235\n",
      "train loss:0.02365724873894618\n",
      "train loss:0.04338805766839359\n",
      "train loss:0.09389062068662601\n",
      "train loss:0.04008357297903738\n",
      "train loss:0.06974191735846244\n",
      "train loss:0.06884048284710001\n",
      "train loss:0.09264537411573437\n",
      "train loss:0.02845663796331485\n",
      "train loss:0.041936385488906165\n",
      "train loss:0.057283194565881164\n",
      "train loss:0.0375183865158726\n",
      "train loss:0.046614737632772574\n",
      "train loss:0.10830707922531406\n",
      "train loss:0.03004563927183953\n",
      "train loss:0.05278710157595792\n",
      "train loss:0.02235597826651031\n",
      "train loss:0.063644506823547\n",
      "train loss:0.08072344105160545\n",
      "train loss:0.035691410095955924\n",
      "train loss:0.10054176964426231\n",
      "train loss:0.03115209602307523\n",
      "train loss:0.04791260427290268\n",
      "train loss:0.01635161286558494\n",
      "train loss:0.09444240940032538\n",
      "train loss:0.04204679682608737\n",
      "train loss:0.038033734917490784\n",
      "train loss:0.07214105759686279\n",
      "train loss:0.0172434651361605\n",
      "train loss:0.046111369945846865\n",
      "train loss:0.07225522338334905\n",
      "train loss:0.060082953217113266\n",
      "train loss:0.11392923581692674\n",
      "train loss:0.045508157103126286\n",
      "train loss:0.0777171760388826\n",
      "train loss:0.06835798614398217\n",
      "train loss:0.03158664369702926\n",
      "train loss:0.09315862525622971\n",
      "train loss:0.08633564139801506\n",
      "train loss:0.06251328781002113\n",
      "train loss:0.03995306434167337\n",
      "train loss:0.10378023974085897\n",
      "train loss:0.10921944846826434\n",
      "train loss:0.07528314138324235\n",
      "train loss:0.08713389943018765\n",
      "train loss:0.107695425208204\n",
      "train loss:0.14322733164788823\n",
      "train loss:0.060547534144517155\n",
      "train loss:0.00865954209945148\n",
      "train loss:0.10859838589982296\n",
      "train loss:0.048206983001480914\n",
      "train loss:0.05222110852496303\n",
      "train loss:0.14951952837002147\n",
      "train loss:0.11684913820731774\n",
      "train loss:0.12451538045501417\n",
      "train loss:0.08184152564781431\n",
      "train loss:0.07003259247901326\n",
      "train loss:0.046709343212496535\n",
      "train loss:0.020829207686191613\n",
      "train loss:0.07586207452768791\n",
      "train loss:0.07598944558985432\n",
      "train loss:0.172116692447034\n",
      "train loss:0.01757391079841997\n",
      "train loss:0.011111526922255891\n",
      "train loss:0.07174805033177618\n",
      "train loss:0.10546609617622835\n",
      "train loss:0.0363608913898766\n",
      "train loss:0.057010395767231\n",
      "train loss:0.030814134459758894\n",
      "train loss:0.059894140985722426\n",
      "train loss:0.030459233746978998\n",
      "train loss:0.08268177918618813\n",
      "train loss:0.026903719234235148\n",
      "train loss:0.018132298170922555\n",
      "train loss:0.1232522637425283\n",
      "train loss:0.04177681211357953\n",
      "train loss:0.034552855945333326\n",
      "train loss:0.06799546457928211\n",
      "train loss:0.10185961137493306\n",
      "train loss:0.052769635230248794\n",
      "train loss:0.11831245168780292\n",
      "train loss:0.03723947634896429\n",
      "train loss:0.048973618592077314\n",
      "train loss:0.09769041849036453\n",
      "train loss:0.035045962635602876\n",
      "train loss:0.05000187208823524\n",
      "train loss:0.08866572426346025\n",
      "train loss:0.025488026771680435\n",
      "train loss:0.029023900477854903\n",
      "train loss:0.12145314393901009\n",
      "train loss:0.012682526650054577\n",
      "train loss:0.06579819117163792\n",
      "train loss:0.025875685997487276\n",
      "train loss:0.05867316480711219\n",
      "train loss:0.026793783617653943\n",
      "train loss:0.11316867690709406\n",
      "train loss:0.03662411688727413\n",
      "train loss:0.0464938123152621\n",
      "train loss:0.04544886557392431\n",
      "train loss:0.026503730668456554\n",
      "train loss:0.03478104665392414\n",
      "train loss:0.039799778959840805\n",
      "train loss:0.09342019532402478\n",
      "train loss:0.06415293857069992\n",
      "train loss:0.01620193698176865\n",
      "train loss:0.035913308479228\n",
      "train loss:0.041875701452926066\n",
      "train loss:0.04757251793975913\n",
      "train loss:0.04738846781973134\n",
      "train loss:0.05049232632063674\n",
      "train loss:0.03225567068562689\n",
      "train loss:0.0664819305883228\n",
      "train loss:0.024469150152312692\n",
      "train loss:0.05163147658538811\n",
      "train loss:0.031873788227615885\n",
      "train loss:0.025040498860159913\n",
      "train loss:0.10259063044969857\n",
      "train loss:0.038904750197142776\n",
      "train loss:0.05518137234141287\n",
      "train loss:0.04537653839122054\n",
      "train loss:0.03450160350771489\n",
      "train loss:0.11651837799397378\n",
      "train loss:0.06844349497386641\n",
      "train loss:0.036880687730259654\n",
      "train loss:0.01666271184231034\n",
      "train loss:0.06434453035713153\n",
      "train loss:0.02651085112376339\n",
      "train loss:0.02094416150521935\n",
      "train loss:0.011926135157645186\n",
      "train loss:0.017591484596245092\n",
      "train loss:0.017862220706689275\n",
      "train loss:0.0738430422138007\n",
      "train loss:0.04617178666100599\n",
      "train loss:0.027439389152517726\n",
      "train loss:0.016592641019975554\n",
      "train loss:0.055254247555418766\n",
      "train loss:0.04709761854627443\n",
      "train loss:0.026047938380148378\n",
      "train loss:0.1978907423420355\n",
      "train loss:0.04005598320411264\n",
      "train loss:0.08743487433599777\n",
      "train loss:0.17005470742908813\n",
      "train loss:0.06967335589944758\n",
      "train loss:0.025608711540924443\n",
      "train loss:0.005419931624818543\n",
      "train loss:0.06140674379899711\n",
      "train loss:0.054364157533170164\n",
      "train loss:0.070920916781782\n",
      "train loss:0.07193420785763455\n",
      "train loss:0.09325096995649806\n",
      "train loss:0.01205546714992424\n",
      "train loss:0.03099235189885941\n",
      "train loss:0.021307154606266816\n",
      "train loss:0.041606214918499376\n",
      "train loss:0.06757846971728561\n",
      "train loss:0.05825993183975821\n",
      "train loss:0.0641925877423305\n",
      "train loss:0.11711841399839892\n",
      "train loss:0.09503933261971222\n",
      "train loss:0.03321582751010043\n",
      "train loss:0.042438015002284314\n",
      "train loss:0.01838023780453141\n",
      "train loss:0.04419324934578594\n",
      "train loss:0.05291347125333837\n",
      "train loss:0.04645571228602962\n",
      "train loss:0.02297962057879488\n",
      "train loss:0.028126800541854485\n",
      "train loss:0.0679145027743047\n",
      "train loss:0.052449536867251005\n",
      "train loss:0.02723413296304984\n",
      "train loss:0.034099042755244835\n",
      "train loss:0.07650356565930314\n",
      "train loss:0.09683142271297511\n",
      "train loss:0.11615228305854751\n",
      "train loss:0.042973076160219434\n",
      "train loss:0.12816990522890215\n",
      "train loss:0.06604615360381555\n",
      "train loss:0.03663041507021959\n",
      "train loss:0.012913482198990286\n",
      "train loss:0.10574767740514317\n",
      "train loss:0.02124343360075996\n",
      "train loss:0.0673466032844184\n",
      "train loss:0.05976314549649758\n",
      "train loss:0.03450102243024307\n",
      "train loss:0.035586665225645\n",
      "train loss:0.04404302631365527\n",
      "train loss:0.04620946972463505\n",
      "train loss:0.013147512319877187\n",
      "train loss:0.0385079788302647\n",
      "train loss:0.019347608065709797\n",
      "train loss:0.042747974474946916\n",
      "train loss:0.05411314240701809\n",
      "train loss:0.06019390063075922\n",
      "train loss:0.07591120316186972\n",
      "train loss:0.07184364839260347\n",
      "train loss:0.04194526191419767\n",
      "train loss:0.03860794118208344\n",
      "train loss:0.02761390372062968\n",
      "train loss:0.009711994754984955\n",
      "train loss:0.05328347832309373\n",
      "train loss:0.06963578042145706\n",
      "train loss:0.18432651072257933\n",
      "train loss:0.04174905212410384\n",
      "train loss:0.03023100571379164\n",
      "train loss:0.04353850647523624\n",
      "train loss:0.009289555583509827\n",
      "train loss:0.020575226646304446\n",
      "train loss:0.02915714889665204\n",
      "train loss:0.06593456163245313\n",
      "train loss:0.12063881343241147\n",
      "train loss:0.03875451181709255\n",
      "train loss:0.17494001919698401\n",
      "train loss:0.05367519351271818\n",
      "train loss:0.06625036920101018\n",
      "train loss:0.016010501475810904\n",
      "train loss:0.07021392435412616\n",
      "train loss:0.041932825255355556\n",
      "train loss:0.05160456767755086\n",
      "train loss:0.04534441861150035\n",
      "train loss:0.056027913083807064\n",
      "train loss:0.022578247105565854\n",
      "train loss:0.04724806402980913\n",
      "train loss:0.0323505826858377\n",
      "train loss:0.028244729183938166\n",
      "train loss:0.02926749011986109\n",
      "train loss:0.029956402833678064\n",
      "train loss:0.05925952966582956\n",
      "train loss:0.04111325026847489\n",
      "train loss:0.11082486569224466\n",
      "train loss:0.04953421448130595\n",
      "train loss:0.006299135834341047\n",
      "train loss:0.05297658777873289\n",
      "train loss:0.017546602506360174\n",
      "train loss:0.04023193608255271\n",
      "train loss:0.0855623811798044\n",
      "train loss:0.06887034087947477\n",
      "train loss:0.12344897110154031\n",
      "train loss:0.0066117971038890146\n",
      "train loss:0.04508476409772754\n",
      "train loss:0.041794795661695104\n",
      "train loss:0.08047324264604125\n",
      "train loss:0.13612977700682558\n",
      "train loss:0.1502474544088381\n",
      "train loss:0.11865651333302511\n",
      "train loss:0.038083310402353826\n",
      "train loss:0.0674911713504521\n",
      "train loss:0.04202813932615251\n",
      "train loss:0.028906553656029864\n",
      "train loss:0.06848732188105412\n",
      "train loss:0.04043691047023973\n",
      "train loss:0.03491361845410157\n",
      "train loss:0.0896317708815637\n",
      "train loss:0.05133018327985573\n",
      "train loss:0.09158396670482966\n",
      "train loss:0.0474440979464081\n",
      "train loss:0.06044320539646198\n",
      "train loss:0.06623478202087045\n",
      "train loss:0.027752397276276607\n",
      "train loss:0.045621581148901524\n",
      "train loss:0.04828620433899234\n",
      "train loss:0.03773572567387967\n",
      "train loss:0.12196735327406373\n",
      "train loss:0.06272807367197117\n",
      "train loss:0.030896981197405773\n",
      "train loss:0.027562037700864028\n",
      "train loss:0.04814046067299836\n",
      "train loss:0.10797094479616456\n",
      "train loss:0.12124744370005348\n",
      "train loss:0.05114312918157167\n",
      "train loss:0.05184945625314492\n",
      "train loss:0.07824031803476805\n",
      "train loss:0.017489498596437433\n",
      "train loss:0.027222102374403864\n",
      "train loss:0.02758894102582292\n",
      "train loss:0.13741563477995672\n",
      "train loss:0.0602428580333289\n",
      "train loss:0.02336470332994992\n",
      "train loss:0.023231258999042863\n",
      "train loss:0.05816840300556031\n",
      "train loss:0.05235677674977137\n",
      "train loss:0.044431507231060124\n",
      "train loss:0.07332385499241406\n",
      "train loss:0.05789612796059701\n",
      "train loss:0.04828200617362314\n",
      "train loss:0.050077405255016236\n",
      "train loss:0.06908537866803165\n",
      "train loss:0.04827669256231776\n",
      "train loss:0.08845002918373805\n",
      "train loss:0.06054257195105719\n",
      "train loss:0.034412158786881995\n",
      "train loss:0.037336582860887334\n",
      "train loss:0.05927808455819921\n",
      "train loss:0.0551950767299387\n",
      "train loss:0.01775131320619468\n",
      "train loss:0.05224210761261285\n",
      "train loss:0.07298402142571489\n",
      "train loss:0.04586189792857848\n",
      "train loss:0.07642338959924394\n",
      "train loss:0.045479959910464295\n",
      "train loss:0.007902841226404585\n",
      "train loss:0.06540970801582845\n",
      "train loss:0.02884644932263149\n",
      "train loss:0.01685755224537476\n",
      "train loss:0.02866233037373176\n",
      "train loss:0.022945765279370887\n",
      "train loss:0.009154138291284182\n",
      "train loss:0.06000963948864348\n",
      "train loss:0.08240299818389539\n",
      "train loss:0.019438015767500406\n",
      "train loss:0.014354555226831052\n",
      "train loss:0.0341492321358502\n",
      "train loss:0.023032003045123584\n",
      "train loss:0.06582061442039773\n",
      "train loss:0.03487022506485113\n",
      "train loss:0.07687071024163666\n",
      "train loss:0.021238082453498026\n",
      "train loss:0.0656567695582679\n",
      "train loss:0.04115210538056864\n",
      "train loss:0.03286024520441679\n",
      "train loss:0.04208230604071904\n",
      "train loss:0.08649451849028743\n",
      "train loss:0.061794006033274014\n",
      "train loss:0.016307517487629083\n",
      "train loss:0.044892582767191505\n",
      "train loss:0.03910345921697014\n",
      "train loss:0.05283322320168651\n",
      "train loss:0.0917945167872707\n",
      "train loss:0.09766399352158603\n",
      "train loss:0.06475759078759676\n",
      "train loss:0.025538715688499244\n",
      "train loss:0.011064435343922376\n",
      "=== epoch:4, train acc:0.978, test acc:0.978 ===\n",
      "train loss:0.022150817631401875\n",
      "train loss:0.1020527389306457\n",
      "train loss:0.06943298594572937\n",
      "train loss:0.05195804218596858\n",
      "train loss:0.026101873079451613\n",
      "train loss:0.16618167234113446\n",
      "train loss:0.08675157434386166\n",
      "train loss:0.016464087079435346\n",
      "train loss:0.09265310576578084\n",
      "train loss:0.014128140543321416\n",
      "train loss:0.01830039589244708\n",
      "train loss:0.08172918652979316\n",
      "train loss:0.022228163929539656\n",
      "train loss:0.04937789625892325\n",
      "train loss:0.09468983726146868\n",
      "train loss:0.02014589333543867\n",
      "train loss:0.017468624154523674\n",
      "train loss:0.052184031633542995\n",
      "train loss:0.0896994544583206\n",
      "train loss:0.023518954214912388\n",
      "train loss:0.03459190170852776\n",
      "train loss:0.012791442298182283\n",
      "train loss:0.0485781917794422\n",
      "train loss:0.02122188023301272\n",
      "train loss:0.013595497992870149\n",
      "train loss:0.02127198464949425\n",
      "train loss:0.022334342732791335\n",
      "train loss:0.020490199362446556\n",
      "train loss:0.015231911566121248\n",
      "train loss:0.030432671994686925\n",
      "train loss:0.01781091001140474\n",
      "train loss:0.03162829852886472\n",
      "train loss:0.005377699880925667\n",
      "train loss:0.042581685937321236\n",
      "train loss:0.0380063471691583\n",
      "train loss:0.052330904793738295\n",
      "train loss:0.06149906250374371\n",
      "train loss:0.05101853769136752\n",
      "train loss:0.05322419938025476\n",
      "train loss:0.057170273695499985\n",
      "train loss:0.03194447376566116\n",
      "train loss:0.05356484505325446\n",
      "train loss:0.02996155156927221\n",
      "train loss:0.04404823181827654\n",
      "train loss:0.02043170503404403\n",
      "train loss:0.051191927244953084\n",
      "train loss:0.08127056500889618\n",
      "train loss:0.02940769524978594\n",
      "train loss:0.01797031310752874\n",
      "train loss:0.08115668513698505\n",
      "train loss:0.05051760008702099\n",
      "train loss:0.059757129459237605\n",
      "train loss:0.06441263628056534\n",
      "train loss:0.030690948526174232\n",
      "train loss:0.09851425803508446\n",
      "train loss:0.05338794246952234\n",
      "train loss:0.09613462572442302\n",
      "train loss:0.024407243494302334\n",
      "train loss:0.08480062638461369\n",
      "train loss:0.08259875623156128\n",
      "train loss:0.027439357474235603\n",
      "train loss:0.02691113034614583\n",
      "train loss:0.0603091866065738\n",
      "train loss:0.03602666927730371\n",
      "train loss:0.010477343915194804\n",
      "train loss:0.06303397042842195\n",
      "train loss:0.0456102144162856\n",
      "train loss:0.04621042311618577\n",
      "train loss:0.03577274395339844\n",
      "train loss:0.020205809160763453\n",
      "train loss:0.06015683130004237\n",
      "train loss:0.04287892865648939\n",
      "train loss:0.017909003139708772\n",
      "train loss:0.021392615439771275\n",
      "train loss:0.028149992713242377\n",
      "train loss:0.02457246002774531\n",
      "train loss:0.03115726994409125\n",
      "train loss:0.03745231423902263\n",
      "train loss:0.027102056446784407\n",
      "train loss:0.04080764169943392\n",
      "train loss:0.09374711386999925\n",
      "train loss:0.046945390622936435\n",
      "train loss:0.037907952824147106\n",
      "train loss:0.04996937258588475\n",
      "train loss:0.017984777960256645\n",
      "train loss:0.04296373561323957\n",
      "train loss:0.047747654467216474\n",
      "train loss:0.05904274103205247\n",
      "train loss:0.10342782017406055\n",
      "train loss:0.12684249590675187\n",
      "train loss:0.04064149629833151\n",
      "train loss:0.04430757707388699\n",
      "train loss:0.055421257036048104\n",
      "train loss:0.01933415238331781\n",
      "train loss:0.039303354763759374\n",
      "train loss:0.07168680757304007\n",
      "train loss:0.016491467101444227\n",
      "train loss:0.03673743044918469\n",
      "train loss:0.051126529500917506\n",
      "train loss:0.04160293978617135\n",
      "train loss:0.016880843422333043\n",
      "train loss:0.0317483953473787\n",
      "train loss:0.029449271771800695\n",
      "train loss:0.0749515842342579\n",
      "train loss:0.11734753980041007\n",
      "train loss:0.07633855947412253\n",
      "train loss:0.02827451699578569\n",
      "train loss:0.04860393049365639\n",
      "train loss:0.09297461369886817\n",
      "train loss:0.04155958954960259\n",
      "train loss:0.021839937980202433\n",
      "train loss:0.03177005482426734\n",
      "train loss:0.03356111151439119\n",
      "train loss:0.08886650836898978\n",
      "train loss:0.029026178798059785\n",
      "train loss:0.055658759477382566\n",
      "train loss:0.061941878109180594\n",
      "train loss:0.026612485787255467\n",
      "train loss:0.028110384075932363\n",
      "train loss:0.05008486885905193\n",
      "train loss:0.010717574380323391\n",
      "train loss:0.04586052140639072\n",
      "train loss:0.11707138000904348\n",
      "train loss:0.06169991053648698\n",
      "train loss:0.08546268593623058\n",
      "train loss:0.038533660008348763\n",
      "train loss:0.05352614184143633\n",
      "train loss:0.031018662395701457\n",
      "train loss:0.04490629646895665\n",
      "train loss:0.03817096360841663\n",
      "train loss:0.014673189001545095\n",
      "train loss:0.03650064350013322\n",
      "train loss:0.029953369161774136\n",
      "train loss:0.1182379932529302\n",
      "train loss:0.1115425502680613\n",
      "train loss:0.039339308328507544\n",
      "train loss:0.07892978067534794\n",
      "train loss:0.04578449798250346\n",
      "train loss:0.08208885576926443\n",
      "train loss:0.08132905081446541\n",
      "train loss:0.018697791228519653\n",
      "train loss:0.06562568401585049\n",
      "train loss:0.04125974564374009\n",
      "train loss:0.049269411001528235\n",
      "train loss:0.03802573383381952\n",
      "train loss:0.04477069562725961\n",
      "train loss:0.019541490165636236\n",
      "train loss:0.03919097877272035\n",
      "train loss:0.02472417312287435\n",
      "train loss:0.042960958537332755\n",
      "train loss:0.014413346393001321\n",
      "train loss:0.09842881614263817\n",
      "train loss:0.06463612852757852\n",
      "train loss:0.05859949065243117\n",
      "train loss:0.047245196264785114\n",
      "train loss:0.04200948930931913\n",
      "train loss:0.02463632002001706\n",
      "train loss:0.021844339433943247\n",
      "train loss:0.03221111396175999\n",
      "train loss:0.06584951207579584\n",
      "train loss:0.021473881085727755\n",
      "train loss:0.09730507765995995\n",
      "train loss:0.10453814556084833\n",
      "train loss:0.01766205968476215\n",
      "train loss:0.01379520223169685\n",
      "train loss:0.08047270787197469\n",
      "train loss:0.016193155044926428\n",
      "train loss:0.059228130820326824\n",
      "train loss:0.017265760874634203\n",
      "train loss:0.024715976439668812\n",
      "train loss:0.05753181634338917\n",
      "train loss:0.02754192923176769\n",
      "train loss:0.07627485254297155\n",
      "train loss:0.0705436106373645\n",
      "train loss:0.0202429169484583\n",
      "train loss:0.05684965524998944\n",
      "train loss:0.030032412893410684\n",
      "train loss:0.03680898702499448\n",
      "train loss:0.046344876866694786\n",
      "train loss:0.01597397613540212\n",
      "train loss:0.059496691479408136\n",
      "train loss:0.021414932827307397\n",
      "train loss:0.04698311931001833\n",
      "train loss:0.1460406952656337\n",
      "train loss:0.04235412327821539\n",
      "train loss:0.06848972911107602\n",
      "train loss:0.012198475709287275\n",
      "train loss:0.07593335484264734\n",
      "train loss:0.0208933718249691\n",
      "train loss:0.02627889560608359\n",
      "train loss:0.049641844572195885\n",
      "train loss:0.09673826646761993\n",
      "train loss:0.02856136432992846\n",
      "train loss:0.03533592161325454\n",
      "train loss:0.11195902729859014\n",
      "train loss:0.03448952494140332\n",
      "train loss:0.023047971558351102\n",
      "train loss:0.02366355601002983\n",
      "train loss:0.051571752861755964\n",
      "train loss:0.06713990910273872\n",
      "train loss:0.030066561529298316\n",
      "train loss:0.041885792896259905\n",
      "train loss:0.07941916387779129\n",
      "train loss:0.021302981846652035\n",
      "train loss:0.030836733560852987\n",
      "train loss:0.04778917957340604\n",
      "train loss:0.02634111940720387\n",
      "train loss:0.012531047089312734\n",
      "train loss:0.04549294264557806\n",
      "train loss:0.029795970163777802\n",
      "train loss:0.04738956372675696\n",
      "train loss:0.057915709427947756\n",
      "train loss:0.0204708263523215\n",
      "train loss:0.0754044055590416\n",
      "train loss:0.04258826704791337\n",
      "train loss:0.027108457484943484\n",
      "train loss:0.04927170335063608\n",
      "train loss:0.02602926908115081\n",
      "train loss:0.05716034501481581\n",
      "train loss:0.009253331605977366\n",
      "train loss:0.01880399100980078\n",
      "train loss:0.12621338828503104\n",
      "train loss:0.03083370692039951\n",
      "train loss:0.05777874543437187\n",
      "train loss:0.06244481656081793\n",
      "train loss:0.06791370828320085\n",
      "train loss:0.0314088795449952\n",
      "train loss:0.03740855353763725\n",
      "train loss:0.03983898877242245\n",
      "train loss:0.02638047112197324\n",
      "train loss:0.07378107260563717\n",
      "train loss:0.029795373532080616\n",
      "train loss:0.05080285387269359\n",
      "train loss:0.0662441419406842\n",
      "train loss:0.1346240626823643\n",
      "train loss:0.013953388465544662\n",
      "train loss:0.022889188661838124\n",
      "train loss:0.08551040720540329\n",
      "train loss:0.03619896880168117\n",
      "train loss:0.05665578690414391\n",
      "train loss:0.07113892067102387\n",
      "train loss:0.049146830812257784\n",
      "train loss:0.036110608433235776\n",
      "train loss:0.028123054202919443\n",
      "train loss:0.016844898070304745\n",
      "train loss:0.01944412466442482\n",
      "train loss:0.13656855108943386\n",
      "train loss:0.03564700446466194\n",
      "train loss:0.0787534019831356\n",
      "train loss:0.05070388442750913\n",
      "train loss:0.03422054085938092\n",
      "train loss:0.02104077887750423\n",
      "train loss:0.024106308545897997\n",
      "train loss:0.01916584836221662\n",
      "train loss:0.06336145417787344\n",
      "train loss:0.016431706065294194\n",
      "train loss:0.01446892359805275\n",
      "train loss:0.05307282630858033\n",
      "train loss:0.02260222735455361\n",
      "train loss:0.027524785580226876\n",
      "train loss:0.019870112647571027\n",
      "train loss:0.0773475940527254\n",
      "train loss:0.02530502228661508\n",
      "train loss:0.0358241823090234\n",
      "train loss:0.06214530270095439\n",
      "train loss:0.040615018712901414\n",
      "train loss:0.05857773687723517\n",
      "train loss:0.02594668353555751\n",
      "train loss:0.05123182790065188\n",
      "train loss:0.020606060541319728\n",
      "train loss:0.04321533071635244\n",
      "train loss:0.027645076288788987\n",
      "train loss:0.029352804671343272\n",
      "train loss:0.06201631299447645\n",
      "train loss:0.0549866335014484\n",
      "train loss:0.032280808434928095\n",
      "train loss:0.023370455354043272\n",
      "train loss:0.01890857297597375\n",
      "train loss:0.037028012227324957\n",
      "train loss:0.0264750485222255\n",
      "train loss:0.12765457573895247\n",
      "train loss:0.05674683780874303\n",
      "train loss:0.008606711715069484\n",
      "train loss:0.03825702432087109\n",
      "train loss:0.03584898352820231\n",
      "train loss:0.03096602130433856\n",
      "train loss:0.09011676919795271\n",
      "train loss:0.036646537642278806\n",
      "train loss:0.02917372313403299\n",
      "train loss:0.05061527366784637\n",
      "train loss:0.029825798573777196\n",
      "train loss:0.06486439295058548\n",
      "train loss:0.006055869757292074\n",
      "train loss:0.0644976916723852\n",
      "train loss:0.06953600695757517\n",
      "train loss:0.03968123927614434\n",
      "train loss:0.049183049310419155\n",
      "train loss:0.03921446317679368\n",
      "train loss:0.021519379783762917\n",
      "train loss:0.06157489879875881\n",
      "train loss:0.03137084072857213\n",
      "train loss:0.024550785352022174\n",
      "train loss:0.04430767570243443\n",
      "train loss:0.15953631809599525\n",
      "train loss:0.02300056442991394\n",
      "train loss:0.02156988976999115\n",
      "train loss:0.014893487772779625\n",
      "train loss:0.10036237406585304\n",
      "train loss:0.030359618300633374\n",
      "train loss:0.018293350367382655\n",
      "train loss:0.10013081034075601\n",
      "train loss:0.0392749839099564\n",
      "train loss:0.08025819039278913\n",
      "train loss:0.03368836817513981\n",
      "train loss:0.03852275462602872\n",
      "train loss:0.03363721636993525\n",
      "train loss:0.016715829472067182\n",
      "train loss:0.035629666016562006\n",
      "train loss:0.027641061265866282\n",
      "train loss:0.016489775099636398\n",
      "train loss:0.10038207002274845\n",
      "train loss:0.032162196582658426\n",
      "train loss:0.01840925115228114\n",
      "train loss:0.023474550506312985\n",
      "train loss:0.042250251414585334\n",
      "train loss:0.03695833118574672\n",
      "train loss:0.036037410158669764\n",
      "train loss:0.03183466295804804\n",
      "train loss:0.03706137460499043\n",
      "train loss:0.02671551626197656\n",
      "train loss:0.01627391867685267\n",
      "train loss:0.04447083004567851\n",
      "train loss:0.048838913386941823\n",
      "train loss:0.08672709290717816\n",
      "train loss:0.07948524121290781\n",
      "train loss:0.026745991921060957\n",
      "train loss:0.015322262730292156\n",
      "train loss:0.05145332780641907\n",
      "train loss:0.02757365356525648\n",
      "train loss:0.01954185402082923\n",
      "train loss:0.014238952560269448\n",
      "train loss:0.018254315095728946\n",
      "train loss:0.08338039164445521\n",
      "train loss:0.01602185221761697\n",
      "train loss:0.09208755940370049\n",
      "train loss:0.011229907806740302\n",
      "train loss:0.029258167881934125\n",
      "train loss:0.060726204158308886\n",
      "train loss:0.11948581324721204\n",
      "train loss:0.058552021048853126\n",
      "train loss:0.012968369931443367\n",
      "train loss:0.013109486847716144\n",
      "train loss:0.10535634580132522\n",
      "train loss:0.03838226899982214\n",
      "train loss:0.0385004272078632\n",
      "train loss:0.05747184005349661\n",
      "train loss:0.04423619864150145\n",
      "train loss:0.039280752869788535\n",
      "train loss:0.02666593487479399\n",
      "train loss:0.01026578188310303\n",
      "train loss:0.025807155221699116\n",
      "train loss:0.024565633916922555\n",
      "train loss:0.03763219703321492\n",
      "train loss:0.017457199362011934\n",
      "train loss:0.027800839633858578\n",
      "train loss:0.13363542645467733\n",
      "train loss:0.06531231533388705\n",
      "train loss:0.18051287459267942\n",
      "train loss:0.07892643131343816\n",
      "train loss:0.025319912160512284\n",
      "train loss:0.04233435898565172\n",
      "train loss:0.04458409588297873\n",
      "train loss:0.016122063545711936\n",
      "train loss:0.08592769204979885\n",
      "train loss:0.04954986434358406\n",
      "train loss:0.010482075492512106\n",
      "train loss:0.015621201360487828\n",
      "train loss:0.03527797730436007\n",
      "train loss:0.05908631276043935\n",
      "train loss:0.1166495804699262\n",
      "train loss:0.0717557957762809\n",
      "train loss:0.09156100313323\n",
      "train loss:0.07602008977749575\n",
      "train loss:0.026544495202449944\n",
      "train loss:0.09373287586378648\n",
      "train loss:0.020577493932478885\n",
      "train loss:0.009842815889743143\n",
      "train loss:0.08431321150491625\n",
      "train loss:0.029524356298019538\n",
      "train loss:0.06500099142366998\n",
      "train loss:0.0070759328116353545\n",
      "train loss:0.02549984097872426\n",
      "train loss:0.04046916157304697\n",
      "train loss:0.02876752661666391\n",
      "train loss:0.014229575977526207\n",
      "train loss:0.03387737953340283\n",
      "train loss:0.011780066374333027\n",
      "train loss:0.07905310103789415\n",
      "train loss:0.02140794808797743\n",
      "train loss:0.018023669493168255\n",
      "train loss:0.03510160900687145\n",
      "train loss:0.09890396730415026\n",
      "train loss:0.06091089811875079\n",
      "train loss:0.09988833275402914\n",
      "train loss:0.020199403287938754\n",
      "train loss:0.042667587399844546\n",
      "train loss:0.045657878281613995\n",
      "train loss:0.04161539368641862\n",
      "train loss:0.019492009277277\n",
      "train loss:0.01933637794582605\n",
      "train loss:0.0906663751685342\n",
      "train loss:0.016584118923036562\n",
      "train loss:0.046513703997653894\n",
      "train loss:0.02700697068213632\n",
      "train loss:0.00990140649965256\n",
      "train loss:0.05915729568128739\n",
      "train loss:0.030238585013944975\n",
      "train loss:0.054313153699947485\n",
      "train loss:0.05067780257711101\n",
      "train loss:0.09610054065348655\n",
      "train loss:0.02738961867751122\n",
      "train loss:0.05516629169358942\n",
      "train loss:0.03719701188430599\n",
      "train loss:0.019537396551656632\n",
      "train loss:0.026522532056105174\n",
      "train loss:0.06511365559328638\n",
      "train loss:0.015341561255014671\n",
      "train loss:0.028224457730488445\n",
      "train loss:0.033296779497706\n",
      "train loss:0.03593347389227956\n",
      "train loss:0.05060881392947951\n",
      "train loss:0.03583345747349658\n",
      "train loss:0.0465241317533492\n",
      "train loss:0.05677139219900366\n",
      "train loss:0.014589883732442245\n",
      "train loss:0.03582513570886607\n",
      "train loss:0.05428046225196322\n",
      "train loss:0.024474294441512542\n",
      "train loss:0.04780047611118591\n",
      "train loss:0.03903140249518013\n",
      "train loss:0.010181066231932356\n",
      "train loss:0.010768777051883435\n",
      "train loss:0.05645267343621323\n",
      "train loss:0.004682206743402691\n",
      "train loss:0.032279112973518743\n",
      "train loss:0.013993152506179236\n",
      "train loss:0.02943435230595497\n",
      "train loss:0.017643802647565335\n",
      "train loss:0.020221449080712377\n",
      "train loss:0.04473821603609813\n",
      "train loss:0.08220325946102236\n",
      "train loss:0.032583261564959304\n",
      "train loss:0.03655725099675508\n",
      "train loss:0.014292131214335842\n",
      "train loss:0.04307183314812421\n",
      "train loss:0.009970491554755566\n",
      "train loss:0.01409455078901847\n",
      "train loss:0.016880168150055712\n",
      "train loss:0.032161693154310854\n",
      "train loss:0.016224500132920084\n",
      "train loss:0.1406432063352191\n",
      "train loss:0.0400804700314461\n",
      "train loss:0.05248536354334666\n",
      "train loss:0.00815393387159718\n",
      "train loss:0.031576013081023466\n",
      "train loss:0.031007558894232522\n",
      "train loss:0.05855624850050639\n",
      "train loss:0.04564180047254151\n",
      "train loss:0.032339024615709436\n",
      "train loss:0.013643276637048231\n",
      "train loss:0.048336424631190124\n",
      "train loss:0.013998702355548544\n",
      "train loss:0.018556760356012954\n",
      "train loss:0.022584917708662576\n",
      "train loss:0.013562689772549777\n",
      "train loss:0.023622506271074126\n",
      "train loss:0.014664170915063937\n",
      "train loss:0.07674908187455867\n",
      "train loss:0.045350007272786305\n",
      "train loss:0.03749893267362342\n",
      "train loss:0.047161251615407046\n",
      "train loss:0.02027411498962299\n",
      "train loss:0.023790860611426778\n",
      "train loss:0.043150558849016855\n",
      "train loss:0.03817597883000781\n",
      "train loss:0.10141596159857315\n",
      "train loss:0.007645328211056368\n",
      "train loss:0.10356012775014735\n",
      "train loss:0.012997112200810255\n",
      "train loss:0.006220143498788354\n",
      "train loss:0.04309122110312913\n",
      "train loss:0.0161469035639808\n",
      "train loss:0.014319989136526646\n",
      "train loss:0.015234912071984933\n",
      "train loss:0.04158504563068041\n",
      "train loss:0.035251252051206515\n",
      "train loss:0.030874652940803507\n",
      "train loss:0.0416991782273522\n",
      "train loss:0.023041103140512543\n",
      "train loss:0.050285242067087274\n",
      "train loss:0.11666449925575054\n",
      "train loss:0.019899739883853854\n",
      "train loss:0.012840762309352898\n",
      "train loss:0.04671051943752134\n",
      "train loss:0.024906353963497576\n",
      "train loss:0.04510523145823117\n",
      "train loss:0.02895900077727558\n",
      "train loss:0.041935430929288954\n",
      "train loss:0.04816668673351446\n",
      "train loss:0.02181240414739086\n",
      "train loss:0.010493613082920112\n",
      "train loss:0.006541097657948203\n",
      "train loss:0.018076415703502387\n",
      "train loss:0.07825821506043323\n",
      "train loss:0.05181012053437288\n",
      "train loss:0.03592662842858628\n",
      "train loss:0.03972506959908102\n",
      "train loss:0.0255905370325654\n",
      "train loss:0.02782020136099918\n",
      "train loss:0.015611012924201433\n",
      "train loss:0.03302044948231424\n",
      "train loss:0.025708510522499995\n",
      "train loss:0.04220636331709256\n",
      "train loss:0.011566828011514535\n",
      "train loss:0.08683197284762587\n",
      "train loss:0.0059293422657478575\n",
      "train loss:0.019971165669477865\n",
      "train loss:0.04176493973321242\n",
      "train loss:0.012167552689836946\n",
      "train loss:0.02165126720598108\n",
      "train loss:0.022459476178485982\n",
      "train loss:0.012034741554166782\n",
      "train loss:0.009430294261788125\n",
      "train loss:0.043107373738861574\n",
      "train loss:0.06194197270274193\n",
      "train loss:0.017632895139713032\n",
      "train loss:0.01967018798382299\n",
      "train loss:0.09571782266113363\n",
      "train loss:0.023103321061032675\n",
      "train loss:0.007730800101448295\n",
      "train loss:0.019577165919255055\n",
      "train loss:0.07268479922770604\n",
      "train loss:0.016551989394001473\n",
      "train loss:0.024741142493861147\n",
      "train loss:0.03073924586261103\n",
      "train loss:0.02597752470823421\n",
      "train loss:0.010756597083532955\n",
      "train loss:0.02911113884349243\n",
      "train loss:0.014278768558468347\n",
      "train loss:0.01773389841560604\n",
      "train loss:0.039929143037431565\n",
      "train loss:0.017259345640217468\n",
      "train loss:0.03240314190546865\n",
      "train loss:0.03251271607858595\n",
      "train loss:0.041161470564395196\n",
      "train loss:0.02502182087258617\n",
      "train loss:0.021737353719426117\n",
      "train loss:0.20254290083795645\n",
      "train loss:0.09632894579789966\n",
      "train loss:0.010166191075125397\n",
      "train loss:0.07410917624030887\n",
      "train loss:0.00649867659788529\n",
      "train loss:0.07687276074010076\n",
      "train loss:0.028077435270520867\n",
      "train loss:0.13547122151813526\n",
      "train loss:0.013450580678760402\n",
      "train loss:0.03686136025518694\n",
      "train loss:0.02213614574514529\n",
      "train loss:0.046577177140336296\n",
      "train loss:0.048831414436913814\n",
      "train loss:0.028866944236112625\n",
      "train loss:0.007402804683039443\n",
      "train loss:0.0223434457823441\n",
      "train loss:0.059667237287104144\n",
      "train loss:0.011665882071638722\n",
      "train loss:0.019599509360014918\n",
      "train loss:0.04074763739062229\n",
      "train loss:0.03102563571270258\n",
      "train loss:0.05470685900584131\n",
      "train loss:0.0162684534796664\n",
      "train loss:0.020880838020513676\n",
      "train loss:0.014435876467446446\n",
      "train loss:0.021878648813789182\n",
      "train loss:0.0851862532475955\n",
      "train loss:0.016967924010826748\n",
      "train loss:0.015596132955867243\n",
      "train loss:0.018208935541315564\n",
      "train loss:0.04732502211388268\n",
      "train loss:0.057439896390089194\n",
      "train loss:0.022888123107399464\n",
      "train loss:0.011826717345601341\n",
      "train loss:0.05106401991573508\n",
      "train loss:0.017058403491730535\n",
      "train loss:0.06420867972741637\n",
      "train loss:0.055809038528676094\n",
      "train loss:0.1062130018932365\n",
      "train loss:0.03954007504925818\n",
      "train loss:0.021518991691403012\n",
      "train loss:0.05093372446892414\n",
      "train loss:0.09318645025148399\n",
      "=== epoch:5, train acc:0.978, test acc:0.972 ===\n",
      "train loss:0.04005162308640414\n",
      "train loss:0.034833843305362044\n",
      "train loss:0.016703684118983132\n",
      "train loss:0.06853891220603658\n",
      "train loss:0.009134730859000288\n",
      "train loss:0.047596029966026195\n",
      "train loss:0.06136093479171087\n",
      "train loss:0.08591102049686195\n",
      "train loss:0.012608643693771824\n",
      "train loss:0.04279168764113066\n",
      "train loss:0.03227787812044947\n",
      "train loss:0.018887558155062528\n",
      "train loss:0.023687429553840133\n",
      "train loss:0.047467792563541666\n",
      "train loss:0.021465837042998027\n",
      "train loss:0.030676969109328146\n",
      "train loss:0.016930203415585467\n",
      "train loss:0.01648052035944025\n",
      "train loss:0.011777736780119437\n",
      "train loss:0.06908657903474286\n",
      "train loss:0.045856730089881996\n",
      "train loss:0.08012454162897932\n",
      "train loss:0.04898100693474475\n",
      "train loss:0.02269706322017929\n",
      "train loss:0.012619825438192846\n",
      "train loss:0.007128785726786047\n",
      "train loss:0.009234335560044795\n",
      "train loss:0.012622137576067142\n",
      "train loss:0.04415629504610341\n",
      "train loss:0.05149687671083216\n",
      "train loss:0.019570945328439546\n",
      "train loss:0.007571062942433631\n",
      "train loss:0.008748771916467701\n",
      "train loss:0.10663773598501196\n",
      "train loss:0.014173238913172435\n",
      "train loss:0.05865851857507333\n",
      "train loss:0.013288080987346892\n",
      "train loss:0.022361331089463393\n",
      "train loss:0.02090970631987797\n",
      "train loss:0.04160069754359297\n",
      "train loss:0.02441515016915387\n",
      "train loss:0.03382782078820198\n",
      "train loss:0.030545146619005644\n",
      "train loss:0.024326259370945565\n",
      "train loss:0.07431624887399182\n",
      "train loss:0.04088289050775572\n",
      "train loss:0.019999206683181787\n",
      "train loss:0.058612286654412385\n",
      "train loss:0.02104778204814951\n",
      "train loss:0.0839948728963501\n",
      "train loss:0.06318898094175027\n",
      "train loss:0.037941593315708365\n",
      "train loss:0.024856352557798847\n",
      "train loss:0.0717410187170066\n",
      "train loss:0.02348150047708975\n",
      "train loss:0.05188197738903003\n",
      "train loss:0.04020610377086203\n",
      "train loss:0.06563445306079943\n",
      "train loss:0.007493747498270671\n",
      "train loss:0.0215827547115361\n",
      "train loss:0.030464608592903692\n",
      "train loss:0.0643050703154692\n",
      "train loss:0.04619206249570529\n",
      "train loss:0.08493992169603766\n",
      "train loss:0.038392086400389824\n",
      "train loss:0.09255672132549271\n",
      "train loss:0.012884230278126437\n",
      "train loss:0.04272183970569334\n",
      "train loss:0.034227930172725574\n",
      "train loss:0.06861195164992143\n",
      "train loss:0.07378503128632613\n",
      "train loss:0.020573765280352877\n",
      "train loss:0.03351930869240134\n",
      "train loss:0.016357908749192428\n",
      "train loss:0.05603207078176756\n",
      "train loss:0.04929348784506607\n",
      "train loss:0.06251313900751984\n",
      "train loss:0.030043723762685624\n",
      "train loss:0.00839582469714176\n",
      "train loss:0.05282087771847042\n",
      "train loss:0.019251135081512223\n",
      "train loss:0.030305703683856624\n",
      "train loss:0.05482687755994492\n",
      "train loss:0.03281537393375363\n",
      "train loss:0.14295768783003135\n",
      "train loss:0.04693689849250426\n",
      "train loss:0.03861751887300779\n",
      "train loss:0.0370569607905633\n",
      "train loss:0.02408117303939136\n",
      "train loss:0.018026210556072494\n",
      "train loss:0.1777811717774026\n",
      "train loss:0.007750484809574006\n",
      "train loss:0.014414463270253421\n",
      "train loss:0.04115104228455146\n",
      "train loss:0.054320412120681186\n",
      "train loss:0.03137284117268227\n",
      "train loss:0.0331126867084643\n",
      "train loss:0.047187008177746306\n",
      "train loss:0.09889807690597785\n",
      "train loss:0.05777055963511644\n",
      "train loss:0.026130995369704202\n",
      "train loss:0.01598170499231364\n",
      "train loss:0.019431292560229227\n",
      "train loss:0.08509092721943155\n",
      "train loss:0.07501399782854494\n",
      "train loss:0.021993406151803282\n",
      "train loss:0.018240388915968082\n",
      "train loss:0.013508959713376909\n",
      "train loss:0.030087498429988934\n",
      "train loss:0.09642079972891861\n",
      "train loss:0.014864848307787688\n",
      "train loss:0.03393141518267101\n",
      "train loss:0.01962199470015477\n",
      "train loss:0.01925319473732657\n",
      "train loss:0.0451471236853435\n",
      "train loss:0.014305282852368935\n",
      "train loss:0.031035967565008354\n",
      "train loss:0.014221907391953998\n",
      "train loss:0.04938286391029086\n",
      "train loss:0.027789111598649927\n",
      "train loss:0.0143820182705918\n",
      "train loss:0.02491307348316946\n",
      "train loss:0.007491582188077087\n",
      "train loss:0.018589778428070084\n",
      "train loss:0.009639397714294826\n",
      "train loss:0.08876155764685924\n",
      "train loss:0.07578017055373074\n",
      "train loss:0.010443784248153492\n",
      "train loss:0.06228858005311601\n",
      "train loss:0.030885540284885063\n",
      "train loss:0.025022963700553458\n",
      "train loss:0.047446929203309854\n",
      "train loss:0.015031843040112933\n",
      "train loss:0.020509134599948308\n",
      "train loss:0.10108225748447924\n",
      "train loss:0.024961198801533094\n",
      "train loss:0.04063533727973652\n",
      "train loss:0.021437323412632138\n",
      "train loss:0.03610040406412946\n",
      "train loss:0.033371329707891605\n",
      "train loss:0.01361538251217416\n",
      "train loss:0.02215801330324504\n",
      "train loss:0.01694834057310363\n",
      "train loss:0.07972058134571296\n",
      "train loss:0.06608099849556975\n",
      "train loss:0.02553710100391312\n",
      "train loss:0.02851326661735118\n",
      "train loss:0.014277651786555991\n",
      "train loss:0.030325066363220556\n",
      "train loss:0.09217718314296251\n",
      "train loss:0.07369465333316697\n",
      "train loss:0.027036581589674955\n",
      "train loss:0.02383296059589327\n",
      "train loss:0.009803827903825559\n",
      "train loss:0.05541838189814494\n",
      "train loss:0.02291961098741958\n",
      "train loss:0.03147407731435106\n",
      "train loss:0.05894942445716438\n",
      "train loss:0.03420526546441765\n",
      "train loss:0.02701331893351548\n",
      "train loss:0.01745271641848583\n",
      "train loss:0.012464945078967383\n",
      "train loss:0.05466887798415582\n",
      "train loss:0.039676510381037006\n",
      "train loss:0.0612036814511681\n",
      "train loss:0.014599372530138188\n",
      "train loss:0.021798823772517448\n",
      "train loss:0.016423847510097\n",
      "train loss:0.010342911505534841\n",
      "train loss:0.021995957204240493\n",
      "train loss:0.10926575224075506\n",
      "train loss:0.003834327243413322\n",
      "train loss:0.04088832589967186\n",
      "train loss:0.03100836966345515\n",
      "train loss:0.019077759248721977\n",
      "train loss:0.027634768169446162\n",
      "train loss:0.043150261161842354\n",
      "train loss:0.015512111321415225\n",
      "train loss:0.01753020132115666\n",
      "train loss:0.008453711583179972\n",
      "train loss:0.015697601235308146\n",
      "train loss:0.035426397096281315\n",
      "train loss:0.029860747544163232\n",
      "train loss:0.05660216187121447\n",
      "train loss:0.030729941958684476\n",
      "train loss:0.0993454151497875\n",
      "train loss:0.03769015867576549\n",
      "train loss:0.07967781502785544\n",
      "train loss:0.027071182013211997\n",
      "train loss:0.04900598937824853\n",
      "train loss:0.03767231178168986\n",
      "train loss:0.045417574204980514\n",
      "train loss:0.11603590004722963\n",
      "train loss:0.04795484775395708\n",
      "train loss:0.030791044119033297\n",
      "train loss:0.020973849131404192\n",
      "train loss:0.058753310826800076\n",
      "train loss:0.023015640866004116\n",
      "train loss:0.012833022767448896\n",
      "train loss:0.019870518194987436\n",
      "train loss:0.016796089916619083\n",
      "train loss:0.01093277995007377\n",
      "train loss:0.03195325937161826\n",
      "train loss:0.026107704295520374\n",
      "train loss:0.028862868474912852\n",
      "train loss:0.022833208144239284\n",
      "train loss:0.040356083188810246\n",
      "train loss:0.027793715859563264\n",
      "train loss:0.1084215455479804\n",
      "train loss:0.02019092929065247\n",
      "train loss:0.03239381641602827\n",
      "train loss:0.010215064725158872\n",
      "train loss:0.02047828636280179\n",
      "train loss:0.013908735446338144\n",
      "train loss:0.05734458450167472\n",
      "train loss:0.04073827572514884\n",
      "train loss:0.01223506188931409\n",
      "train loss:0.011621713859608671\n",
      "train loss:0.011102651728123438\n",
      "train loss:0.034134444530440636\n",
      "train loss:0.04998019509361909\n",
      "train loss:0.013529233246569183\n",
      "train loss:0.012522241363109199\n",
      "train loss:0.040311341595418985\n",
      "train loss:0.052100457762541505\n",
      "train loss:0.02438000862514356\n",
      "train loss:0.012230231838326071\n",
      "train loss:0.02606884815959937\n",
      "train loss:0.020539111093028927\n",
      "train loss:0.06836610102800798\n",
      "train loss:0.07467446740831438\n",
      "train loss:0.029162070624434724\n",
      "train loss:0.04035918578594155\n",
      "train loss:0.0229329698435044\n",
      "train loss:0.02289272062406487\n",
      "train loss:0.015656786698555303\n",
      "train loss:0.027553319285019376\n",
      "train loss:0.036146779980399404\n",
      "train loss:0.02888218363939052\n",
      "train loss:0.05045420262098567\n",
      "train loss:0.01501913689283798\n",
      "train loss:0.035362317668121535\n",
      "train loss:0.0292450803481931\n",
      "train loss:0.014778365712376442\n",
      "train loss:0.014418129954267205\n",
      "train loss:0.023130776058300544\n",
      "train loss:0.031050522911582862\n",
      "train loss:0.032642674767996344\n",
      "train loss:0.0068690012467396\n",
      "train loss:0.024880516087266664\n",
      "train loss:0.02527237159950676\n",
      "train loss:0.014353119651760265\n",
      "train loss:0.018730588014587716\n",
      "train loss:0.034356770010791945\n",
      "train loss:0.003176541662373169\n",
      "train loss:0.0909666869567819\n",
      "train loss:0.021634307642634812\n",
      "train loss:0.006087779580315545\n",
      "train loss:0.06610663845201567\n",
      "train loss:0.0068510910847600645\n",
      "train loss:0.07535046209003335\n",
      "train loss:0.05968402785834273\n",
      "train loss:0.05413887333444323\n",
      "train loss:0.129983190482179\n",
      "train loss:0.02030924174799472\n",
      "train loss:0.035728461460369634\n",
      "train loss:0.014791427814338945\n",
      "train loss:0.014467973606400463\n",
      "train loss:0.005555999646543515\n",
      "train loss:0.03041096396432755\n",
      "train loss:0.028646568255870152\n",
      "train loss:0.026174570773534092\n",
      "train loss:0.005274742786568506\n",
      "train loss:0.051545496230332805\n",
      "train loss:0.032828042343183664\n",
      "train loss:0.03759736505631083\n",
      "train loss:0.029616520295768257\n",
      "train loss:0.030377458384935753\n",
      "train loss:0.024587874477784214\n",
      "train loss:0.02281503640808504\n",
      "train loss:0.004718996375150078\n",
      "train loss:0.02605089669252075\n",
      "train loss:0.0579434807023199\n",
      "train loss:0.013713500895574902\n",
      "train loss:0.03717229550460354\n",
      "train loss:0.03371655330785489\n",
      "train loss:0.04532198219267128\n",
      "train loss:0.011828114063471215\n",
      "train loss:0.01386092530514356\n",
      "train loss:0.025994383730769413\n",
      "train loss:0.0061278889542080075\n",
      "train loss:0.014992313871032732\n",
      "train loss:0.13623964292611557\n",
      "train loss:0.02990515843307738\n",
      "train loss:0.04369975322418956\n",
      "train loss:0.011369482417715196\n",
      "train loss:0.02828220986144484\n",
      "train loss:0.021886933981174816\n",
      "train loss:0.06278183180347094\n",
      "train loss:0.05941797539858754\n",
      "train loss:0.040838971348404154\n",
      "train loss:0.03675501008790526\n",
      "train loss:0.01531368150446029\n",
      "train loss:0.047610909436156944\n",
      "train loss:0.06378787907109962\n",
      "train loss:0.026963353654296952\n",
      "train loss:0.031098857374776922\n",
      "train loss:0.014062808683009747\n",
      "train loss:0.01798634344232332\n",
      "train loss:0.011946222905171644\n",
      "train loss:0.008583925800174851\n",
      "train loss:0.008602539658091064\n",
      "train loss:0.05725991906150227\n",
      "train loss:0.0154717699488993\n",
      "train loss:0.00552400708198478\n",
      "train loss:0.013143334839473697\n",
      "train loss:0.014689033109773143\n",
      "train loss:0.03944668112024745\n",
      "train loss:0.008726433876065445\n",
      "train loss:0.04252118740457766\n",
      "train loss:0.02460021387531486\n",
      "train loss:0.014730798339358357\n",
      "train loss:0.011905722280137058\n",
      "train loss:0.02894969415023368\n",
      "train loss:0.007821672549386986\n",
      "train loss:0.07941507777543953\n",
      "train loss:0.01572115424131475\n",
      "train loss:0.009577005242890142\n",
      "train loss:0.02198054259353524\n",
      "train loss:0.013123695164205631\n",
      "train loss:0.010637935582280439\n",
      "train loss:0.012310949379501501\n",
      "train loss:0.06649253526548173\n",
      "train loss:0.010896439394054365\n",
      "train loss:0.05471236154377856\n",
      "train loss:0.006760956419805821\n",
      "train loss:0.07516446937969289\n",
      "train loss:0.019286698204577922\n",
      "train loss:0.019488106256252885\n",
      "train loss:0.073421069309274\n",
      "train loss:0.007944361779489597\n",
      "train loss:0.02087304753150365\n",
      "train loss:0.04644988529055582\n",
      "train loss:0.014440459993837786\n",
      "train loss:0.00621150466954292\n",
      "train loss:0.017451110234467503\n",
      "train loss:0.022727163231987438\n",
      "train loss:0.08375382431689417\n",
      "train loss:0.050970759769180356\n",
      "train loss:0.048179508704590736\n",
      "train loss:0.0274231242355419\n",
      "train loss:0.025534770109797815\n",
      "train loss:0.010093166172609943\n",
      "train loss:0.07581287332974405\n",
      "train loss:0.03392529742855359\n",
      "train loss:0.00825017063218797\n",
      "train loss:0.05715443420164594\n",
      "train loss:0.012826979631294831\n",
      "train loss:0.05993220681377427\n",
      "train loss:0.04793225935563062\n",
      "train loss:0.02968192707386422\n",
      "train loss:0.004718711319903044\n",
      "train loss:0.038624479358288555\n",
      "train loss:0.04454607458726509\n",
      "train loss:0.057817940331371\n",
      "train loss:0.024348958947850826\n",
      "train loss:0.018965210301486735\n",
      "train loss:0.052376283492300287\n",
      "train loss:0.015231541695654818\n",
      "train loss:0.03364448654492262\n",
      "train loss:0.009147441955418875\n",
      "train loss:0.010181514567150416\n",
      "train loss:0.01501106017813076\n",
      "train loss:0.009449255392126025\n",
      "train loss:0.019030122510153607\n",
      "train loss:0.023808957044636904\n",
      "train loss:0.016968334834714247\n",
      "train loss:0.06271326778116182\n",
      "train loss:0.01524105509455786\n",
      "train loss:0.04390068993299628\n",
      "train loss:0.014042350979429732\n",
      "train loss:0.06294308239109588\n",
      "train loss:0.04342805777924485\n",
      "train loss:0.07872721783813756\n",
      "train loss:0.00573060006476832\n",
      "train loss:0.021677483413657637\n",
      "train loss:0.010839229405940287\n",
      "train loss:0.03457320463289732\n",
      "train loss:0.08201372878519615\n",
      "train loss:0.0321468230367419\n",
      "train loss:0.02206410123041231\n",
      "train loss:0.006724914842653362\n",
      "train loss:0.023851980457524725\n",
      "train loss:0.0795126013843239\n",
      "train loss:0.017446915600029856\n",
      "train loss:0.01476294226808716\n",
      "train loss:0.014160215394350955\n",
      "train loss:0.020736831151317806\n",
      "train loss:0.06260850465116503\n",
      "train loss:0.007356260740135421\n",
      "train loss:0.017159323105684656\n",
      "train loss:0.02164814987675097\n",
      "train loss:0.015433534948896467\n",
      "train loss:0.03125807209433707\n",
      "train loss:0.01135440432158896\n",
      "train loss:0.07386159217946055\n",
      "train loss:0.009475346378997242\n",
      "train loss:0.0925206208912099\n",
      "train loss:0.02043730011517481\n",
      "train loss:0.004101353349495186\n",
      "train loss:0.009032273078480955\n",
      "train loss:0.0056936279773495664\n",
      "train loss:0.005609271552658878\n",
      "train loss:0.014674894104035994\n",
      "train loss:0.02103741240526571\n",
      "train loss:0.020234997778215517\n",
      "train loss:0.02890350680772278\n",
      "train loss:0.017930949363837764\n",
      "train loss:0.04185097901253128\n",
      "train loss:0.01115648537977159\n",
      "train loss:0.005441974486395646\n",
      "train loss:0.007940227891893845\n",
      "train loss:0.02586388692119246\n",
      "train loss:0.005832904216586431\n",
      "train loss:0.019383769925402757\n",
      "train loss:0.01741736056551467\n",
      "train loss:0.04733256950103039\n",
      "train loss:0.02003485921618935\n",
      "train loss:0.007875505886667399\n",
      "train loss:0.0208949683377216\n",
      "train loss:0.01922734654244864\n",
      "train loss:0.04714155264840845\n",
      "train loss:0.05418474234730145\n",
      "train loss:0.01856822273799136\n",
      "train loss:0.024670017679730608\n",
      "train loss:0.019752971072088343\n",
      "train loss:0.02304361791948121\n",
      "train loss:0.041315692688661976\n",
      "train loss:0.004351023043139921\n",
      "train loss:0.006704829831625137\n",
      "train loss:0.06423335321667058\n",
      "train loss:0.01218450718742305\n",
      "train loss:0.004887759207396588\n",
      "train loss:0.010821058998776403\n",
      "train loss:0.017213833873881465\n",
      "train loss:0.07363916982541058\n",
      "train loss:0.027424792366226393\n",
      "train loss:0.01912955919584121\n",
      "train loss:0.035489624171340696\n",
      "train loss:0.025151137238027678\n",
      "train loss:0.020030306806589553\n",
      "train loss:0.01694323960106169\n",
      "train loss:0.08855317339014236\n",
      "train loss:0.02983555049875922\n",
      "train loss:0.05114082169003233\n",
      "train loss:0.03920388866654228\n",
      "train loss:0.009363164397479657\n",
      "train loss:0.014124818594662764\n",
      "train loss:0.05636097325751904\n",
      "train loss:0.03935369633361362\n",
      "train loss:0.0385889086083717\n",
      "train loss:0.029110936401487396\n",
      "train loss:0.015880735809060274\n",
      "train loss:0.061198459641027395\n",
      "train loss:0.025256291708294878\n",
      "train loss:0.013769158406648701\n",
      "train loss:0.021879207291041453\n",
      "train loss:0.0239021537534643\n",
      "train loss:0.07891687214344296\n",
      "train loss:0.02572054943162394\n",
      "train loss:0.048743914625190336\n",
      "train loss:0.05008306126097367\n",
      "train loss:0.023608161562368293\n",
      "train loss:0.029392056540928323\n",
      "train loss:0.02025493863162048\n",
      "train loss:0.03482604418488127\n",
      "train loss:0.07966477669886066\n",
      "train loss:0.038509036307848174\n",
      "train loss:0.006234567739922539\n",
      "train loss:0.020842190010905995\n",
      "train loss:0.018828234697667142\n",
      "train loss:0.06627394894494869\n",
      "train loss:0.09313073421523271\n",
      "train loss:0.009709030568202319\n",
      "train loss:0.03770026958150783\n",
      "train loss:0.012909751063685611\n",
      "train loss:0.02020275209486078\n",
      "train loss:0.01842569615467797\n",
      "train loss:0.021808574269277528\n",
      "train loss:0.020654880414886098\n",
      "train loss:0.020756336793949247\n",
      "train loss:0.04276702686942501\n",
      "train loss:0.02434336554962638\n",
      "train loss:0.005217887430368396\n",
      "train loss:0.016439031538640434\n",
      "train loss:0.022305915288745908\n",
      "train loss:0.03453212088639843\n",
      "train loss:0.0259373122898058\n",
      "train loss:0.03290126983232738\n",
      "train loss:0.015753617242418395\n",
      "train loss:0.08946439551584305\n",
      "train loss:0.014149264708649356\n",
      "train loss:0.014860822509143772\n",
      "train loss:0.003638392756890551\n",
      "train loss:0.05281302455122855\n",
      "train loss:0.027083446172017283\n",
      "train loss:0.030069461244865644\n",
      "train loss:0.019037786902260524\n",
      "train loss:0.012278005744730121\n",
      "train loss:0.03837936033910918\n",
      "train loss:0.012617586907501706\n",
      "train loss:0.015632695936625945\n",
      "train loss:0.021560911619373985\n",
      "train loss:0.013503425580191403\n",
      "train loss:0.0754984435583631\n",
      "train loss:0.03934206855133718\n",
      "train loss:0.06613788037560712\n",
      "train loss:0.07011517406835771\n",
      "train loss:0.010166030228020689\n",
      "train loss:0.030503369734530508\n",
      "train loss:0.06815447804686539\n",
      "train loss:0.021692895619517705\n",
      "train loss:0.007846157111767083\n",
      "train loss:0.022067749021924273\n",
      "train loss:0.018280708605170996\n",
      "train loss:0.022504144453154646\n",
      "train loss:0.03833199621212045\n",
      "train loss:0.008740239932030278\n",
      "train loss:0.011145557313674094\n",
      "train loss:0.06520008128686838\n",
      "train loss:0.011033156702625715\n",
      "train loss:0.02921172334209708\n",
      "train loss:0.0179233489989328\n",
      "train loss:0.02590099140464647\n",
      "train loss:0.033539864002536626\n",
      "train loss:0.020250551760817862\n",
      "train loss:0.013552259757544321\n",
      "train loss:0.00885027675842665\n",
      "train loss:0.048911155847685926\n",
      "train loss:0.02191493164721649\n",
      "train loss:0.028610983462650244\n",
      "train loss:0.040437220173902465\n",
      "train loss:0.0402222073882273\n",
      "train loss:0.062171550289056514\n",
      "train loss:0.00735320534018524\n",
      "train loss:0.008765092526284563\n",
      "train loss:0.09070052702855896\n",
      "train loss:0.004643911886909168\n",
      "train loss:0.005537176828850128\n",
      "train loss:0.0038275237454505205\n",
      "train loss:0.01866998904125825\n",
      "train loss:0.051352239992592634\n",
      "train loss:0.02215673399715159\n",
      "train loss:0.026882229454058933\n",
      "train loss:0.010914248539280922\n",
      "train loss:0.034858559840465736\n",
      "train loss:0.0612198849924429\n",
      "train loss:0.08869585056233566\n",
      "train loss:0.030619711659985685\n",
      "train loss:0.020129916367807112\n",
      "train loss:0.04477320426374558\n",
      "train loss:0.02526995574593518\n",
      "train loss:0.011782606411118654\n",
      "train loss:0.03509009092047987\n",
      "train loss:0.03788567010255181\n",
      "train loss:0.02281273945560948\n",
      "train loss:0.031502246893348074\n",
      "train loss:0.019149768256098564\n",
      "train loss:0.029562143736795617\n",
      "train loss:0.051653706885514135\n",
      "train loss:0.004031809493807815\n",
      "train loss:0.010641657036233477\n",
      "train loss:0.023039989184558452\n",
      "train loss:0.009695198414890466\n",
      "train loss:0.009188573126135998\n",
      "train loss:0.02027632732827318\n",
      "train loss:0.006124056003066476\n",
      "train loss:0.02152811457436464\n",
      "train loss:0.033191323243365774\n",
      "train loss:0.001986651277212244\n",
      "train loss:0.03575787119084429\n",
      "train loss:0.028480066378023854\n",
      "train loss:0.14357738444449428\n",
      "train loss:0.03336346141093167\n",
      "train loss:0.02135461249231361\n",
      "train loss:0.012367207775298985\n",
      "train loss:0.010838263303029394\n",
      "train loss:0.11513841736531331\n",
      "train loss:0.04027008820592878\n",
      "train loss:0.02293219475542423\n",
      "train loss:0.021243870543236093\n",
      "train loss:0.015168895387029244\n",
      "train loss:0.007284391122033043\n",
      "train loss:0.013773459344367371\n",
      "train loss:0.032046653389024723\n",
      "train loss:0.04987649976506169\n",
      "train loss:0.024291650772487024\n",
      "train loss:0.012218834039889537\n",
      "train loss:0.011258090661591526\n",
      "train loss:0.0690658657837088\n",
      "=== epoch:6, train acc:0.985, test acc:0.985 ===\n",
      "train loss:0.01074417490457758\n",
      "train loss:0.05121063424207751\n",
      "train loss:0.00670778843026834\n",
      "train loss:0.033284842737576904\n",
      "train loss:0.007900882628172295\n",
      "train loss:0.024798334553956542\n",
      "train loss:0.03291179643995723\n",
      "train loss:0.013602697718521333\n",
      "train loss:0.005144579173654669\n",
      "train loss:0.03526484979569227\n",
      "train loss:0.03662493304826262\n",
      "train loss:0.014291736685577205\n",
      "train loss:0.016072052574333966\n",
      "train loss:0.06335353164773234\n",
      "train loss:0.10363595535628622\n",
      "train loss:0.01371018310247282\n",
      "train loss:0.017724519238127217\n",
      "train loss:0.006951400211188883\n",
      "train loss:0.05540624530518442\n",
      "train loss:0.009752593764005061\n",
      "train loss:0.013230922101771792\n",
      "train loss:0.01887790624709303\n",
      "train loss:0.09756006062181612\n",
      "train loss:0.040834499071384096\n",
      "train loss:0.007719832800759705\n",
      "train loss:0.020036427116154457\n",
      "train loss:0.047388820093498533\n",
      "train loss:0.005952629197429946\n",
      "train loss:0.014594046362184199\n",
      "train loss:0.008528193051801969\n",
      "train loss:0.017897531135424086\n",
      "train loss:0.009677502873041357\n",
      "train loss:0.0174267519993372\n",
      "train loss:0.05694579048887759\n",
      "train loss:0.05005952018245787\n",
      "train loss:0.0042973452441110735\n",
      "train loss:0.013059826715787728\n",
      "train loss:0.03417139622757849\n",
      "train loss:0.004175166113312746\n",
      "train loss:0.02486962382528886\n",
      "train loss:0.023757885430761197\n",
      "train loss:0.013443841615727717\n",
      "train loss:0.060215070361333584\n",
      "train loss:0.013614499115443436\n",
      "train loss:0.015498939085183693\n",
      "train loss:0.012849312607713532\n",
      "train loss:0.07191876591236747\n",
      "train loss:0.02540469601711798\n",
      "train loss:0.04134342041008145\n",
      "train loss:0.06921295141885433\n",
      "train loss:0.005281991685676427\n",
      "train loss:0.025173118551543895\n",
      "train loss:0.07185043672406705\n",
      "train loss:0.03653211417938835\n",
      "train loss:0.026302311492418767\n",
      "train loss:0.07519342302719233\n",
      "train loss:0.009861578537049337\n",
      "train loss:0.09128707881063171\n",
      "train loss:0.016298773657834675\n",
      "train loss:0.02156780144818975\n",
      "train loss:0.009897302552090828\n",
      "train loss:0.04748316422205973\n",
      "train loss:0.02050797121598209\n",
      "train loss:0.016782760832866915\n",
      "train loss:0.003552496052686245\n",
      "train loss:0.017558274901371625\n",
      "train loss:0.0301431592132764\n",
      "train loss:0.05086968021819318\n",
      "train loss:0.007228977619336771\n",
      "train loss:0.007071937963677199\n",
      "train loss:0.006549913685508574\n",
      "train loss:0.04334321584160151\n",
      "train loss:0.01326300541096493\n",
      "train loss:0.02112432325654177\n",
      "train loss:0.04798927824413205\n",
      "train loss:0.0205146625075734\n",
      "train loss:0.003609042457806224\n",
      "train loss:0.02593598435858554\n",
      "train loss:0.0322962116307254\n",
      "train loss:0.014242393708703982\n",
      "train loss:0.012722225307992956\n",
      "train loss:0.019496534640273667\n",
      "train loss:0.03334348412005445\n",
      "train loss:0.0286208475082777\n",
      "train loss:0.07267953994287314\n",
      "train loss:0.009578161949727174\n",
      "train loss:0.015098108956632949\n",
      "train loss:0.01150581741318212\n",
      "train loss:0.01278391470091053\n",
      "train loss:0.02043648795558449\n",
      "train loss:0.013572985224167042\n",
      "train loss:0.01469173241167877\n",
      "train loss:0.021160205518035605\n",
      "train loss:0.004431024507947373\n",
      "train loss:0.023548362327202317\n",
      "train loss:0.007240565181751484\n",
      "train loss:0.020563655821988797\n",
      "train loss:0.015856262464977375\n",
      "train loss:0.021449145441754885\n",
      "train loss:0.006335015691594967\n",
      "train loss:0.0756571607266192\n",
      "train loss:0.1062807184771834\n",
      "train loss:0.012661402532854893\n",
      "train loss:0.013117691780404457\n",
      "train loss:0.0501586681529411\n",
      "train loss:0.0007979873231387279\n",
      "train loss:0.05112151477339954\n",
      "train loss:0.007481973674705545\n",
      "train loss:0.09197586772099792\n",
      "train loss:0.03753238936791235\n",
      "train loss:0.01631903646327073\n",
      "train loss:0.048952072163203526\n",
      "train loss:0.030547362152498946\n",
      "train loss:0.018103411940506284\n",
      "train loss:0.024895714515185498\n",
      "train loss:0.009189215525162123\n",
      "train loss:0.02545338523234069\n",
      "train loss:0.02490643893872845\n",
      "train loss:0.029922463847318777\n",
      "train loss:0.005584802034393957\n",
      "train loss:0.030810420500664737\n",
      "train loss:0.02960410004069518\n",
      "train loss:0.020670562454332967\n",
      "train loss:0.01606186562559799\n",
      "train loss:0.06205927784256057\n",
      "train loss:0.025419639172254066\n",
      "train loss:0.027211643246679587\n",
      "train loss:0.020404780229590337\n",
      "train loss:0.013535538108720793\n",
      "train loss:0.004017275892176475\n",
      "train loss:0.029212903311729856\n",
      "train loss:0.031762782789047775\n",
      "train loss:0.030798528489279425\n",
      "train loss:0.02256381201311712\n",
      "train loss:0.012846072870599561\n",
      "train loss:0.02859629893212837\n",
      "train loss:0.014420616794671692\n",
      "train loss:0.04459409999347368\n",
      "train loss:0.0074189759391577025\n",
      "train loss:0.03112163875917616\n",
      "train loss:0.005384828643825178\n",
      "train loss:0.02699284882004477\n",
      "train loss:0.007248075042224681\n",
      "train loss:0.014276766582163345\n",
      "train loss:0.02212492621132239\n",
      "train loss:0.05192038272755636\n",
      "train loss:0.023473613673684817\n",
      "train loss:0.05759840733322398\n",
      "train loss:0.03969109037291822\n",
      "train loss:0.012748849011438372\n",
      "train loss:0.039978084117810404\n",
      "train loss:0.005399634575342471\n",
      "train loss:0.019215520716466906\n",
      "train loss:0.048494758910457625\n",
      "train loss:0.022719933454494735\n",
      "train loss:0.019190971804892952\n",
      "train loss:0.03110702894975086\n",
      "train loss:0.029896572551856168\n",
      "train loss:0.04725968479808294\n",
      "train loss:0.022137771803086147\n",
      "train loss:0.011209232816067775\n",
      "train loss:0.028384009104442835\n",
      "train loss:0.08113132952905772\n",
      "train loss:0.025568447370720518\n",
      "train loss:0.01698834262775637\n",
      "train loss:0.009047115743872609\n",
      "train loss:0.017663441121979775\n",
      "train loss:0.12957189725848706\n",
      "train loss:0.019030654113253595\n",
      "train loss:0.09421847367312516\n",
      "train loss:0.019912942618404535\n",
      "train loss:0.04991649623340278\n",
      "train loss:0.02217448422526772\n",
      "train loss:0.0167687400265243\n",
      "train loss:0.010775789813831522\n",
      "train loss:0.05400580343549911\n",
      "train loss:0.0220560978922575\n",
      "train loss:0.17741296821864908\n",
      "train loss:0.05151323442041005\n",
      "train loss:0.018606319163962368\n",
      "train loss:0.008285185403160972\n",
      "train loss:0.004225849381656461\n",
      "train loss:0.016031829213660403\n",
      "train loss:0.010275421232266928\n",
      "train loss:0.020425598961739427\n",
      "train loss:0.008894368571275693\n",
      "train loss:0.07138120019350618\n",
      "train loss:0.010214253417003763\n",
      "train loss:0.014789718099211013\n",
      "train loss:0.006495730291674066\n",
      "train loss:0.02019739131402462\n",
      "train loss:0.009549050410660813\n",
      "train loss:0.033988496817604893\n",
      "train loss:0.014672923915942574\n",
      "train loss:0.05760381733375379\n",
      "train loss:0.023824106268745367\n",
      "train loss:0.006554758349772363\n",
      "train loss:0.02074677534014418\n",
      "train loss:0.026418339529184362\n",
      "train loss:0.035204803953393246\n",
      "train loss:0.026053091507641794\n",
      "train loss:0.007986161337388324\n",
      "train loss:0.04278310940169817\n",
      "train loss:0.004198446630036453\n",
      "train loss:0.0042344384568500275\n",
      "train loss:0.005001605673165352\n",
      "train loss:0.008688940988099695\n",
      "train loss:0.0021226049563988574\n",
      "train loss:0.043006244516171924\n",
      "train loss:0.02002904515673409\n",
      "train loss:0.05697511348006001\n",
      "train loss:0.01590965332654524\n",
      "train loss:0.010717472638400685\n",
      "train loss:0.11195883672048439\n",
      "train loss:0.024968915400853168\n",
      "train loss:0.013026239624271376\n",
      "train loss:0.018855913006245204\n",
      "train loss:0.032127561553513845\n",
      "train loss:0.00876263784576307\n",
      "train loss:0.03230554652364478\n",
      "train loss:0.0172665348570879\n",
      "train loss:0.029299518151050634\n",
      "train loss:0.020741987577061714\n",
      "train loss:0.007930448127734855\n",
      "train loss:0.03845172905415713\n",
      "train loss:0.017711492812887173\n",
      "train loss:0.022661378042173344\n",
      "train loss:0.027555626539814283\n",
      "train loss:0.11161889928373243\n",
      "train loss:0.01877842528527385\n",
      "train loss:0.011944990774520037\n",
      "train loss:0.02240244467358424\n",
      "train loss:0.00964986267817109\n",
      "train loss:0.03133181885616984\n",
      "train loss:0.01195170381879303\n",
      "train loss:0.005483746638634979\n",
      "train loss:0.022783732518189773\n",
      "train loss:0.028967586875159757\n",
      "train loss:0.009518058771449164\n",
      "train loss:0.008718188515125146\n",
      "train loss:0.002335923941926657\n",
      "train loss:0.012918667687030453\n",
      "train loss:0.011093695392518827\n",
      "train loss:0.07412198261303611\n",
      "train loss:0.02139565428805604\n",
      "train loss:0.0018829613218776789\n",
      "train loss:0.06692872121605552\n",
      "train loss:0.022485987674346744\n",
      "train loss:0.03300096186554257\n",
      "train loss:0.014624046676173522\n",
      "train loss:0.022883508203320035\n",
      "train loss:0.02264990487503338\n",
      "train loss:0.008225953257132372\n",
      "train loss:0.003218295451906233\n",
      "train loss:0.014838707847215743\n",
      "train loss:0.11395662353354\n",
      "train loss:0.051087596959721926\n",
      "train loss:0.027479196992629285\n",
      "train loss:0.05097751140855637\n",
      "train loss:0.005384899221375627\n",
      "train loss:0.04880443212850036\n",
      "train loss:0.019393561557030977\n",
      "train loss:0.025864982414756633\n",
      "train loss:0.0070676215989445325\n",
      "train loss:0.04653761309948384\n",
      "train loss:0.011576916681683083\n",
      "train loss:0.05427752534043833\n",
      "train loss:0.01392354125216873\n",
      "train loss:0.02635116261189806\n",
      "train loss:0.0031503138722737555\n",
      "train loss:0.009824045028524827\n",
      "train loss:0.04062117698497513\n",
      "train loss:0.02936253215229999\n",
      "train loss:0.027840277055758134\n",
      "train loss:0.015403939722946654\n",
      "train loss:0.015384121091965656\n",
      "train loss:0.01980816610447862\n",
      "train loss:0.04112966923901136\n",
      "train loss:0.01029041448394117\n",
      "train loss:0.04740064495334433\n",
      "train loss:0.022478939199836415\n",
      "train loss:0.00632816275838402\n",
      "train loss:0.011695752893354023\n",
      "train loss:0.015148237142950449\n",
      "train loss:0.008755611210165083\n",
      "train loss:0.011193778266002976\n",
      "train loss:0.05512669463019335\n",
      "train loss:0.010249547780930113\n",
      "train loss:0.05098640589321665\n",
      "train loss:0.008874782690404032\n",
      "train loss:0.013328021225236434\n",
      "train loss:0.012393599472305304\n",
      "train loss:0.02533923165761267\n",
      "train loss:0.07414631181703302\n",
      "train loss:0.008225778323159651\n",
      "train loss:0.018731064349658537\n",
      "train loss:0.008288880689763552\n",
      "train loss:0.015757070572471065\n",
      "train loss:0.07859770572474963\n",
      "train loss:0.024471115111051395\n",
      "train loss:0.022687871089869516\n",
      "train loss:0.023420335540842375\n",
      "train loss:0.006260440712560103\n",
      "train loss:0.020579319545544164\n",
      "train loss:0.01893385593705456\n",
      "train loss:0.006869700545003151\n",
      "train loss:0.020972651009338494\n",
      "train loss:0.06652529329109502\n",
      "train loss:0.0528860493822981\n",
      "train loss:0.06485677397965028\n",
      "train loss:0.024479038275364504\n",
      "train loss:0.013269663396701666\n",
      "train loss:0.03603011075913619\n",
      "train loss:0.04429505419217268\n",
      "train loss:0.03731538256491279\n",
      "train loss:0.033849633724752734\n",
      "train loss:0.042772252252189426\n",
      "train loss:0.004782424028632791\n",
      "train loss:0.023931292214126768\n",
      "train loss:0.02293206020735185\n",
      "train loss:0.01250384603484118\n",
      "train loss:0.02251025556639425\n",
      "train loss:0.014940049814971464\n",
      "train loss:0.0121700145091714\n",
      "train loss:0.008445273995264768\n",
      "train loss:0.00786482611379187\n",
      "train loss:0.005248192907207667\n",
      "train loss:0.03261496548364054\n",
      "train loss:0.013414884829532953\n",
      "train loss:0.026989992817822175\n",
      "train loss:0.010210537005560351\n",
      "train loss:0.009572738076652113\n",
      "train loss:0.01482270481219132\n",
      "train loss:0.019863213285443538\n",
      "train loss:0.005846690672900847\n",
      "train loss:0.02087934146562793\n",
      "train loss:0.007032373872180245\n",
      "train loss:0.014433162960525039\n",
      "train loss:0.08684150126605351\n",
      "train loss:0.014791654307905642\n",
      "train loss:0.013772210124586664\n",
      "train loss:0.026564073660838582\n",
      "train loss:0.005551580205282905\n",
      "train loss:0.009905782118932121\n",
      "train loss:0.005874263114492917\n",
      "train loss:0.008287440952826554\n",
      "train loss:0.008088007113353602\n",
      "train loss:0.014486443908026742\n",
      "train loss:0.02614089404439883\n",
      "train loss:0.011420707979904552\n",
      "train loss:0.04118204708185983\n",
      "train loss:0.016854654288415805\n",
      "train loss:0.14378750047796957\n",
      "train loss:0.004117829514622577\n",
      "train loss:0.02330555928181835\n",
      "train loss:0.006413071713946516\n",
      "train loss:0.009431640959998305\n",
      "train loss:0.008873677926548895\n",
      "train loss:0.009227390430253857\n",
      "train loss:0.02113138707610397\n",
      "train loss:0.006015666979145188\n",
      "train loss:0.08676689861372547\n",
      "train loss:0.05075165954111431\n",
      "train loss:0.013296701601910366\n",
      "train loss:0.07403940527089864\n",
      "train loss:0.011599256085688075\n",
      "train loss:0.02407547326366834\n",
      "train loss:0.051137719937972906\n",
      "train loss:0.006334628109290382\n",
      "train loss:0.022584718678334635\n",
      "train loss:0.018648783945033994\n",
      "train loss:0.016726379560906838\n",
      "train loss:0.03174814531590301\n",
      "train loss:0.008785995805102271\n",
      "train loss:0.014126534180597464\n",
      "train loss:0.008630242285079241\n",
      "train loss:0.017502296775922445\n",
      "train loss:0.005753477551843828\n",
      "train loss:0.07907061816245829\n",
      "train loss:0.026110933175137907\n",
      "train loss:0.044901721775620886\n",
      "train loss:0.05478854634834292\n",
      "train loss:0.006354669737211334\n",
      "train loss:0.012242982561044667\n",
      "train loss:0.004499543716716272\n",
      "train loss:0.00893406770616067\n",
      "train loss:0.0354536345650343\n",
      "train loss:0.014159854147526763\n",
      "train loss:0.0308904491950274\n",
      "train loss:0.00772971931264523\n",
      "train loss:0.021744195455071665\n",
      "train loss:0.031660189170084466\n",
      "train loss:0.05724728001038832\n",
      "train loss:0.040606723612943735\n",
      "train loss:0.01441081000222597\n",
      "train loss:0.014642883478157655\n",
      "train loss:0.03604579330618574\n",
      "train loss:0.012313867691199055\n",
      "train loss:0.026902212130331754\n",
      "train loss:0.03161371611840498\n",
      "train loss:0.00814775031160999\n",
      "train loss:0.0035925626612563844\n",
      "train loss:0.024960458328079565\n",
      "train loss:0.026807229262523467\n",
      "train loss:0.00491236245041514\n",
      "train loss:0.005692691173085982\n",
      "train loss:0.013921334020183236\n",
      "train loss:0.01007091056229807\n",
      "train loss:0.009028019886309392\n",
      "train loss:0.015391846565564051\n",
      "train loss:0.07334924114845282\n",
      "train loss:0.02133605770235568\n",
      "train loss:0.009731928118083438\n",
      "train loss:0.06212722510254477\n",
      "train loss:0.006413028160141836\n",
      "train loss:0.01807716396347685\n",
      "train loss:0.009148695891852462\n",
      "train loss:0.007488077392032502\n",
      "train loss:0.00920155106080099\n",
      "train loss:0.00881616624815944\n",
      "train loss:0.012857377912090108\n",
      "train loss:0.009118927516857727\n",
      "train loss:0.008672722167993765\n",
      "train loss:0.026931020500727505\n",
      "train loss:0.02926643946476029\n",
      "train loss:0.029993720577640413\n",
      "train loss:0.007734922183353219\n",
      "train loss:0.02576069002861005\n",
      "train loss:0.03248550278051281\n",
      "train loss:0.017449269826205566\n",
      "train loss:0.013903607655302687\n",
      "train loss:0.0052255228329020145\n",
      "train loss:0.010954057031667701\n",
      "train loss:0.01818864932280016\n",
      "train loss:0.009645201068897843\n",
      "train loss:0.00998958427868878\n",
      "train loss:0.03650552898402355\n",
      "train loss:0.01800094474497532\n",
      "train loss:0.03478099890273357\n",
      "train loss:0.033969925760578265\n",
      "train loss:0.04094749133460016\n",
      "train loss:0.04452724218943464\n",
      "train loss:0.026219110903991517\n",
      "train loss:0.04550447301576762\n",
      "train loss:0.002616061126395722\n",
      "train loss:0.02091491619733624\n",
      "train loss:0.053655613983772554\n",
      "train loss:0.031549959703474774\n",
      "train loss:0.027536336739186488\n",
      "train loss:0.009224576646949433\n",
      "train loss:0.022003888309130217\n",
      "train loss:0.0029429109095689627\n",
      "train loss:0.01150202249503799\n",
      "train loss:0.02030743051751852\n",
      "train loss:0.007928159786753897\n",
      "train loss:0.024166048426925154\n",
      "train loss:0.012122408694217055\n",
      "train loss:0.02683688497973814\n",
      "train loss:0.005051995920267402\n",
      "train loss:0.02232532278160699\n",
      "train loss:0.010127890937862722\n",
      "train loss:0.026078129860843378\n",
      "train loss:0.05554051347155995\n",
      "train loss:0.0206290390786914\n",
      "train loss:0.010185564515397882\n",
      "train loss:0.03008782419035846\n",
      "train loss:0.04955572035318747\n",
      "train loss:0.021361471514245677\n",
      "train loss:0.030594280910513437\n",
      "train loss:0.003930304280277156\n",
      "train loss:0.011721597889687357\n",
      "train loss:0.014516350949627143\n",
      "train loss:0.007575350000864128\n",
      "train loss:0.006962905556744809\n",
      "train loss:0.013464169879394871\n",
      "train loss:0.02405575789704584\n",
      "train loss:0.11538394639500099\n",
      "train loss:0.006201775060670888\n",
      "train loss:0.0045222752894115885\n",
      "train loss:0.021167296803578185\n",
      "train loss:0.005662009400032252\n",
      "train loss:0.019225141791067605\n",
      "train loss:0.015567734706923582\n",
      "train loss:0.0044911807106359\n",
      "train loss:0.018612717961925387\n",
      "train loss:0.024638188371059466\n",
      "train loss:0.012114247421544804\n",
      "train loss:0.03932686246119598\n",
      "train loss:0.006720577464091634\n",
      "train loss:0.014236834109301533\n",
      "train loss:0.011919746142447358\n",
      "train loss:0.00921626478293431\n",
      "train loss:0.005009626463604783\n",
      "train loss:0.025883287025704648\n",
      "train loss:0.029205353627381064\n",
      "train loss:0.027507055842797397\n",
      "train loss:0.00723097261598145\n",
      "train loss:0.012497649069573964\n",
      "train loss:0.003627278623489476\n",
      "train loss:0.05423507749644853\n",
      "train loss:0.005655236720743168\n",
      "train loss:0.008687475609685288\n",
      "train loss:0.0010098667030164158\n",
      "train loss:0.005237739550873959\n",
      "train loss:0.05199224038892893\n",
      "train loss:0.013825978854138294\n",
      "train loss:0.01989401835355356\n",
      "train loss:0.035013657920144936\n",
      "train loss:0.039497301554853224\n",
      "train loss:0.01141886688796047\n",
      "train loss:0.016549421809377598\n",
      "train loss:0.04235441763943459\n",
      "train loss:0.023587561293121853\n",
      "train loss:0.019500993710221314\n",
      "train loss:0.013927211245644477\n",
      "train loss:0.03256432348683189\n",
      "train loss:0.0160485879850299\n",
      "train loss:0.041936618128416286\n",
      "train loss:0.013350284380177846\n",
      "train loss:0.0350942599344959\n",
      "train loss:0.004666710912598807\n",
      "train loss:0.019739779002634357\n",
      "train loss:0.12598274727492118\n",
      "train loss:0.005938077923236771\n",
      "train loss:0.012488208249292622\n",
      "train loss:0.026925164331680632\n",
      "train loss:0.018880976204419385\n",
      "train loss:0.0185805154689592\n",
      "train loss:0.03556157613027103\n",
      "train loss:0.014332339544253716\n",
      "train loss:0.03830917675342823\n",
      "train loss:0.03564217459007896\n",
      "train loss:0.003066158067051237\n",
      "train loss:0.052292905539173866\n",
      "train loss:0.008397188378366328\n",
      "train loss:0.026200829631201728\n",
      "train loss:0.04075385413585399\n",
      "train loss:0.006051424992144652\n",
      "train loss:0.007527154869305821\n",
      "train loss:0.008964295406212337\n",
      "train loss:0.04762977826768637\n",
      "train loss:0.015264072632302393\n",
      "train loss:0.01198411215148743\n",
      "train loss:0.007653301455375548\n",
      "train loss:0.01622069724439224\n",
      "train loss:0.0023234664374846476\n",
      "train loss:0.014792321993657565\n",
      "train loss:0.0064149914521598895\n",
      "train loss:0.025616663762723008\n",
      "train loss:0.04643272312432544\n",
      "train loss:0.0036215866779319506\n",
      "train loss:0.020407137758015975\n",
      "train loss:0.013646967773121094\n",
      "train loss:0.008438302901128484\n",
      "train loss:0.009696455986117777\n",
      "train loss:0.0051659156174135535\n",
      "train loss:0.003759099392124003\n",
      "train loss:0.010984857937224632\n",
      "train loss:0.04152340954109396\n",
      "train loss:0.003978268005611762\n",
      "train loss:0.027619758684305013\n",
      "train loss:0.011609600795979941\n",
      "train loss:0.03565137798338916\n",
      "train loss:0.01408202268432055\n",
      "train loss:0.020423994380697988\n",
      "train loss:0.0062418443304257274\n",
      "train loss:0.009316672403276625\n",
      "train loss:0.004169058887766775\n",
      "train loss:0.02743764489070596\n",
      "train loss:0.021020235498176193\n",
      "train loss:0.022795434300907646\n",
      "train loss:0.005702303601481789\n",
      "train loss:0.022919018645531034\n",
      "train loss:0.014848189771042415\n",
      "train loss:0.030373175618749255\n",
      "train loss:0.003718142275692272\n",
      "train loss:0.05252554213570565\n",
      "train loss:0.015742131271331294\n",
      "train loss:0.02866804617593828\n",
      "train loss:0.033698647267634364\n",
      "train loss:0.030270610267791497\n",
      "train loss:0.01474792685401808\n",
      "train loss:0.0275771501399715\n",
      "train loss:0.002843800910880656\n",
      "train loss:0.00408895775061581\n",
      "train loss:0.01597175283380345\n",
      "train loss:0.026424651310163232\n",
      "train loss:0.017876640307149295\n",
      "train loss:0.02680918826549434\n",
      "train loss:0.025136961036745474\n",
      "train loss:0.0045318405475161146\n",
      "train loss:0.006096554295264501\n",
      "train loss:0.010724755415373807\n",
      "train loss:0.013096624401038797\n",
      "train loss:0.006666796186559264\n",
      "train loss:0.021555872573199165\n",
      "train loss:0.052240770006235865\n",
      "train loss:0.09915303269229274\n",
      "train loss:0.018460727959389495\n",
      "train loss:0.03500868273083298\n",
      "=== epoch:7, train acc:0.985, test acc:0.979 ===\n",
      "train loss:0.0153465481876106\n",
      "train loss:0.0506928010097372\n",
      "train loss:0.026489455598738294\n",
      "train loss:0.013101565676701598\n",
      "train loss:0.014300852473205372\n",
      "train loss:0.011462246923146725\n",
      "train loss:0.010564302165512048\n",
      "train loss:0.015391069722836364\n",
      "train loss:0.013654608899877964\n",
      "train loss:0.011657589790706625\n",
      "train loss:0.013726969917788892\n",
      "train loss:0.008380457028414392\n",
      "train loss:0.00457025947132764\n",
      "train loss:0.020414476862207032\n",
      "train loss:0.05821657086878445\n",
      "train loss:0.0044908044836254445\n",
      "train loss:0.09190672751743348\n",
      "train loss:0.04629438963086242\n",
      "train loss:0.014630460432108205\n",
      "train loss:0.00563673349003821\n",
      "train loss:0.025585597471167513\n",
      "train loss:0.010844409328892204\n",
      "train loss:0.03554927245194305\n",
      "train loss:0.013147684173173692\n",
      "train loss:0.005144880964201633\n",
      "train loss:0.026443131107751663\n",
      "train loss:0.003546529482126381\n",
      "train loss:0.019403929926322012\n",
      "train loss:0.003896429069138136\n",
      "train loss:0.017739326831257965\n",
      "train loss:0.014818330977546219\n",
      "train loss:0.005929504621957098\n",
      "train loss:0.022958375566391402\n",
      "train loss:0.018804981447948444\n",
      "train loss:0.004891134571411631\n",
      "train loss:0.029772787577780596\n",
      "train loss:0.04979535300808815\n",
      "train loss:0.00745462265213389\n",
      "train loss:0.06665500639417181\n",
      "train loss:0.008804102164657214\n",
      "train loss:0.006063262872323954\n",
      "train loss:0.019072105993707896\n",
      "train loss:0.020986993775967563\n",
      "train loss:0.04265061273458352\n",
      "train loss:0.011545188955460686\n",
      "train loss:0.006545878289144338\n",
      "train loss:0.04346619951456116\n",
      "train loss:0.02951929038885119\n",
      "train loss:0.05074928647280979\n",
      "train loss:0.0654779282799003\n",
      "train loss:0.012077540775686657\n",
      "train loss:0.019075367854724787\n",
      "train loss:0.01744206563517686\n",
      "train loss:0.008120151211678918\n",
      "train loss:0.00488842527226833\n",
      "train loss:0.02029513414069669\n",
      "train loss:0.0413769216624917\n",
      "train loss:0.010293653077611669\n",
      "train loss:0.00784172938324876\n",
      "train loss:0.005992962634375776\n",
      "train loss:0.01905385727072176\n",
      "train loss:0.010637656625126357\n",
      "train loss:0.013905866624394607\n",
      "train loss:0.012450376053065697\n",
      "train loss:0.009318246337134153\n",
      "train loss:0.01691050468775914\n",
      "train loss:0.011716047580361464\n",
      "train loss:0.00787258649352544\n",
      "train loss:0.008322276321839194\n",
      "train loss:0.004398221022377917\n",
      "train loss:0.02331915727833375\n",
      "train loss:0.008299879313167087\n",
      "train loss:0.003806460247606681\n",
      "train loss:0.003487703136581684\n",
      "train loss:0.009715422408755942\n",
      "train loss:0.028312737087168922\n",
      "train loss:0.035391401550125635\n",
      "train loss:0.007401016136554167\n",
      "train loss:0.015135486801172415\n",
      "train loss:0.010753933691516377\n",
      "train loss:0.0060626856607836985\n",
      "train loss:0.005058086962286854\n",
      "train loss:0.007097840458772774\n",
      "train loss:0.02273232123019773\n",
      "train loss:0.009496366373714654\n",
      "train loss:0.01706564569678203\n",
      "train loss:0.01466157849011292\n",
      "train loss:0.01463797057720994\n",
      "train loss:0.00660092898899823\n",
      "train loss:0.016707003749614778\n",
      "train loss:0.033172151767281687\n",
      "train loss:0.043990067538807354\n",
      "train loss:0.01194328359124658\n",
      "train loss:0.004473348627589366\n",
      "train loss:0.007369923637035338\n",
      "train loss:0.006352318147170612\n",
      "train loss:0.00477405207918592\n",
      "train loss:0.02545221286328201\n",
      "train loss:0.010518248230207477\n",
      "train loss:0.015373379869359927\n",
      "train loss:0.015068907367361556\n",
      "train loss:0.022569097848963465\n",
      "train loss:0.003121689183859114\n",
      "train loss:0.010358222431146775\n",
      "train loss:0.0039088504959700196\n",
      "train loss:0.02026195463163528\n",
      "train loss:0.010738346517923608\n",
      "train loss:0.004074527199204205\n",
      "train loss:0.018108541960589267\n",
      "train loss:0.04168946590909415\n",
      "train loss:0.01572023484764935\n",
      "train loss:0.009443300817230044\n",
      "train loss:0.0283693683138898\n",
      "train loss:0.05222777177935011\n",
      "train loss:0.01908123715488962\n",
      "train loss:0.009195798302839064\n",
      "train loss:0.05909858741413337\n",
      "train loss:0.009697707071618666\n",
      "train loss:0.031353874807967155\n",
      "train loss:0.05884276787707968\n",
      "train loss:0.012387095996648773\n",
      "train loss:0.06791721145921314\n",
      "train loss:0.02071859945199461\n",
      "train loss:0.0034273561564397985\n",
      "train loss:0.07254621616576204\n",
      "train loss:0.024201673011525326\n",
      "train loss:0.009268302157001864\n",
      "train loss:0.022982972702518954\n",
      "train loss:0.01695799732935205\n",
      "train loss:0.014762769796812032\n",
      "train loss:0.006290763874446884\n",
      "train loss:0.010257503056285559\n",
      "train loss:0.006834382726465046\n",
      "train loss:0.020372971969675423\n",
      "train loss:0.010847858085411936\n",
      "train loss:0.010820752340837103\n",
      "train loss:0.041754283290989264\n",
      "train loss:0.01118245660275776\n",
      "train loss:0.03166580955578828\n",
      "train loss:0.006346135017911115\n",
      "train loss:0.018103516370880295\n",
      "train loss:0.023105228532002878\n",
      "train loss:0.006492900056159418\n",
      "train loss:0.003073951517349434\n",
      "train loss:0.00796459046773662\n",
      "train loss:0.0036711804367468015\n",
      "train loss:0.008528893302031082\n",
      "train loss:0.016121739441942028\n",
      "train loss:0.030976953697176436\n",
      "train loss:0.007005699209968012\n",
      "train loss:0.03416625652688261\n",
      "train loss:0.0027050976489154353\n",
      "train loss:0.0031469539572472754\n",
      "train loss:0.013405895934522943\n",
      "train loss:0.007322570793018029\n",
      "train loss:0.0034235325982544446\n",
      "train loss:0.04117701426556309\n",
      "train loss:0.023512786027459848\n",
      "train loss:0.016221133505085666\n",
      "train loss:0.04227370846110708\n",
      "train loss:0.013500250578693364\n",
      "train loss:0.01611741404061681\n",
      "train loss:0.006362775373888385\n",
      "train loss:0.012052584044151611\n",
      "train loss:0.0141380169907729\n",
      "train loss:0.006145632281520625\n",
      "train loss:0.028977671230647813\n",
      "train loss:0.007167005949337898\n",
      "train loss:0.01047217764974412\n",
      "train loss:0.028148020546025308\n",
      "train loss:0.005120702589135746\n",
      "train loss:0.014639742039890128\n",
      "train loss:0.0062094031584642795\n",
      "train loss:0.026076821400133263\n",
      "train loss:0.0018647224092982165\n",
      "train loss:0.041559461717337216\n",
      "train loss:0.020608596917785767\n",
      "train loss:0.012604709833213566\n",
      "train loss:0.021885441542881204\n",
      "train loss:0.04238357560586725\n",
      "train loss:0.014521059754209018\n",
      "train loss:0.005399788053021055\n",
      "train loss:0.029896713631078282\n",
      "train loss:0.005648900710834408\n",
      "train loss:0.015205780651202467\n",
      "train loss:0.060084993778088264\n",
      "train loss:0.00789884410476811\n",
      "train loss:0.006005216081422442\n",
      "train loss:0.017047894935335123\n",
      "train loss:0.006960153252731812\n",
      "train loss:0.012126358717059022\n",
      "train loss:0.008372305667830288\n",
      "train loss:0.009521433190030678\n",
      "train loss:0.007221520666272105\n",
      "train loss:0.06860042093397731\n",
      "train loss:0.012710803620695765\n",
      "train loss:0.016419010467767378\n",
      "train loss:0.00395394041533273\n",
      "train loss:0.06554220456177842\n",
      "train loss:0.005032137131553056\n",
      "train loss:0.02184860742360029\n",
      "train loss:0.0094408418113815\n",
      "train loss:0.003867267133364805\n",
      "train loss:0.0015396213274394442\n",
      "train loss:0.043025596488610915\n",
      "train loss:0.0022980625594143256\n",
      "train loss:0.01356609756343847\n",
      "train loss:0.01113346629833193\n",
      "train loss:0.008292392872256003\n",
      "train loss:0.0047950341038829735\n",
      "train loss:0.007688739828407537\n",
      "train loss:0.04011035804746379\n",
      "train loss:0.05041167191479881\n",
      "train loss:0.02403070348837559\n",
      "train loss:0.020747857276831493\n",
      "train loss:0.001600787989754707\n",
      "train loss:0.008588724639857197\n",
      "train loss:0.02114123759449373\n",
      "train loss:0.003817848887341027\n",
      "train loss:0.0012916436012776178\n",
      "train loss:0.009709692713633429\n",
      "train loss:0.006531977715698851\n",
      "train loss:0.031233550163345974\n",
      "train loss:0.07200025809303806\n",
      "train loss:0.06263535265487497\n",
      "train loss:0.023883600246546358\n",
      "train loss:0.01710080842814929\n",
      "train loss:0.023382724620299302\n",
      "train loss:0.008300149629956349\n",
      "train loss:0.007899933549362963\n",
      "train loss:0.030242501647264674\n",
      "train loss:0.014934567103681826\n",
      "train loss:0.03244206054863181\n",
      "train loss:0.013642962883941193\n",
      "train loss:0.03306544080015297\n",
      "train loss:0.010167349834146536\n",
      "train loss:0.018381598549627204\n",
      "train loss:0.014726867452046702\n",
      "train loss:0.10975779034610979\n",
      "train loss:0.010766694132923065\n",
      "train loss:0.018499552445681064\n",
      "train loss:0.013022902178485719\n",
      "train loss:0.02936197355521408\n",
      "train loss:0.03487488899140584\n",
      "train loss:0.04204124938425946\n",
      "train loss:0.016058106814948056\n",
      "train loss:0.022565561546451365\n",
      "train loss:0.03176850709093186\n",
      "train loss:0.023596851516495942\n",
      "train loss:0.055261879811068094\n",
      "train loss:0.02790242102418382\n",
      "train loss:0.054157440083836904\n",
      "train loss:0.013802469759165574\n",
      "train loss:0.015092514812551819\n",
      "train loss:0.016029473320337655\n",
      "train loss:0.016854009471708134\n",
      "train loss:0.02792304471878098\n",
      "train loss:0.049974588797879395\n",
      "train loss:0.03132094578182318\n",
      "train loss:0.05954623417516167\n",
      "train loss:0.017388936390908997\n",
      "train loss:0.01758149822286001\n",
      "train loss:0.0225657725901456\n",
      "train loss:0.024957827611233645\n",
      "train loss:0.06885680200429074\n",
      "train loss:0.011790610879963866\n",
      "train loss:0.011856078088659771\n",
      "train loss:0.00613011778122546\n",
      "train loss:0.09746867342277249\n",
      "train loss:0.011019177473133636\n",
      "train loss:0.01675129254936748\n",
      "train loss:0.005646536627554859\n",
      "train loss:0.014088377072245585\n",
      "train loss:0.002917117271651201\n",
      "train loss:0.026182345388147427\n",
      "train loss:0.030281336607066698\n",
      "train loss:0.014444188969234193\n",
      "train loss:0.03083995469047095\n",
      "train loss:0.010862313433291025\n",
      "train loss:0.01046536170140697\n",
      "train loss:0.014402214785386214\n",
      "train loss:0.11271554015163616\n",
      "train loss:0.007172334885157466\n",
      "train loss:0.04907485157662779\n",
      "train loss:0.01471270817255831\n",
      "train loss:0.02052970128350313\n",
      "train loss:0.00824494782702524\n",
      "train loss:0.0150366777613352\n",
      "train loss:0.06119727530024506\n",
      "train loss:0.01973373264629917\n",
      "train loss:0.0041409373847655015\n",
      "train loss:0.015009411797791004\n",
      "train loss:0.07085966561074519\n",
      "train loss:0.021527575108401045\n",
      "train loss:0.03778327763962379\n",
      "train loss:0.05924469500658735\n",
      "train loss:0.00783946336239433\n",
      "train loss:0.009643322927900981\n",
      "train loss:0.005139709645933889\n",
      "train loss:0.013107276654564307\n",
      "train loss:0.024716065684207634\n",
      "train loss:0.013297165731311874\n",
      "train loss:0.010094607251302281\n",
      "train loss:0.004795596472363182\n",
      "train loss:0.024026772781094517\n",
      "train loss:0.008927881029552928\n",
      "train loss:0.0026550731182216564\n",
      "train loss:0.039337410688497734\n",
      "train loss:0.0032136176181026886\n",
      "train loss:0.006151060777498702\n",
      "train loss:0.02189887103276398\n",
      "train loss:0.0031000746640884517\n",
      "train loss:0.051844405627058394\n",
      "train loss:0.011388343930248407\n",
      "train loss:0.01192992540222133\n",
      "train loss:0.0035414874568142716\n",
      "train loss:0.008998303804552871\n",
      "train loss:0.0026620346794246578\n",
      "train loss:0.0036848714254375373\n",
      "train loss:0.012299839602849562\n",
      "train loss:0.013255669665015068\n",
      "train loss:0.0037657013538042686\n",
      "train loss:0.006420817929871609\n",
      "train loss:0.024041853162906107\n",
      "train loss:0.040761821636063844\n",
      "train loss:0.004201431923026632\n",
      "train loss:0.008597650678868132\n",
      "train loss:0.010843411775503114\n",
      "train loss:0.007546420949547078\n",
      "train loss:0.027008566047885697\n",
      "train loss:0.015583055126415876\n",
      "train loss:0.01008042821538137\n",
      "train loss:0.026148678335186235\n",
      "train loss:0.028459395760464558\n",
      "train loss:0.014136882428296802\n",
      "train loss:0.003144637104223453\n",
      "train loss:0.012291044863077114\n",
      "train loss:0.03086551017795995\n",
      "train loss:0.022329257133165005\n",
      "train loss:0.06012294880361359\n",
      "train loss:0.004995098277948681\n",
      "train loss:0.08096663012487104\n",
      "train loss:0.014960110596865315\n",
      "train loss:0.029593554995309804\n",
      "train loss:0.012786841229366068\n",
      "train loss:0.0016635476847348455\n",
      "train loss:0.01965576471827359\n",
      "train loss:0.020205877743219962\n",
      "train loss:0.002848034479314705\n",
      "train loss:0.0036908844203623796\n",
      "train loss:0.052868597504900514\n",
      "train loss:0.021865143555219384\n",
      "train loss:0.019730072899866953\n",
      "train loss:0.0017119477515489994\n",
      "train loss:0.018224942438928457\n",
      "train loss:0.010392480562449447\n",
      "train loss:0.005878282940925201\n",
      "train loss:0.011341761832540926\n",
      "train loss:0.007577436295924913\n",
      "train loss:0.017553754510728103\n",
      "train loss:0.04195284246305759\n",
      "train loss:0.029658137068850787\n",
      "train loss:0.031060667958183758\n",
      "train loss:0.017878750419757557\n",
      "train loss:0.006993346563877718\n",
      "train loss:0.06453466067919111\n",
      "train loss:0.035120791030218715\n",
      "train loss:0.003095225815714568\n",
      "train loss:0.018033382043914012\n",
      "train loss:0.01039438619185155\n",
      "train loss:0.014610783216347503\n",
      "train loss:0.01261023141644269\n",
      "train loss:0.021603021260102134\n",
      "train loss:0.0072074964950631535\n",
      "train loss:0.023127395124153387\n",
      "train loss:0.007505996709266414\n",
      "train loss:0.011736472276628907\n",
      "train loss:0.06089842156984357\n",
      "train loss:0.008177778653041073\n",
      "train loss:0.008024668347859153\n",
      "train loss:0.0033208465512274375\n",
      "train loss:0.008632194474988315\n",
      "train loss:0.021414913426566616\n",
      "train loss:0.01801560796770363\n",
      "train loss:0.006397623391297826\n",
      "train loss:0.011245108645248523\n",
      "train loss:0.0044025668858164715\n",
      "train loss:0.02661092314876413\n",
      "train loss:0.0344906150688212\n",
      "train loss:0.0032042278122637324\n",
      "train loss:0.01294203484889511\n",
      "train loss:0.004651687807728489\n",
      "train loss:0.004822684547924587\n",
      "train loss:0.02035093993865303\n",
      "train loss:0.015114787767065067\n",
      "train loss:0.01907900063719807\n",
      "train loss:0.006450206982696859\n",
      "train loss:0.006707243167022103\n",
      "train loss:0.009085919832830313\n",
      "train loss:0.03574356463737297\n",
      "train loss:0.011247895820619722\n",
      "train loss:0.011720427901754111\n",
      "train loss:0.017944161823635226\n",
      "train loss:0.054557607472055014\n",
      "train loss:0.05252349176331642\n",
      "train loss:0.011556723130095911\n",
      "train loss:0.0027230379132170946\n",
      "train loss:0.010328567894174306\n",
      "train loss:0.011483269015908461\n",
      "train loss:0.024008219360810247\n",
      "train loss:0.001190832054650739\n",
      "train loss:0.004705037878388174\n",
      "train loss:0.008251139943404965\n",
      "train loss:0.021495987627857423\n",
      "train loss:0.013744695213584613\n",
      "train loss:0.012533295710839911\n",
      "train loss:0.011827908836054635\n",
      "train loss:0.011490698987123278\n",
      "train loss:0.007519890158746926\n",
      "train loss:0.016867635616865707\n",
      "train loss:0.04686060583069884\n",
      "train loss:0.008899130733659371\n",
      "train loss:0.003365424714785885\n",
      "train loss:0.027920226165585618\n",
      "train loss:0.07863346359741663\n",
      "train loss:0.03215536379536378\n",
      "train loss:0.008664555220653848\n",
      "train loss:0.008187097905786839\n",
      "train loss:0.0019340185875823673\n",
      "train loss:0.005478896909656097\n",
      "train loss:0.008796229739813689\n",
      "train loss:0.01275494995304244\n",
      "train loss:0.014130679540810771\n",
      "train loss:0.020046558487435976\n",
      "train loss:0.007193120098594178\n",
      "train loss:0.021471692266415585\n",
      "train loss:0.014998143331633781\n",
      "train loss:0.015753030324550044\n",
      "train loss:0.012325081773567323\n",
      "train loss:0.03413586723532332\n",
      "train loss:0.02073780254558661\n",
      "train loss:0.005270990569988668\n",
      "train loss:0.03197896472342459\n",
      "train loss:0.006427387091909783\n",
      "train loss:0.00460332001694416\n",
      "train loss:0.00987642430367093\n",
      "train loss:0.003038391459690975\n",
      "train loss:0.0014998589358575479\n",
      "train loss:0.025818502845521136\n",
      "train loss:0.0063609159830695615\n",
      "train loss:0.009856802681331153\n",
      "train loss:0.07225529962994016\n",
      "train loss:0.0061085661146207835\n",
      "train loss:0.00454656438865094\n",
      "train loss:0.026010802315654922\n",
      "train loss:0.010529353235085491\n",
      "train loss:0.004728087218165912\n",
      "train loss:0.04498297933083387\n",
      "train loss:0.0077689148463061545\n",
      "train loss:0.006614640014335717\n",
      "train loss:0.0039695267730742775\n",
      "train loss:0.007224441287268226\n",
      "train loss:0.015094005641937379\n",
      "train loss:0.015254858130665518\n",
      "train loss:0.0023192346949073538\n",
      "train loss:0.003566614584477238\n",
      "train loss:0.008169247264463124\n",
      "train loss:0.003850534778159438\n",
      "train loss:0.004250235092508891\n",
      "train loss:0.031770557200945265\n",
      "train loss:0.004402276547663538\n",
      "train loss:0.018552228299950325\n",
      "train loss:0.0169405286702478\n",
      "train loss:0.0012498347371973676\n",
      "train loss:0.009584279615727049\n",
      "train loss:0.006582802331219261\n",
      "train loss:0.0033211402249075724\n",
      "train loss:0.007115880212981785\n",
      "train loss:0.006876368296393835\n",
      "train loss:0.011164099076367976\n",
      "train loss:0.009625349545262318\n",
      "train loss:0.0339173085775219\n",
      "train loss:0.046289676902852614\n",
      "train loss:0.006326196924934307\n",
      "train loss:0.009954159275046993\n",
      "train loss:0.012949982451258198\n",
      "train loss:0.059921597117237574\n",
      "train loss:0.008799110721908558\n",
      "train loss:0.004433254439159878\n",
      "train loss:0.019605692191638137\n",
      "train loss:0.027571344368381063\n",
      "train loss:0.023943084900776304\n",
      "train loss:0.010618117607295769\n",
      "train loss:0.00605268338260921\n",
      "train loss:0.01969814632621988\n",
      "train loss:0.027364297325068117\n",
      "train loss:0.008167874395445838\n",
      "train loss:0.007554539563467467\n",
      "train loss:0.005051349849521781\n",
      "train loss:0.016892073208241324\n",
      "train loss:0.1469951019150118\n",
      "train loss:0.010064770977893697\n",
      "train loss:0.008006380753343846\n",
      "train loss:0.04790059826390777\n",
      "train loss:0.010130145132537112\n",
      "train loss:0.012622431388996873\n",
      "train loss:0.010811935067012836\n",
      "train loss:0.010365398954244145\n",
      "train loss:0.009020026060741402\n",
      "train loss:0.0011636492442212974\n",
      "train loss:0.01832212438295658\n",
      "train loss:0.013236311125926836\n",
      "train loss:0.0060496489920759625\n",
      "train loss:0.00729464662915284\n",
      "train loss:0.026020984494331906\n",
      "train loss:0.012851817476176723\n",
      "train loss:0.006841600152370809\n",
      "train loss:0.03986156870260607\n",
      "train loss:0.014219064861140157\n",
      "train loss:0.013828981840989156\n",
      "train loss:0.06107741948814507\n",
      "train loss:0.006269931544059435\n",
      "train loss:0.0037776062036305952\n",
      "train loss:0.0062687509408681195\n",
      "train loss:0.053354905003069344\n",
      "train loss:0.021007494157421404\n",
      "train loss:0.030394655851818043\n",
      "train loss:0.02018294813589833\n",
      "train loss:0.014890154817750745\n",
      "train loss:0.005492458887188435\n",
      "train loss:0.004871293626884846\n",
      "train loss:0.015267313429524079\n",
      "train loss:0.032125898805854425\n",
      "train loss:0.025483022938501333\n",
      "train loss:0.0080719880843265\n",
      "train loss:0.039609875366856825\n",
      "train loss:0.052187828116567324\n",
      "train loss:0.03751151812914577\n",
      "train loss:0.03364962824843819\n",
      "train loss:0.0370172609533653\n",
      "train loss:0.010560899217009624\n",
      "train loss:0.006434537546749744\n",
      "train loss:0.02436789324961603\n",
      "train loss:0.020365727767643754\n",
      "train loss:0.047400707708989104\n",
      "train loss:0.004766573689139151\n",
      "train loss:0.028309709429480797\n",
      "train loss:0.023831632116243968\n",
      "train loss:0.010148139864063392\n",
      "train loss:0.01006416330358015\n",
      "train loss:0.016063361399733224\n",
      "train loss:0.008057056751109766\n",
      "train loss:0.035968694720258744\n",
      "train loss:0.00511520730467355\n",
      "train loss:0.010121081503091439\n",
      "train loss:0.0038182863049662117\n",
      "train loss:0.02974138273777569\n",
      "train loss:0.008711049084345581\n",
      "train loss:0.024714039808034514\n",
      "train loss:0.015259059735921765\n",
      "train loss:0.010177248656603275\n",
      "train loss:0.006342439345554058\n",
      "train loss:0.05220764860548658\n",
      "train loss:0.01114174195222291\n",
      "train loss:0.02279378137238727\n",
      "train loss:0.04496445315577259\n",
      "train loss:0.006938431682631699\n",
      "train loss:0.0125065714318926\n",
      "train loss:0.007833974327481468\n",
      "train loss:0.010178908855484564\n",
      "train loss:0.0016380182773029545\n",
      "train loss:0.01614481130722888\n",
      "train loss:0.008433603580342808\n",
      "train loss:0.026599896841156774\n",
      "train loss:0.004984383427397708\n",
      "train loss:0.006119218088913606\n",
      "train loss:0.0035632162823051494\n",
      "train loss:0.005017364160456628\n",
      "train loss:0.005139552461181509\n",
      "train loss:0.010315223146869364\n",
      "train loss:0.021226026264915515\n",
      "train loss:0.004328104024546159\n",
      "train loss:0.002631324656552213\n",
      "train loss:0.024713484773084788\n",
      "train loss:0.00982801498651845\n",
      "train loss:0.018818468851197465\n",
      "train loss:0.08652745362873766\n",
      "train loss:0.031433750476725336\n",
      "train loss:0.0035175006528683182\n",
      "train loss:0.020915794107089655\n",
      "train loss:0.01569536975810647\n",
      "train loss:0.00734661152906001\n",
      "train loss:0.048512328238769165\n",
      "train loss:0.015166112392407689\n",
      "train loss:0.008937614703387243\n",
      "train loss:0.0037963665110174612\n",
      "train loss:0.006617232955836042\n",
      "train loss:0.008144764383530588\n",
      "train loss:0.019422233733332274\n",
      "train loss:0.010411659025965856\n",
      "=== epoch:8, train acc:0.989, test acc:0.985 ===\n",
      "train loss:0.019766883477995774\n",
      "train loss:0.06166142496574767\n",
      "train loss:0.07122941672201226\n",
      "train loss:0.027209517117218304\n",
      "train loss:0.020498212921067665\n",
      "train loss:0.01691078225409896\n",
      "train loss:0.010089936409959779\n",
      "train loss:0.012267774784214189\n",
      "train loss:0.009051684689934439\n",
      "train loss:0.007264199616505715\n",
      "train loss:0.02546309068096597\n",
      "train loss:0.01181292588351992\n",
      "train loss:0.02141027124216\n",
      "train loss:0.0193437435821475\n",
      "train loss:0.05803854400497914\n",
      "train loss:0.007843406083558827\n",
      "train loss:0.0033951085873548865\n",
      "train loss:0.0019042992354291696\n",
      "train loss:0.005061229633601056\n",
      "train loss:0.0028341868107944882\n",
      "train loss:0.005109301434979192\n",
      "train loss:0.01073057238325036\n",
      "train loss:0.004879659580055566\n",
      "train loss:0.002823464995711547\n",
      "train loss:0.0077758693346394155\n",
      "train loss:0.06792982158167522\n",
      "train loss:0.0018856239616131493\n",
      "train loss:0.010349822015114231\n",
      "train loss:0.0022127168072944912\n",
      "train loss:0.01570270061504489\n",
      "train loss:0.00389045372811653\n",
      "train loss:0.03491232265987504\n",
      "train loss:0.03678902631202507\n",
      "train loss:0.010128759849064153\n",
      "train loss:0.004640296257185052\n",
      "train loss:0.0019491020829210423\n",
      "train loss:0.04686116225950943\n",
      "train loss:0.06312154987210174\n",
      "train loss:0.004935378081469083\n",
      "train loss:0.02493883605270105\n",
      "train loss:0.0042683181209881805\n",
      "train loss:0.0014978834335229382\n",
      "train loss:0.01187128563150037\n",
      "train loss:0.011364819347696507\n",
      "train loss:0.0028376495965898784\n",
      "train loss:0.03633750130859912\n",
      "train loss:0.003891789132995916\n",
      "train loss:0.0078021230357687476\n",
      "train loss:0.0061934977114513744\n",
      "train loss:0.007220289381443474\n",
      "train loss:0.060067956976908296\n",
      "train loss:0.006879112716377204\n",
      "train loss:0.009095781617433695\n",
      "train loss:0.009176182140364976\n",
      "train loss:0.007078467462097931\n",
      "train loss:0.0537511295848004\n",
      "train loss:0.004840459859175661\n",
      "train loss:0.02163728244103973\n",
      "train loss:0.16903761692689584\n",
      "train loss:0.0365189714067002\n",
      "train loss:0.006529678221986265\n",
      "train loss:0.016084714832874155\n",
      "train loss:0.04891384343947644\n",
      "train loss:0.012289807123775458\n",
      "train loss:0.01302972424345944\n",
      "train loss:0.006984233694592119\n",
      "train loss:0.004966704373863287\n",
      "train loss:0.0027609427291666678\n",
      "train loss:0.019422362607885383\n",
      "train loss:0.012396221593738009\n",
      "train loss:0.019759864507743245\n",
      "train loss:0.00295111358102912\n",
      "train loss:0.003477583839432056\n",
      "train loss:0.01748924502555384\n",
      "train loss:0.010646864248978389\n",
      "train loss:0.011788838218428514\n",
      "train loss:0.0463625773565561\n",
      "train loss:0.013418677437515356\n",
      "train loss:0.0241719279439192\n",
      "train loss:0.029439842887132618\n",
      "train loss:0.005101512345894426\n",
      "train loss:0.013162781393213396\n",
      "train loss:0.00531953070981893\n",
      "train loss:0.003367376246821262\n",
      "train loss:0.007574744101578008\n",
      "train loss:0.005892273880661976\n",
      "train loss:0.0045653840149512135\n",
      "train loss:0.009822892570351101\n",
      "train loss:0.029285235067096932\n",
      "train loss:0.005294679212825762\n",
      "train loss:0.0061148367807175455\n",
      "train loss:0.039624044682426335\n",
      "train loss:0.01152050832590173\n",
      "train loss:0.00670806719799692\n",
      "train loss:0.005244116458363852\n",
      "train loss:0.005159189352267732\n",
      "train loss:0.0060743098407192555\n",
      "train loss:0.021505794493640585\n",
      "train loss:0.0040852708516543376\n",
      "train loss:0.017650625672527672\n",
      "train loss:0.01816934935075905\n",
      "train loss:0.018154166160471382\n",
      "train loss:0.03204706696159689\n",
      "train loss:0.01538698893771787\n",
      "train loss:0.010713751318543468\n",
      "train loss:0.0033239473724068895\n",
      "train loss:0.008716282684184928\n",
      "train loss:0.0020487542966959437\n",
      "train loss:0.017726586145948027\n",
      "train loss:0.008771571294377042\n",
      "train loss:0.00977121153872983\n",
      "train loss:0.018300578526335844\n",
      "train loss:0.00543466219432982\n",
      "train loss:0.005258850860116191\n",
      "train loss:0.021986065227589394\n",
      "train loss:0.014960738684207487\n",
      "train loss:0.017780505111979608\n",
      "train loss:0.0030049559065198237\n",
      "train loss:0.00791477516767231\n",
      "train loss:0.01308300612865727\n",
      "train loss:0.008579983252189066\n",
      "train loss:0.08274692875292022\n",
      "train loss:0.006365183915282267\n",
      "train loss:0.016679475256394783\n",
      "train loss:0.012728166128110832\n",
      "train loss:0.004844335956571789\n",
      "train loss:0.0013145234463431302\n",
      "train loss:0.005171385842114907\n",
      "train loss:0.027204575458482802\n",
      "train loss:0.006342439417183588\n",
      "train loss:0.019334695663816917\n",
      "train loss:0.010761868019115124\n",
      "train loss:0.014519032794575636\n",
      "train loss:0.005722712937231783\n",
      "train loss:0.06660860362719781\n",
      "train loss:0.011547957517619828\n",
      "train loss:0.01243877521316366\n",
      "train loss:0.016347193717794497\n",
      "train loss:0.05746065111625857\n",
      "train loss:0.004407168732892961\n",
      "train loss:0.009041461044395252\n",
      "train loss:0.01879468295099318\n",
      "train loss:0.004351263099623431\n",
      "train loss:0.007890405677927844\n",
      "train loss:0.013593758044412046\n",
      "train loss:0.03771793265424145\n",
      "train loss:0.013525783876733479\n",
      "train loss:0.0021933645083713343\n",
      "train loss:0.0036428911350373655\n",
      "train loss:0.005596601540997405\n",
      "train loss:0.036552993361934946\n",
      "train loss:0.007775182282435635\n",
      "train loss:0.009475406125276286\n",
      "train loss:0.0035101092758892\n",
      "train loss:0.06386212319974885\n",
      "train loss:0.009070772714455345\n",
      "train loss:0.008855570457947506\n",
      "train loss:0.015705562584424442\n",
      "train loss:0.006879285043466512\n",
      "train loss:0.009413267096853455\n",
      "train loss:0.02241537090756984\n",
      "train loss:0.008953200961256466\n",
      "train loss:0.06638335731805282\n",
      "train loss:0.023050259800506744\n",
      "train loss:0.023382050265139034\n",
      "train loss:0.005874226397985627\n",
      "train loss:0.0018517194726220907\n",
      "train loss:0.024945992850402797\n",
      "train loss:0.034972193949416426\n",
      "train loss:0.004544182392263001\n",
      "train loss:0.006192411557392172\n",
      "train loss:0.003770145409008645\n",
      "train loss:0.00802917211481329\n",
      "train loss:0.005089615916664939\n",
      "train loss:0.015496036511036046\n",
      "train loss:0.03218812017482644\n",
      "train loss:0.02524950193589841\n",
      "train loss:0.023880223477673507\n",
      "train loss:0.0037166494278522825\n",
      "train loss:0.06487075367710358\n",
      "train loss:0.034344997514163415\n",
      "train loss:0.013611367387308993\n",
      "train loss:0.005547676505757303\n",
      "train loss:0.004419022849561926\n",
      "train loss:0.00514495628788379\n",
      "train loss:0.056798325894143825\n",
      "train loss:0.010890846776940475\n",
      "train loss:0.02700302145266163\n",
      "train loss:0.09625605379499767\n",
      "train loss:0.00817585857977607\n",
      "train loss:0.0027027923743073432\n",
      "train loss:0.017260018639895517\n",
      "train loss:0.05258540846668138\n",
      "train loss:0.009142091317045449\n",
      "train loss:0.013569901012670409\n",
      "train loss:0.013533972794011582\n",
      "train loss:0.00623597831001711\n",
      "train loss:0.012884047735272838\n",
      "train loss:0.08566628868051981\n",
      "train loss:0.011605238322590894\n",
      "train loss:0.01733080432301553\n",
      "train loss:0.018316499160805858\n",
      "train loss:0.006589227551537414\n",
      "train loss:0.0171614385089367\n",
      "train loss:0.10110593353329288\n",
      "train loss:0.00137706696901528\n",
      "train loss:0.027190809030078013\n",
      "train loss:0.004674950741925499\n",
      "train loss:0.002617226718891834\n",
      "train loss:0.0062283587349218315\n",
      "train loss:0.004390053310488643\n",
      "train loss:0.009766016862754969\n",
      "train loss:0.012772028779559892\n",
      "train loss:0.02091182391023164\n",
      "train loss:0.008593553938743104\n",
      "train loss:0.013760738870445724\n",
      "train loss:0.015499602228158075\n",
      "train loss:0.01448343083900514\n",
      "train loss:0.006442185675030347\n",
      "train loss:0.0038054270726506083\n",
      "train loss:0.00534887713698799\n",
      "train loss:0.012914399023188734\n",
      "train loss:0.009485643914911251\n",
      "train loss:0.005431644529332541\n",
      "train loss:0.008023165237152354\n",
      "train loss:0.01201010508326098\n",
      "train loss:0.005034293007280054\n",
      "train loss:0.008466558886190067\n",
      "train loss:0.023489826116671674\n",
      "train loss:0.001896704760838523\n",
      "train loss:0.01716259588754502\n",
      "train loss:0.010119200332842802\n",
      "train loss:0.012648376206437172\n",
      "train loss:0.02208861966274029\n",
      "train loss:0.012038318974756282\n",
      "train loss:0.010705164095517352\n",
      "train loss:0.013308722252320574\n",
      "train loss:0.01053143683203645\n",
      "train loss:0.011441710129166071\n",
      "train loss:0.004501208017601773\n",
      "train loss:0.013149131202801987\n",
      "train loss:0.003401084669277781\n",
      "train loss:0.007561703230746892\n",
      "train loss:0.029146347882655247\n",
      "train loss:0.011025508821044618\n",
      "train loss:0.004110732989596295\n",
      "train loss:0.01213640570758419\n",
      "train loss:0.0024766823761351144\n",
      "train loss:0.016391603954281304\n",
      "train loss:0.013321463110819417\n",
      "train loss:0.00992610076795706\n",
      "train loss:0.015075124063398004\n",
      "train loss:0.026937042991388632\n",
      "train loss:0.012353695901471293\n",
      "train loss:0.007212890831815545\n",
      "train loss:0.013434462038017054\n",
      "train loss:0.019539024612080878\n",
      "train loss:0.0027635231434749185\n",
      "train loss:0.011966127451852583\n",
      "train loss:0.007304689545514984\n",
      "train loss:0.0075601012167483385\n",
      "train loss:0.01685222306893735\n",
      "train loss:0.004722556877155683\n",
      "train loss:0.01206859743527869\n",
      "train loss:0.011171024800317344\n",
      "train loss:0.010401779220167504\n",
      "train loss:0.0021886316538434775\n",
      "train loss:0.017818115041913947\n",
      "train loss:0.0094121755311242\n",
      "train loss:0.004721968746563696\n",
      "train loss:0.003427615501276107\n",
      "train loss:0.006515721018079771\n",
      "train loss:0.017906175374759303\n",
      "train loss:0.0010251482056442965\n",
      "train loss:0.019217769992748254\n",
      "train loss:0.013693488671868613\n",
      "train loss:0.04593188124599656\n",
      "train loss:0.004782528036458655\n",
      "train loss:0.015186632702089323\n",
      "train loss:0.013596178914453574\n",
      "train loss:0.01652377093812522\n",
      "train loss:0.012702125907757732\n",
      "train loss:0.0065075939247508695\n",
      "train loss:0.0033122752831449965\n",
      "train loss:0.008780625275927642\n",
      "train loss:0.0039382930554272355\n",
      "train loss:0.025861879666272042\n",
      "train loss:0.014254905582543397\n",
      "train loss:0.002298518750852192\n",
      "train loss:0.03485474601795763\n",
      "train loss:0.01338932916074416\n",
      "train loss:0.01029466125545555\n",
      "train loss:0.02143106118895582\n",
      "train loss:0.010534334474648932\n",
      "train loss:0.012569591723617475\n",
      "train loss:0.004736883007351187\n",
      "train loss:0.01477722035041452\n",
      "train loss:0.008131233115110352\n",
      "train loss:0.021864429273143405\n",
      "train loss:0.006749422914386145\n",
      "train loss:0.016260302978146977\n",
      "train loss:0.01704788417358821\n",
      "train loss:0.009281987088644477\n",
      "train loss:0.042462850066481206\n",
      "train loss:0.002808482497069963\n",
      "train loss:0.014018441775479323\n",
      "train loss:0.006652708639917416\n",
      "train loss:0.008045935894516968\n",
      "train loss:0.007101642244151691\n",
      "train loss:0.019266895584900336\n",
      "train loss:0.015362107405614205\n",
      "train loss:0.00404835706284647\n",
      "train loss:0.006873857735861569\n",
      "train loss:0.009237795007895584\n",
      "train loss:0.015824649683865304\n",
      "train loss:0.0028042612044023407\n",
      "train loss:0.012940699981347649\n",
      "train loss:0.005798073822637488\n",
      "train loss:0.012595126280277697\n",
      "train loss:0.012004098073662537\n",
      "train loss:0.023348409832424658\n",
      "train loss:0.0019993701458944965\n",
      "train loss:0.01539550428139407\n",
      "train loss:0.045913510301422725\n",
      "train loss:0.004036773001747919\n",
      "train loss:0.03825991469556043\n",
      "train loss:0.004533471269455291\n",
      "train loss:0.04373447038360145\n",
      "train loss:0.008499207937983899\n",
      "train loss:0.0054966418700125265\n",
      "train loss:0.003784575254552014\n",
      "train loss:0.007345636990496417\n",
      "train loss:0.003359762767588511\n",
      "train loss:0.01544637499274963\n",
      "train loss:0.010611890354798812\n",
      "train loss:0.010380609367215266\n",
      "train loss:0.003862756925363871\n",
      "train loss:0.005857474031752932\n",
      "train loss:0.009359366051006042\n",
      "train loss:0.003757222465207709\n",
      "train loss:0.09588059058713103\n",
      "train loss:0.00802491734741513\n",
      "train loss:0.0019208747084638492\n",
      "train loss:0.023620312801516663\n",
      "train loss:0.004813145442601219\n",
      "train loss:0.009095659933237457\n",
      "train loss:0.017105543511124442\n",
      "train loss:0.0060937188428833965\n",
      "train loss:0.002517544428351367\n",
      "train loss:0.006026029534824392\n",
      "train loss:0.006477552370511249\n",
      "train loss:0.0027629258023894577\n",
      "train loss:0.009339960771374906\n",
      "train loss:0.008089822417517554\n",
      "train loss:0.011992354228137915\n",
      "train loss:0.0034882238088525842\n",
      "train loss:0.005867384856692584\n",
      "train loss:0.013938775786493642\n",
      "train loss:0.002712635693415316\n",
      "train loss:0.002717120100499003\n",
      "train loss:0.013581967726162231\n",
      "train loss:0.0058162248068697135\n",
      "train loss:0.02116199609752982\n",
      "train loss:0.00719242165774342\n",
      "train loss:0.02555139124934812\n",
      "train loss:0.011898879643058776\n",
      "train loss:0.005326749307180044\n",
      "train loss:0.007477241635430716\n",
      "train loss:0.020006413327689168\n",
      "train loss:0.033895209531624816\n",
      "train loss:0.0030543891030208902\n",
      "train loss:0.009459947247810335\n",
      "train loss:0.003944540228478705\n",
      "train loss:0.0014730386963614165\n",
      "train loss:0.016390620283864076\n",
      "train loss:0.007881731440508622\n",
      "train loss:0.028302690267827682\n",
      "train loss:0.06049450524317816\n",
      "train loss:0.010300913894510684\n",
      "train loss:0.019050203455335226\n",
      "train loss:0.009023929529194894\n",
      "train loss:0.007152879970697504\n",
      "train loss:0.0058854658211473085\n",
      "train loss:0.0025735948905501117\n",
      "train loss:0.011352678215164497\n",
      "train loss:0.051955854512238255\n",
      "train loss:0.07706693628893267\n",
      "train loss:0.03933621232298928\n",
      "train loss:0.004332436852069725\n",
      "train loss:0.0009323181489899161\n",
      "train loss:0.01700989366908879\n",
      "train loss:0.011929305814300845\n",
      "train loss:0.008232229721484309\n",
      "train loss:0.012939361445487702\n",
      "train loss:0.023406326331101904\n",
      "train loss:0.003847358113470666\n",
      "train loss:0.013798330246610984\n",
      "train loss:0.028639970391965287\n",
      "train loss:0.04018437624676114\n",
      "train loss:0.011938030424075086\n",
      "train loss:0.019794075942848082\n",
      "train loss:0.0018556092238948508\n",
      "train loss:0.010903913414548072\n",
      "train loss:0.012964224899086624\n",
      "train loss:0.014047385041080093\n",
      "train loss:0.1542716456888272\n",
      "train loss:0.005446082123554123\n",
      "train loss:0.011901178571919184\n",
      "train loss:0.04253297298624816\n",
      "train loss:0.014403009433359495\n",
      "train loss:0.002768350541770741\n",
      "train loss:0.006281945131439715\n",
      "train loss:0.01752714931038448\n",
      "train loss:0.01554492154524931\n",
      "train loss:0.00684352176408623\n",
      "train loss:0.003584223231608905\n",
      "train loss:0.006871595541430679\n",
      "train loss:0.017710863153345247\n",
      "train loss:0.012442442477327868\n",
      "train loss:0.00510039940038763\n",
      "train loss:0.007099645722301027\n",
      "train loss:0.007355216422213291\n",
      "train loss:0.012354603124991986\n",
      "train loss:0.001801517631587478\n",
      "train loss:0.0057038718580334664\n",
      "train loss:0.01706058625945415\n",
      "train loss:0.002589663193981255\n",
      "train loss:0.004447081952833005\n",
      "train loss:0.0026823101697323144\n",
      "train loss:0.009359755986662522\n",
      "train loss:0.03245251572482365\n",
      "train loss:0.009483079682991832\n",
      "train loss:0.007247339093635433\n",
      "train loss:0.021965531570099804\n",
      "train loss:0.006991172649808771\n",
      "train loss:0.0077029503901934115\n",
      "train loss:0.017455905717636264\n",
      "train loss:0.0024864688804937165\n",
      "train loss:0.024684243216939718\n",
      "train loss:0.003609130735804239\n",
      "train loss:0.014163532714609328\n",
      "train loss:0.005788587936340658\n",
      "train loss:0.009249067548570255\n",
      "train loss:0.008266889051796745\n",
      "train loss:0.005699962979472345\n",
      "train loss:0.008746619746582812\n",
      "train loss:0.006551761926693291\n",
      "train loss:0.002966978307410049\n",
      "train loss:0.012321516125961909\n",
      "train loss:0.001463964602394665\n",
      "train loss:0.009761806958341647\n",
      "train loss:0.019638505176923823\n",
      "train loss:0.007024501351484098\n",
      "train loss:0.004009061874024118\n",
      "train loss:0.07687539257035488\n",
      "train loss:0.011998541087691881\n",
      "train loss:0.0070975493132032184\n",
      "train loss:0.006081275558788549\n",
      "train loss:0.0029191792752632584\n",
      "train loss:0.011947816596737614\n",
      "train loss:0.006390890175401679\n",
      "train loss:0.01265398021858274\n",
      "train loss:0.011055498475894581\n",
      "train loss:0.03096982747201203\n",
      "train loss:0.007639370422006932\n",
      "train loss:0.008990655710213286\n",
      "train loss:0.006491821295966205\n",
      "train loss:0.002396369536382937\n",
      "train loss:0.00680923044066697\n",
      "train loss:0.006557248839575987\n",
      "train loss:0.016260838645457402\n",
      "train loss:0.01792932876862472\n",
      "train loss:0.004023615811029022\n",
      "train loss:0.006782102396604923\n",
      "train loss:0.031695569550907216\n",
      "train loss:0.020527056867299956\n",
      "train loss:0.008460583697531747\n",
      "train loss:0.010979336474095299\n",
      "train loss:0.048042503927093534\n",
      "train loss:0.012510205358239839\n",
      "train loss:0.012506141986633676\n",
      "train loss:0.012122542888938936\n",
      "train loss:0.0016159955803878765\n",
      "train loss:0.01776932614307271\n",
      "train loss:0.004238888407956025\n",
      "train loss:0.011143764342351587\n",
      "train loss:0.005413096719816949\n",
      "train loss:0.006658743286954736\n",
      "train loss:0.0019412408899980144\n",
      "train loss:0.02950115147993764\n",
      "train loss:0.008072412621083179\n",
      "train loss:0.061506790244346785\n",
      "train loss:0.0027117270170733893\n",
      "train loss:0.024075731607877807\n",
      "train loss:0.02068154369460059\n",
      "train loss:0.01153827317536304\n",
      "train loss:0.004115325599050827\n",
      "train loss:0.023782934782716\n",
      "train loss:0.017133009569329553\n",
      "train loss:0.017449170762661146\n",
      "train loss:0.020774338455429628\n",
      "train loss:0.004355601316074085\n",
      "train loss:0.011735571770371746\n",
      "train loss:0.008622489582355687\n",
      "train loss:0.012898248672486337\n",
      "train loss:0.02479596774763061\n",
      "train loss:0.015612749302358479\n",
      "train loss:0.010870405346272786\n",
      "train loss:0.005163633910763056\n",
      "train loss:0.01161858462256616\n",
      "train loss:0.018307460683704858\n",
      "train loss:0.007672284163218132\n",
      "train loss:0.009926522414528984\n",
      "train loss:0.005585215078648517\n",
      "train loss:0.008350141057570863\n",
      "train loss:0.009240478995219322\n",
      "train loss:0.002719851823602457\n",
      "train loss:0.004669884979845831\n",
      "train loss:0.013567227568451252\n",
      "train loss:0.019523746233222533\n",
      "train loss:0.001294208290120592\n",
      "train loss:0.0023493435465455335\n",
      "train loss:0.00418910555602991\n",
      "train loss:0.008020426332732698\n",
      "train loss:0.006597502207286694\n",
      "train loss:0.008363446551102294\n",
      "train loss:0.01085847683284398\n",
      "train loss:0.15909645704643743\n",
      "train loss:0.004005079958843728\n",
      "train loss:0.03776817939626172\n",
      "train loss:0.009717255096847234\n",
      "train loss:0.0026864993505017073\n",
      "train loss:0.04457259475629608\n",
      "train loss:0.04696412664209076\n",
      "train loss:0.014047096898301949\n",
      "train loss:0.08664625416733263\n",
      "train loss:0.02395323611688012\n",
      "train loss:0.012632441020116361\n",
      "train loss:0.016462725957592527\n",
      "train loss:0.016401839567389827\n",
      "train loss:0.020302872983062922\n",
      "train loss:0.005613778784908695\n",
      "train loss:0.001677666276757749\n",
      "train loss:0.005154613958441092\n",
      "train loss:0.006561020736414058\n",
      "train loss:0.0100718061970165\n",
      "train loss:0.0032398750068613315\n",
      "train loss:0.0010665660746031268\n",
      "train loss:0.012977884506125565\n",
      "train loss:0.0038331096516008496\n",
      "train loss:0.008429271731891303\n",
      "train loss:0.011796218750066024\n",
      "train loss:0.003517083317822126\n",
      "train loss:0.0035017928226739724\n",
      "train loss:0.004473575586646528\n",
      "train loss:0.012734263884830722\n",
      "train loss:0.004306544202664424\n",
      "train loss:0.07372673737372132\n",
      "train loss:0.0203431194956238\n",
      "train loss:0.03423329317710414\n",
      "train loss:0.004826258883000112\n",
      "train loss:0.006762263265552257\n",
      "train loss:0.03011443253117583\n",
      "train loss:0.005897394424062633\n",
      "train loss:0.0037873117092393598\n",
      "train loss:0.018609996835128453\n",
      "train loss:0.004836059205204252\n",
      "train loss:0.006353653931414735\n",
      "train loss:0.025439467402659396\n",
      "train loss:0.007800777563131914\n",
      "train loss:0.01526432004227059\n",
      "train loss:0.0031367235399574565\n",
      "train loss:0.010692950471481595\n",
      "train loss:0.011385534066947893\n",
      "train loss:0.0021757739952461526\n",
      "train loss:0.0022434934554220933\n",
      "train loss:0.0034449178835461226\n",
      "train loss:0.012023748306230398\n",
      "train loss:0.024362278159704643\n",
      "train loss:0.004344619096457658\n",
      "train loss:0.004327936879012188\n",
      "train loss:0.006675163112702688\n",
      "train loss:0.002055561794523421\n",
      "train loss:0.007278100621538498\n",
      "train loss:0.006316472197567512\n",
      "train loss:0.016603311806075247\n",
      "train loss:0.004565760737874299\n",
      "train loss:0.006683546333309258\n",
      "train loss:0.003644801123589334\n",
      "train loss:0.008588772479740556\n",
      "train loss:0.005777764362824467\n",
      "train loss:0.03298970393474531\n",
      "train loss:0.04952821763140247\n",
      "train loss:0.015588800543810337\n",
      "train loss:0.016499366282433477\n",
      "train loss:0.0016088771671293985\n",
      "train loss:0.014648552525585017\n",
      "train loss:0.002334832847990923\n",
      "train loss:0.02190479457521747\n",
      "train loss:0.018470293468045046\n",
      "=== epoch:9, train acc:0.991, test acc:0.985 ===\n",
      "train loss:0.01164338636711286\n",
      "train loss:0.0032560960627941488\n",
      "train loss:0.008708538711894101\n",
      "train loss:0.01079517221170425\n",
      "train loss:0.007487115608445732\n",
      "train loss:0.01196060587513877\n",
      "train loss:0.014573387789181779\n",
      "train loss:0.04888873639582258\n",
      "train loss:0.04448298863634197\n",
      "train loss:0.012029194022728118\n",
      "train loss:0.04415508457296556\n",
      "train loss:0.0012106366150555876\n",
      "train loss:0.004546136701678796\n",
      "train loss:0.002837606785387498\n",
      "train loss:0.007983737965091699\n",
      "train loss:0.0022272108462186267\n",
      "train loss:0.041316282370724544\n",
      "train loss:0.011433044461491258\n",
      "train loss:0.004492411016513866\n",
      "train loss:0.005590131559490519\n",
      "train loss:0.028346309901533952\n",
      "train loss:0.006653116289574591\n",
      "train loss:0.0023173457980862557\n",
      "train loss:0.015442831045489684\n",
      "train loss:0.009692803973736827\n",
      "train loss:0.0011915929785552633\n",
      "train loss:0.004993448880229522\n",
      "train loss:0.022863827861677243\n",
      "train loss:0.05112395238516248\n",
      "train loss:0.0188863092030477\n",
      "train loss:0.00822914324459476\n",
      "train loss:0.01745402766337625\n",
      "train loss:0.01512767101875626\n",
      "train loss:0.009397844350396319\n",
      "train loss:0.009019919841420221\n",
      "train loss:0.017335473236143192\n",
      "train loss:0.026019758603779527\n",
      "train loss:0.02103214494872744\n",
      "train loss:0.008500549037406034\n",
      "train loss:0.0020105074526380997\n",
      "train loss:0.0018008487591094314\n",
      "train loss:0.0017412923208865736\n",
      "train loss:0.011394134453578288\n",
      "train loss:0.01320760194116102\n",
      "train loss:0.028329292419654803\n",
      "train loss:0.020077828478649286\n",
      "train loss:0.01473272192368878\n",
      "train loss:0.0047323369338979635\n",
      "train loss:0.006999987262149324\n",
      "train loss:0.019934357067603662\n",
      "train loss:0.0014726702460122348\n",
      "train loss:0.023313456134138016\n",
      "train loss:0.00836818212392867\n",
      "train loss:0.013091654420697658\n",
      "train loss:0.03749323942364209\n",
      "train loss:0.015127491876332895\n",
      "train loss:0.026156825347862817\n",
      "train loss:0.006705301990349153\n",
      "train loss:0.003412145401385848\n",
      "train loss:0.010737413069097878\n",
      "train loss:0.001760145610072224\n",
      "train loss:0.006209836526975657\n",
      "train loss:0.008170344347425015\n",
      "train loss:0.008683338977733731\n",
      "train loss:0.013929736370323355\n",
      "train loss:0.09353578192138526\n",
      "train loss:0.0069316420907430095\n",
      "train loss:0.008561186834240026\n",
      "train loss:0.0540755737345576\n",
      "train loss:0.010793505784845479\n",
      "train loss:0.0045814323868575545\n",
      "train loss:0.012021859896642142\n",
      "train loss:0.0016575428899796205\n",
      "train loss:0.05130777105517462\n",
      "train loss:0.009199528947559026\n",
      "train loss:0.0035219464069937804\n",
      "train loss:0.00941841546395434\n",
      "train loss:0.08183027506094658\n",
      "train loss:0.0067779976198881365\n",
      "train loss:0.008165730999457013\n",
      "train loss:0.008326752681773304\n",
      "train loss:0.013338483040959992\n",
      "train loss:0.015082723135208597\n",
      "train loss:0.0032334604625813036\n",
      "train loss:0.011548863464010175\n",
      "train loss:0.00850782695617255\n",
      "train loss:0.00793826599212575\n",
      "train loss:0.0046970823377280166\n",
      "train loss:0.01844487467920134\n",
      "train loss:0.008010053078950998\n",
      "train loss:0.012885165882593863\n",
      "train loss:0.0036155739593280605\n",
      "train loss:0.012826539601113485\n",
      "train loss:0.0133214860517528\n",
      "train loss:0.005860581114344381\n",
      "train loss:0.002735136811031527\n",
      "train loss:0.0025777970021978857\n",
      "train loss:0.0057855730472915114\n",
      "train loss:0.030095393515552894\n",
      "train loss:0.0186481542619817\n",
      "train loss:0.0074859854693070434\n",
      "train loss:0.04319939637430927\n",
      "train loss:0.030582211820369676\n",
      "train loss:0.010851219713690428\n",
      "train loss:0.0020428276152964107\n",
      "train loss:0.02831932393092222\n",
      "train loss:0.004983173474948072\n",
      "train loss:0.01344515080240546\n",
      "train loss:0.019776775062399662\n",
      "train loss:0.002831287589058122\n",
      "train loss:0.01963089360514893\n",
      "train loss:0.003412125426202395\n",
      "train loss:0.00758205012491758\n",
      "train loss:0.011133579165012376\n",
      "train loss:0.02073108321947894\n",
      "train loss:0.024901959239740302\n",
      "train loss:0.004025003850787446\n",
      "train loss:0.003709076560530827\n",
      "train loss:0.020309208423426164\n",
      "train loss:0.011065757170425669\n",
      "train loss:0.002834762832404731\n",
      "train loss:0.00489060235022887\n",
      "train loss:0.0048489376224110274\n",
      "train loss:0.013775865098179307\n",
      "train loss:0.007555027635973789\n",
      "train loss:0.0073289704684941104\n",
      "train loss:0.018146217849385325\n",
      "train loss:0.0060427481882985076\n",
      "train loss:0.006805503868141427\n",
      "train loss:0.005207250026918083\n",
      "train loss:0.0025624236281688263\n",
      "train loss:0.008782747334879343\n",
      "train loss:0.01725325670351595\n",
      "train loss:0.011896534241729857\n",
      "train loss:0.0014544132018872516\n",
      "train loss:0.004260013114804879\n",
      "train loss:0.0031769624629824165\n",
      "train loss:0.010679936892158863\n",
      "train loss:0.009902386725742118\n",
      "train loss:0.0018897865838558062\n",
      "train loss:0.003502351239708981\n",
      "train loss:0.0005758450729075407\n",
      "train loss:0.0030024349540120152\n",
      "train loss:0.04603993690990392\n",
      "train loss:0.014660679602111456\n",
      "train loss:0.012784526969717436\n",
      "train loss:0.0025849869138400016\n",
      "train loss:0.010703431993832278\n",
      "train loss:0.00868895871105511\n",
      "train loss:0.0272859533081729\n",
      "train loss:0.004462230520150768\n",
      "train loss:0.008116456170793285\n",
      "train loss:0.019313516707878765\n",
      "train loss:0.0036775449628028505\n",
      "train loss:0.005073930664855122\n",
      "train loss:0.002908873190088334\n",
      "train loss:0.02019566401653049\n",
      "train loss:0.0038363307850429224\n",
      "train loss:0.007933727146189444\n",
      "train loss:0.010361833854467362\n",
      "train loss:0.0044622498080922465\n",
      "train loss:0.02022319459732797\n",
      "train loss:0.022262028400460546\n",
      "train loss:0.004346132615268895\n",
      "train loss:0.0382316032929477\n",
      "train loss:0.021568606377539462\n",
      "train loss:0.002696447835412991\n",
      "train loss:0.002071564198557\n",
      "train loss:0.03902904342635908\n",
      "train loss:0.04029744858537101\n",
      "train loss:0.0029288710677731196\n",
      "train loss:0.01749132320800135\n",
      "train loss:0.009570883082698718\n",
      "train loss:0.03145955365472912\n",
      "train loss:0.006416090702583191\n",
      "train loss:0.006736241796512176\n",
      "train loss:0.002148531364815581\n",
      "train loss:0.007490392241118804\n",
      "train loss:0.019473155461493988\n",
      "train loss:0.01972893084252771\n",
      "train loss:0.012124928561646531\n",
      "train loss:0.009847409923783086\n",
      "train loss:0.004737160778566301\n",
      "train loss:0.00340874587713952\n",
      "train loss:0.003627875836070097\n",
      "train loss:0.003906534427970933\n",
      "train loss:0.0353848914225461\n",
      "train loss:0.009799846357074177\n",
      "train loss:0.0030640230655320446\n",
      "train loss:0.014760501469912883\n",
      "train loss:0.010944059301786591\n",
      "train loss:0.010415357300266517\n",
      "train loss:0.04065172597633454\n",
      "train loss:0.004060924028224832\n",
      "train loss:0.02505374313475433\n",
      "train loss:0.00891885013303778\n",
      "train loss:0.002315825294173828\n",
      "train loss:0.0030452225201079365\n",
      "train loss:0.006775559719903303\n",
      "train loss:0.01861361583861747\n",
      "train loss:0.017942167011430466\n",
      "train loss:0.006303352186206412\n",
      "train loss:0.012510707580301806\n",
      "train loss:0.0039586322329781334\n",
      "train loss:0.005619543638371745\n",
      "train loss:0.0104046644884378\n",
      "train loss:0.022430403268591328\n",
      "train loss:0.002373908668338762\n",
      "train loss:0.009851244546781967\n",
      "train loss:0.0021773347834129412\n",
      "train loss:0.006538517210411943\n",
      "train loss:0.014170465380408316\n",
      "train loss:0.0022597230522846973\n",
      "train loss:0.014084727359951789\n",
      "train loss:0.007968250001147585\n",
      "train loss:0.00670023570128516\n",
      "train loss:0.004195153080692861\n",
      "train loss:0.008738848896358405\n",
      "train loss:0.0062822022965915115\n",
      "train loss:0.01736659368752468\n",
      "train loss:0.009662136405985117\n",
      "train loss:0.010091414898434816\n",
      "train loss:0.004267402557632911\n",
      "train loss:0.004394363995053366\n",
      "train loss:0.008743131704345718\n",
      "train loss:0.024705392539586524\n",
      "train loss:0.019231075653973945\n",
      "train loss:0.007860018879144372\n",
      "train loss:0.0077113566848710435\n",
      "train loss:0.06874379653527105\n",
      "train loss:0.006907201452700835\n",
      "train loss:0.0041705206878077765\n",
      "train loss:0.012312956638262268\n",
      "train loss:0.005302603441218308\n",
      "train loss:0.009032248711889283\n",
      "train loss:0.006476916475724426\n",
      "train loss:0.011913111974709525\n",
      "train loss:0.029417384652098363\n",
      "train loss:0.015702329778168794\n",
      "train loss:0.002768436500475945\n",
      "train loss:0.006790546684747311\n",
      "train loss:0.013209945392014522\n",
      "train loss:0.00719169974426312\n",
      "train loss:0.00456894981385901\n",
      "train loss:0.009156831712095727\n",
      "train loss:0.039490465547152125\n",
      "train loss:0.006034950231406515\n",
      "train loss:0.0070595991403080574\n",
      "train loss:0.0012725957247625736\n",
      "train loss:0.003840888526871945\n",
      "train loss:0.008639200292321568\n",
      "train loss:0.007631660465122725\n",
      "train loss:0.005430073468336698\n",
      "train loss:0.0063051789530689595\n",
      "train loss:0.005023844574488147\n",
      "train loss:0.0014583516996650927\n",
      "train loss:0.006643407597488744\n",
      "train loss:0.012744903100225273\n",
      "train loss:0.007331632900731839\n",
      "train loss:0.0018188512874069223\n",
      "train loss:0.013009327334423773\n",
      "train loss:0.008083511785731827\n",
      "train loss:0.0028615002614011237\n",
      "train loss:0.012998444644111514\n",
      "train loss:0.0026391934886359873\n",
      "train loss:0.010752199366525115\n",
      "train loss:0.0021751259166419355\n",
      "train loss:0.004083302383471746\n",
      "train loss:0.014546891503043606\n",
      "train loss:0.011870323780989234\n",
      "train loss:0.0022209632876451692\n",
      "train loss:0.006709367991602786\n",
      "train loss:0.027825431397904662\n",
      "train loss:0.0013335496505564991\n",
      "train loss:0.0016838465394674762\n",
      "train loss:0.016802423388152476\n",
      "train loss:0.0017291092565444863\n",
      "train loss:0.0060398105349867\n",
      "train loss:0.0025126035858474573\n",
      "train loss:0.01020770644876404\n",
      "train loss:0.001815619240252516\n",
      "train loss:0.0199970256217945\n",
      "train loss:0.0028812769135131157\n",
      "train loss:0.005566085928983658\n",
      "train loss:0.005510802146642083\n",
      "train loss:0.005152553697631441\n",
      "train loss:0.007732361215308153\n",
      "train loss:0.000733021661441155\n",
      "train loss:0.005465020208077201\n",
      "train loss:0.0038365564101778536\n",
      "train loss:0.003788468574603121\n",
      "train loss:0.0025965719485751926\n",
      "train loss:0.023253570952969257\n",
      "train loss:0.00881712842268504\n",
      "train loss:0.008600950875353649\n",
      "train loss:0.01197752748124997\n",
      "train loss:0.007649623017489446\n",
      "train loss:0.016706407158875787\n",
      "train loss:0.008308711643414289\n",
      "train loss:0.07652044605702951\n",
      "train loss:0.029570732538969132\n",
      "train loss:0.045534808613763106\n",
      "train loss:0.0022766361723482783\n",
      "train loss:0.006239557688308087\n",
      "train loss:0.0036166656540436073\n",
      "train loss:0.04565788881499379\n",
      "train loss:0.009514344460994919\n",
      "train loss:0.02353139944411828\n",
      "train loss:0.012120254617667595\n",
      "train loss:0.0055095071786945915\n",
      "train loss:0.0009254810850785404\n",
      "train loss:0.007353535740933084\n",
      "train loss:0.0054794988393935965\n",
      "train loss:0.009176404078838215\n",
      "train loss:0.014506053149519901\n",
      "train loss:0.012219906269296617\n",
      "train loss:0.008101803340793584\n",
      "train loss:0.005398591091480707\n",
      "train loss:0.009417637636230648\n",
      "train loss:0.001669923781795661\n",
      "train loss:0.028684995718860917\n",
      "train loss:0.00938628083956536\n",
      "train loss:0.002530577660544051\n",
      "train loss:0.0013355061076580086\n",
      "train loss:0.006798389449655876\n",
      "train loss:0.011350189733267188\n",
      "train loss:0.004593140377254272\n",
      "train loss:0.014970019205852227\n",
      "train loss:0.017394662724967352\n",
      "train loss:0.011446372351797659\n",
      "train loss:0.0036055234982365837\n",
      "train loss:0.011657652551578185\n",
      "train loss:0.023671931486030397\n",
      "train loss:0.006436115793411963\n",
      "train loss:0.007238285313610189\n",
      "train loss:0.010801873932495527\n",
      "train loss:0.003190192983787659\n",
      "train loss:0.008180397017294928\n",
      "train loss:0.0026367207424926997\n",
      "train loss:0.02139408628952518\n",
      "train loss:0.04793080723132726\n",
      "train loss:0.007550364436025518\n",
      "train loss:0.032970578538165936\n",
      "train loss:0.012155997861709242\n",
      "train loss:0.009490219110848118\n",
      "train loss:0.009993534355410403\n",
      "train loss:0.019340133877531824\n",
      "train loss:0.006279661552109728\n",
      "train loss:0.018984851810818076\n",
      "train loss:0.060087954265588654\n",
      "train loss:0.039683773010460804\n",
      "train loss:0.011159672527042698\n",
      "train loss:0.0024331836600047013\n",
      "train loss:0.015120026795187775\n",
      "train loss:0.025068040461796715\n",
      "train loss:0.01353560093570446\n",
      "train loss:0.0033307126901960995\n",
      "train loss:0.003482246078593979\n",
      "train loss:0.006417360408383234\n",
      "train loss:0.00406531280820675\n",
      "train loss:0.014374977291540126\n",
      "train loss:0.013711199609770125\n",
      "train loss:0.04930789422696571\n",
      "train loss:0.00593935142352361\n",
      "train loss:0.01813143985808402\n",
      "train loss:0.0029488009988848083\n",
      "train loss:0.005355596544928243\n",
      "train loss:0.002283508855843949\n",
      "train loss:0.008231067815283735\n",
      "train loss:0.0014833252611229926\n",
      "train loss:0.018979437434682334\n",
      "train loss:0.03127403294491256\n",
      "train loss:0.014326096190260096\n",
      "train loss:0.019867093567535844\n",
      "train loss:0.0023028520697827588\n",
      "train loss:0.0030905475909463564\n",
      "train loss:0.03473408205024354\n",
      "train loss:0.017033516583573858\n",
      "train loss:0.0045422796655751815\n",
      "train loss:0.021919993554321535\n",
      "train loss:0.038984916241309106\n",
      "train loss:0.009523429775637247\n",
      "train loss:0.00476895669407491\n",
      "train loss:0.01827244078521393\n",
      "train loss:0.011788976911404792\n",
      "train loss:0.008301863806686387\n",
      "train loss:0.057121013104078716\n",
      "train loss:0.005559450537087159\n",
      "train loss:0.00960775910494164\n",
      "train loss:0.010381148858638119\n",
      "train loss:0.019155613112127243\n",
      "train loss:0.0023166098974646125\n",
      "train loss:0.0025572467856288666\n",
      "train loss:0.006965199316201303\n",
      "train loss:0.013105091503324794\n",
      "train loss:0.006279316236044607\n",
      "train loss:0.010014865524369315\n",
      "train loss:0.019222774385069856\n",
      "train loss:0.007920658560051357\n",
      "train loss:0.010872889667922065\n",
      "train loss:0.004346013710793687\n",
      "train loss:0.00633973233157198\n",
      "train loss:0.0027502547510513636\n",
      "train loss:0.011061479226802453\n",
      "train loss:0.005148632982953139\n",
      "train loss:0.005345316633612579\n",
      "train loss:0.002609414557890438\n",
      "train loss:0.01187113522443868\n",
      "train loss:0.006907713463332748\n",
      "train loss:0.005342845603641578\n",
      "train loss:0.023901806297225225\n",
      "train loss:0.0114658549119968\n",
      "train loss:0.0035012607882696856\n",
      "train loss:0.010091788784828401\n",
      "train loss:0.0003995639357222093\n",
      "train loss:0.003937054012502665\n",
      "train loss:0.008024226350316575\n",
      "train loss:0.0033313686560308454\n",
      "train loss:0.006411099031976278\n",
      "train loss:0.016257658536195718\n",
      "train loss:0.007964725202088787\n",
      "train loss:0.005343807874279191\n",
      "train loss:0.01936229183827532\n",
      "train loss:0.026208021836324404\n",
      "train loss:0.007241409011236859\n",
      "train loss:0.03324540124530404\n",
      "train loss:0.0013408154111285292\n",
      "train loss:0.0011370408240795036\n",
      "train loss:0.009897849618280321\n",
      "train loss:0.0064101285318381475\n",
      "train loss:0.0028512982918069895\n",
      "train loss:0.003932074786779806\n",
      "train loss:0.012592328253893652\n",
      "train loss:0.005429390819957739\n",
      "train loss:0.0064763960670185085\n",
      "train loss:0.004124246635595199\n",
      "train loss:0.002026857830661\n",
      "train loss:0.007333120383890149\n",
      "train loss:0.014255543933743859\n",
      "train loss:0.0030858161486638485\n",
      "train loss:0.002822139812591319\n",
      "train loss:0.027615147655296112\n",
      "train loss:0.01071929538298529\n",
      "train loss:0.019622158580581875\n",
      "train loss:0.03307694965212226\n",
      "train loss:0.004828393128758032\n",
      "train loss:0.0005342350196776304\n",
      "train loss:0.0022127183433412203\n",
      "train loss:0.0021495586045580444\n",
      "train loss:0.014774115061732445\n",
      "train loss:0.0027672607953156325\n",
      "train loss:0.013461780879991385\n",
      "train loss:0.00892468874786543\n",
      "train loss:0.019713491146063\n",
      "train loss:0.02409790124643119\n",
      "train loss:0.0068045840763118585\n",
      "train loss:0.004146443485678943\n",
      "train loss:0.012496768406880571\n",
      "train loss:0.006705949894752811\n",
      "train loss:0.003411158245104319\n",
      "train loss:0.02125092341740701\n",
      "train loss:0.0013613858654712636\n",
      "train loss:0.007107102582616339\n",
      "train loss:0.01188905310647241\n",
      "train loss:0.003221937456359068\n",
      "train loss:0.00818965680410778\n",
      "train loss:0.005367078612045641\n",
      "train loss:0.0025574879563404367\n",
      "train loss:0.014926035474184873\n",
      "train loss:0.0035149093866633408\n",
      "train loss:0.0022379353538659317\n",
      "train loss:0.1234635309795702\n",
      "train loss:0.001656190970829033\n",
      "train loss:0.004186823784423297\n",
      "train loss:0.0033229090064666434\n",
      "train loss:0.005701313190885709\n",
      "train loss:0.004375581775063742\n",
      "train loss:0.005759899206184693\n",
      "train loss:0.0012542291642546914\n",
      "train loss:0.0022114748310964965\n",
      "train loss:0.04819444288384159\n",
      "train loss:0.014322593972689746\n",
      "train loss:0.005761951823996549\n",
      "train loss:0.013882815887491462\n",
      "train loss:0.00601021088402495\n",
      "train loss:0.02387614988308349\n",
      "train loss:0.02652660407777279\n",
      "train loss:0.005764888289806057\n",
      "train loss:0.00854672307049424\n",
      "train loss:0.013712440740599347\n",
      "train loss:0.020350083357653818\n",
      "train loss:0.011405926245125618\n",
      "train loss:0.0038251852002544728\n",
      "train loss:0.004716135869282014\n",
      "train loss:0.05772750981930981\n",
      "train loss:0.024644667040271795\n",
      "train loss:0.005405694580243512\n",
      "train loss:0.004442927658105376\n",
      "train loss:0.004481379830740296\n",
      "train loss:0.002683511368345215\n",
      "train loss:0.008215569678729351\n",
      "train loss:0.0034436090486488174\n",
      "train loss:0.005394401987959239\n",
      "train loss:0.004994184997213992\n",
      "train loss:0.056154392203008774\n",
      "train loss:0.01408216133413746\n",
      "train loss:0.012577182139606024\n",
      "train loss:0.0035487815842790466\n",
      "train loss:0.028814547556945423\n",
      "train loss:0.0034971049149080603\n",
      "train loss:0.002408411081914674\n",
      "train loss:0.012612284911156317\n",
      "train loss:0.01068792213320222\n",
      "train loss:0.011313486365491211\n",
      "train loss:0.029530618575865787\n",
      "train loss:0.014436858879655923\n",
      "train loss:0.021386660671386455\n",
      "train loss:0.00870483214630844\n",
      "train loss:0.003019884473934819\n",
      "train loss:0.0062132175481757704\n",
      "train loss:0.0014547715888834952\n",
      "train loss:0.0040697844143869795\n",
      "train loss:0.0033344500459753183\n",
      "train loss:0.062338849735130125\n",
      "train loss:0.0076856998145319235\n",
      "train loss:0.0018912727115109843\n",
      "train loss:0.0005647771038854451\n",
      "train loss:0.014398672993839106\n",
      "train loss:0.056128826642975874\n",
      "train loss:0.0054363755277321525\n",
      "train loss:0.020025712176309288\n",
      "train loss:0.005802692959932929\n",
      "train loss:0.023124246303052626\n",
      "train loss:0.006939626780640736\n",
      "train loss:0.021458141885245596\n",
      "train loss:0.01124895906279446\n",
      "train loss:0.0008517173787824007\n",
      "train loss:0.005636220212950964\n",
      "train loss:0.0011009699144030186\n",
      "train loss:0.010092933846931858\n",
      "train loss:0.005470664298726783\n",
      "train loss:0.001825832214872292\n",
      "train loss:0.020324894368338963\n",
      "train loss:0.009194071959957677\n",
      "train loss:0.019351031054461544\n",
      "train loss:0.0039017070273568467\n",
      "train loss:0.01149874630881815\n",
      "train loss:0.010924780283231898\n",
      "train loss:0.003394548331127704\n",
      "train loss:0.0024257419350352818\n",
      "train loss:0.03350696426276682\n",
      "train loss:0.02553075981003437\n",
      "train loss:0.0014244830064936518\n",
      "train loss:0.003973031114873221\n",
      "train loss:0.007167090185483195\n",
      "train loss:0.00614694453571199\n",
      "train loss:0.010420480391843106\n",
      "train loss:0.014746103613608324\n",
      "train loss:0.0017459198711703187\n",
      "train loss:0.005892452547401869\n",
      "train loss:0.006451927308316336\n",
      "train loss:0.012789449751679267\n",
      "train loss:0.010554562780698709\n",
      "train loss:0.006944728255732479\n",
      "train loss:0.00993509042875401\n",
      "train loss:0.004869452002553378\n",
      "train loss:0.0034162970275878296\n",
      "train loss:0.0012522168731188554\n",
      "train loss:0.006163224643956613\n",
      "train loss:0.002024129986473861\n",
      "train loss:0.007438023500600095\n",
      "train loss:0.030638756824694822\n",
      "train loss:0.0014607775387215727\n",
      "train loss:0.003990858509083579\n",
      "train loss:0.00489104191159637\n",
      "train loss:0.002903418433726278\n",
      "train loss:0.000928721918418887\n",
      "train loss:0.0003830893078166932\n",
      "train loss:0.002067296654302499\n",
      "train loss:0.0053786390654013295\n",
      "train loss:0.004529322035470309\n",
      "train loss:0.0036729260497369194\n",
      "train loss:0.008105012706054652\n",
      "train loss:0.002658414443589484\n",
      "train loss:0.008717771668361752\n",
      "train loss:0.0007066228300546232\n",
      "train loss:0.0127808228440442\n",
      "train loss:0.012271915904576065\n",
      "train loss:0.006394516781327638\n",
      "train loss:0.008005957738141294\n",
      "train loss:0.029059929568160586\n",
      "train loss:0.024023615774857544\n",
      "train loss:0.002832217000318158\n",
      "train loss:0.006520981999945289\n",
      "train loss:0.008828310810128021\n",
      "train loss:0.008788795705138108\n",
      "train loss:0.0029754065079079773\n",
      "train loss:0.006163321753560207\n",
      "train loss:0.00850645951265693\n",
      "train loss:0.016737841229221694\n",
      "=== epoch:10, train acc:0.991, test acc:0.986 ===\n",
      "train loss:0.0020263835625923495\n",
      "train loss:0.019321871768317435\n",
      "train loss:0.009324835620005327\n",
      "train loss:0.011484128568007363\n",
      "train loss:0.009781390579555157\n",
      "train loss:0.02090893558106704\n",
      "train loss:0.025257576343418377\n",
      "train loss:0.004488751397355505\n",
      "train loss:0.007258535506470454\n",
      "train loss:0.0016340084639320197\n",
      "train loss:0.0026777702409734173\n",
      "train loss:0.009401928165475916\n",
      "train loss:0.014611651631670719\n",
      "train loss:0.002993368763416124\n",
      "train loss:0.00613475881029096\n",
      "train loss:0.002626849931518835\n",
      "train loss:0.0019842117952603346\n",
      "train loss:0.020529204090455153\n",
      "train loss:0.004171525370129787\n",
      "train loss:0.004114505245733792\n",
      "train loss:0.0014584409140604583\n",
      "train loss:0.005693765900663425\n",
      "train loss:0.007790937234763725\n",
      "train loss:0.016760454955656583\n",
      "train loss:0.00732318102216878\n",
      "train loss:0.010086945879026093\n",
      "train loss:0.029784172687237317\n",
      "train loss:0.0018151347558974474\n",
      "train loss:0.009897412266582709\n",
      "train loss:0.00462476763816484\n",
      "train loss:0.009310933503525286\n",
      "train loss:0.09390439402259315\n",
      "train loss:0.002320395022540641\n",
      "train loss:0.010534745715333282\n",
      "train loss:0.0035506480811330746\n",
      "train loss:0.04190958968499909\n",
      "train loss:0.0018653798362607834\n",
      "train loss:0.04989077900636797\n",
      "train loss:0.05332717313542372\n",
      "train loss:0.0129022722953167\n",
      "train loss:0.009340823906006625\n",
      "train loss:0.0034408605721443714\n",
      "train loss:0.005987576832071803\n",
      "train loss:0.012649711754845168\n",
      "train loss:0.009475371260715655\n",
      "train loss:0.005149774886174233\n",
      "train loss:0.013323908803110442\n",
      "train loss:0.021905018928089243\n",
      "train loss:0.008276807483336012\n",
      "train loss:0.007283504032621089\n",
      "train loss:0.0286915206333377\n",
      "train loss:0.0073816218933131185\n",
      "train loss:0.0085221363407915\n",
      "train loss:0.007067459091781626\n",
      "train loss:0.0014098540108438882\n",
      "train loss:0.005799029579572235\n",
      "train loss:0.005138794529884745\n",
      "train loss:0.05452457060664906\n",
      "train loss:0.01601497391109458\n",
      "train loss:0.009884792138880268\n",
      "train loss:0.0056354878269046695\n",
      "train loss:0.008669991178366789\n",
      "train loss:0.009169645244117994\n",
      "train loss:0.0015854017171317875\n",
      "train loss:0.0020458360661023875\n",
      "train loss:0.005088506269789373\n",
      "train loss:0.0046619666842401325\n",
      "train loss:0.005445284994245503\n",
      "train loss:0.036038813493408435\n",
      "train loss:0.0004946127530116913\n",
      "train loss:0.010993380213139652\n",
      "train loss:0.012253817758914353\n",
      "train loss:0.0028127631287217718\n",
      "train loss:0.008907553056545026\n",
      "train loss:0.006559330110969656\n",
      "train loss:0.007315848111302615\n",
      "train loss:0.005563600138225457\n",
      "train loss:0.019722288918286816\n",
      "train loss:0.0039108964573931725\n",
      "train loss:0.01762070385889336\n",
      "train loss:0.003764659517226095\n",
      "train loss:0.004700687101304152\n",
      "train loss:0.003214881859962285\n",
      "train loss:0.004331066937501027\n",
      "train loss:0.02891217061180421\n",
      "train loss:0.0013051739076818875\n",
      "train loss:0.00680998868983559\n",
      "train loss:0.00208009221918919\n",
      "train loss:0.004438459200403222\n",
      "train loss:0.023272485235958297\n",
      "train loss:0.0025115440341789137\n",
      "train loss:0.007879578068086009\n",
      "train loss:0.0077392090983063495\n",
      "train loss:0.004840451524442988\n",
      "train loss:0.014336425207631929\n",
      "train loss:0.018627428060675816\n",
      "train loss:0.0048312028196936365\n",
      "train loss:0.02054795587943246\n",
      "train loss:0.009100339082022279\n",
      "train loss:0.008913671932560967\n",
      "train loss:0.004514335014692987\n",
      "train loss:0.007252989332117435\n",
      "train loss:0.003060558118536479\n",
      "train loss:0.009409171170923098\n",
      "train loss:0.008971732438268152\n",
      "train loss:0.00307405704345364\n",
      "train loss:0.005317027241783772\n",
      "train loss:0.010173838593728774\n",
      "train loss:0.0014926221081547027\n",
      "train loss:0.003377607419319393\n",
      "train loss:0.008803182729343039\n",
      "train loss:0.0035230716349473803\n",
      "train loss:0.013758025419669934\n",
      "train loss:0.007232618743580012\n",
      "train loss:0.03792501616566897\n",
      "train loss:0.00700400695630076\n",
      "train loss:0.011725056191769669\n",
      "train loss:0.0034932445188737777\n",
      "train loss:0.006293632365517555\n",
      "train loss:0.011514771680968214\n",
      "train loss:0.010392940988912129\n",
      "train loss:0.01050326191364797\n",
      "train loss:0.0014248877937757295\n",
      "train loss:0.00948580340679043\n",
      "train loss:0.021141794251130507\n",
      "train loss:0.009405078241301794\n",
      "train loss:0.0023339889004264447\n",
      "train loss:0.003585065788159171\n",
      "train loss:0.004848642616035817\n",
      "train loss:0.0026242341767059394\n",
      "train loss:0.006374248951957836\n",
      "train loss:0.0042234278204408195\n",
      "train loss:0.0041045280938575065\n",
      "train loss:0.010063949810568929\n",
      "train loss:0.0006631905943177498\n",
      "train loss:0.0013640288100050934\n",
      "train loss:0.006861281398117647\n",
      "train loss:0.005602457011495964\n",
      "train loss:0.0012807127201824855\n",
      "train loss:0.004033705757718592\n",
      "train loss:0.0006896644252340592\n",
      "train loss:0.01394771383393088\n",
      "train loss:0.0012522196673903354\n",
      "train loss:0.004594619190802302\n",
      "train loss:0.006282234049310939\n",
      "train loss:0.0032003002623205144\n",
      "train loss:0.02852301086800015\n",
      "train loss:0.0037795255286516105\n",
      "train loss:0.004836477939386968\n",
      "train loss:0.002323901826208217\n",
      "train loss:0.016115289713432044\n",
      "train loss:0.007682181944314998\n",
      "train loss:0.011652383484173084\n",
      "train loss:0.015393271561283782\n",
      "train loss:0.003940717683010574\n",
      "train loss:0.1329079456226796\n",
      "train loss:0.008864585011481881\n",
      "train loss:0.0015165678972103639\n",
      "train loss:0.0037575622004736757\n",
      "train loss:0.008204627580342265\n",
      "train loss:0.012710712331221959\n",
      "train loss:0.020341306534453287\n",
      "train loss:0.030757341192514925\n",
      "train loss:0.015696976590193482\n",
      "train loss:0.0716866116793754\n",
      "train loss:0.03697605708248166\n",
      "train loss:0.008548130633788849\n",
      "train loss:0.005591028118531587\n",
      "train loss:0.01231938331546499\n",
      "train loss:0.0018652312686115642\n",
      "train loss:0.006196428831748215\n",
      "train loss:0.0010539722033007636\n",
      "train loss:0.008909710349484533\n",
      "train loss:0.0014674459615468178\n",
      "train loss:0.012958396062966213\n",
      "train loss:0.01828118332076414\n",
      "train loss:0.004627224721796741\n",
      "train loss:0.00758365954279902\n",
      "train loss:0.0031664618187032968\n",
      "train loss:0.002395372302055516\n",
      "train loss:0.0007863434022605071\n",
      "train loss:0.0062582309912102485\n",
      "train loss:0.003680343441934079\n",
      "train loss:0.004759783008944113\n",
      "train loss:0.02475731095450279\n",
      "train loss:0.009580370056928017\n",
      "train loss:0.025867923318574095\n",
      "train loss:0.021234008252271414\n",
      "train loss:0.019130786764047714\n",
      "train loss:0.024762413680125935\n",
      "train loss:0.0020024556016224205\n",
      "train loss:0.03258157952743391\n",
      "train loss:0.017803822447122003\n",
      "train loss:0.0015325207320863977\n",
      "train loss:0.0015674262781129105\n",
      "train loss:0.004339212181747906\n",
      "train loss:0.0024305626657783693\n",
      "train loss:0.027067736852367075\n",
      "train loss:0.027830255289140043\n",
      "train loss:0.06979167181585656\n",
      "train loss:0.06148134661059136\n",
      "train loss:0.011229270752694791\n",
      "train loss:0.00424506507089164\n",
      "train loss:0.010968257241392325\n",
      "train loss:0.004389821658777054\n",
      "train loss:0.014226569229008366\n",
      "train loss:0.005082870999165938\n",
      "train loss:0.004880780427688247\n",
      "train loss:0.015425928389991373\n",
      "train loss:0.013862956381829723\n",
      "train loss:0.014729267146813226\n",
      "train loss:0.0077285803155659515\n",
      "train loss:0.005892544246523285\n",
      "train loss:0.010960633453221206\n",
      "train loss:0.012820733783801283\n",
      "train loss:0.015284327177150243\n",
      "train loss:0.0019247818452765562\n",
      "train loss:0.009414046966022183\n",
      "train loss:0.004424881736036263\n",
      "train loss:0.0066175647215752495\n",
      "train loss:0.0067784693708636545\n",
      "train loss:0.0024846306066470965\n",
      "train loss:0.012937703445340655\n",
      "train loss:0.005585571331840988\n",
      "train loss:0.005779600879409525\n",
      "train loss:0.0009569046010063181\n",
      "train loss:0.0033107197634611413\n",
      "train loss:0.014078285639177276\n",
      "train loss:0.0036199081738295166\n",
      "train loss:0.00489131759927117\n",
      "train loss:0.003901194701195486\n",
      "train loss:0.023916806003028094\n",
      "train loss:0.003576385252679545\n",
      "train loss:0.0036978476096989543\n",
      "train loss:0.0228527736118237\n",
      "train loss:0.0026438785233968243\n",
      "train loss:0.002185225879287885\n",
      "train loss:0.008159531930171285\n",
      "train loss:0.005125765544600354\n",
      "train loss:0.005847171656773477\n",
      "train loss:0.0033236647092264532\n",
      "train loss:0.0009469630011260549\n",
      "train loss:0.0033956133394440844\n",
      "train loss:0.0006661747471727994\n",
      "train loss:0.004321118009846522\n",
      "train loss:0.004393228798509831\n",
      "train loss:0.0016566970331707038\n",
      "train loss:0.005738029248585096\n",
      "train loss:0.004439640667373951\n",
      "train loss:0.005859298483533047\n",
      "train loss:0.0022875753726779927\n",
      "train loss:0.0026460923619883374\n",
      "train loss:0.020971891240174158\n",
      "train loss:0.00790594712001018\n",
      "train loss:0.005166223736512292\n",
      "train loss:0.0009399473617239994\n",
      "train loss:0.001503326884751435\n",
      "train loss:0.009139306147870216\n",
      "train loss:0.00894839252389079\n",
      "train loss:0.0006467279832001473\n",
      "train loss:0.00101080673728853\n",
      "train loss:0.0005690079007922808\n",
      "train loss:0.0011740804043660095\n",
      "train loss:0.016093082013458403\n",
      "train loss:0.005472253379094016\n",
      "train loss:0.0035270608568454486\n",
      "train loss:0.011344259026472892\n",
      "train loss:0.004377966989097583\n",
      "train loss:0.005016858058311638\n",
      "train loss:0.004349677936126955\n",
      "train loss:0.002492679551869975\n",
      "train loss:0.012863417875131653\n",
      "train loss:0.004599256725774863\n",
      "train loss:0.004419573843372057\n",
      "train loss:0.006530854162080507\n",
      "train loss:0.011195913591260612\n",
      "train loss:0.010983200797005696\n",
      "train loss:0.0014581073764754241\n",
      "train loss:0.03221881201416393\n",
      "train loss:0.004836730602760598\n",
      "train loss:0.02440182732318208\n",
      "train loss:0.0015555022685579457\n",
      "train loss:0.004108969672190134\n",
      "train loss:0.0017858584801162464\n",
      "train loss:0.04357154439564224\n",
      "train loss:0.0031098310791899484\n",
      "train loss:0.002288940169925066\n",
      "train loss:0.0035913561651978675\n",
      "train loss:0.001599519662857933\n",
      "train loss:0.01131550251756476\n",
      "train loss:0.009387299897617926\n",
      "train loss:0.007928114779154399\n",
      "train loss:0.004973108938901139\n",
      "train loss:0.0036452911244157084\n",
      "train loss:0.011200573726411247\n",
      "train loss:0.002073469142389066\n",
      "train loss:0.0021404544492145\n",
      "train loss:0.011026806041803103\n",
      "train loss:0.00490047350196441\n",
      "train loss:0.004041177027047381\n",
      "train loss:0.013023999631870502\n",
      "train loss:0.009349344007691487\n",
      "train loss:0.008048257823071538\n",
      "train loss:0.004191671638142359\n",
      "train loss:0.009484460660674073\n",
      "train loss:0.0054746982319554775\n",
      "train loss:0.0005600765539305086\n",
      "train loss:0.0007079824439410931\n",
      "train loss:0.004462110292045674\n",
      "train loss:0.0036258042661498503\n",
      "train loss:0.03179644945960241\n",
      "train loss:0.0012979474278982548\n",
      "train loss:0.01811653643230794\n",
      "train loss:0.021597981030457607\n",
      "train loss:0.002314115459335621\n",
      "train loss:0.002618855254826613\n",
      "train loss:0.0029062220215717955\n",
      "train loss:0.02721866115914918\n",
      "train loss:0.006608238105830266\n",
      "train loss:0.0022227630890441145\n",
      "train loss:0.006210637459024471\n",
      "train loss:0.01101494728980094\n",
      "train loss:0.019582879656194353\n",
      "train loss:0.008823128089030489\n",
      "train loss:0.018181166803349757\n",
      "train loss:0.002650603511114583\n",
      "train loss:0.004202607699508501\n",
      "train loss:0.0023981018193512515\n",
      "train loss:0.021033139063421892\n",
      "train loss:0.01746096726721138\n",
      "train loss:0.012461437193360469\n",
      "train loss:0.01138722237826331\n",
      "train loss:0.025942871212865738\n",
      "train loss:0.0034622444676441393\n",
      "train loss:0.0033005376575381755\n",
      "train loss:0.0010418888577722995\n",
      "train loss:0.0039217663797141665\n",
      "train loss:0.006310423700054939\n",
      "train loss:0.007574011478783348\n",
      "train loss:0.0038630636666956157\n",
      "train loss:0.0031981839754430348\n",
      "train loss:0.011412419637019404\n",
      "train loss:0.004318170235261989\n",
      "train loss:0.04618299537136804\n",
      "train loss:0.006797982406994547\n",
      "train loss:0.0013724136363769592\n",
      "train loss:0.008808364825841327\n",
      "train loss:0.005598402956271664\n",
      "train loss:0.013039577801409416\n",
      "train loss:0.0017885991580445806\n",
      "train loss:0.0030931286136301585\n",
      "train loss:0.009865305181730262\n",
      "train loss:0.0027421527054464607\n",
      "train loss:0.007173164675832917\n",
      "train loss:0.004064941249317804\n",
      "train loss:0.009140796176162041\n",
      "train loss:0.0206812942380457\n",
      "train loss:0.0033946728980096385\n",
      "train loss:0.002461064657906877\n",
      "train loss:0.020936476589242126\n",
      "train loss:0.002010864194395183\n",
      "train loss:0.025700604670170463\n",
      "train loss:0.003435890201342444\n",
      "train loss:0.0033054275209182566\n",
      "train loss:0.002139308320907964\n",
      "train loss:0.014459907440643396\n",
      "train loss:0.0041136495868502885\n",
      "train loss:0.015416584787323337\n",
      "train loss:0.002952314818185553\n",
      "train loss:0.025439278237597725\n",
      "train loss:0.011870753001142351\n",
      "train loss:0.002062529475141936\n",
      "train loss:0.009638757613934058\n",
      "train loss:0.004843033479646924\n",
      "train loss:0.0028620174035967672\n",
      "train loss:0.0048386858596877\n",
      "train loss:0.0025933338228881398\n",
      "train loss:0.009679220549364211\n",
      "train loss:0.006188782839325597\n",
      "train loss:0.006211305356445328\n",
      "train loss:0.0005846399085524507\n",
      "train loss:0.00481226645518836\n",
      "train loss:0.015467385268935652\n",
      "train loss:0.008854426073402406\n",
      "train loss:0.01728750513651587\n",
      "train loss:0.0012192413829593901\n",
      "train loss:0.0017899527028016953\n",
      "train loss:0.019109019143539838\n",
      "train loss:0.003788765973760057\n",
      "train loss:0.007610154843872463\n",
      "train loss:0.0016763534344759368\n",
      "train loss:0.007957581237833435\n",
      "train loss:0.018065830033450515\n",
      "train loss:0.00046031410367612104\n",
      "train loss:0.042780251693700186\n",
      "train loss:0.004274010940626577\n",
      "train loss:0.013566175478704378\n",
      "train loss:0.015190427225561775\n",
      "train loss:0.0222968622048934\n",
      "train loss:0.015201897713711903\n",
      "train loss:0.011320159712580347\n",
      "train loss:0.0005887332700425101\n",
      "train loss:0.0054617863269806385\n",
      "train loss:0.0026440092240144967\n",
      "train loss:0.007472301721576391\n",
      "train loss:0.006382579646777644\n",
      "train loss:0.01106842864566608\n",
      "train loss:0.0011423539950185225\n",
      "train loss:0.00414015872633661\n",
      "train loss:0.005323044137026089\n",
      "train loss:0.005363402486070927\n",
      "train loss:0.007024266908791763\n",
      "train loss:0.006923613176627735\n",
      "train loss:0.001810299970718006\n",
      "train loss:0.012541958903477852\n",
      "train loss:0.030189850474716298\n",
      "train loss:0.00936679161388978\n",
      "train loss:0.019468694075927395\n",
      "train loss:0.027203155152473495\n",
      "train loss:0.010177164355275293\n",
      "train loss:0.005554816705456322\n",
      "train loss:0.023041556507021475\n",
      "train loss:0.0025864530163970476\n",
      "train loss:0.0021544204632519773\n",
      "train loss:0.005481664235853452\n",
      "train loss:0.005107461931906346\n",
      "train loss:0.006487514137433767\n",
      "train loss:0.008558849854905386\n",
      "train loss:0.002421986283556667\n",
      "train loss:0.0020280024313749454\n",
      "train loss:0.0069493946324037945\n",
      "train loss:0.01076034917363619\n",
      "train loss:0.0136320516568427\n",
      "train loss:0.001937952623380606\n",
      "train loss:0.004570772463171111\n",
      "train loss:0.013922504870843622\n",
      "train loss:0.0005673351311718279\n",
      "train loss:0.01857970030518396\n",
      "train loss:0.01743433275733808\n",
      "train loss:0.00289696368282069\n",
      "train loss:0.0020970896392785003\n",
      "train loss:0.01953180203269465\n",
      "train loss:0.005049933695060793\n",
      "train loss:0.0008294210471117785\n",
      "train loss:0.004239121395823211\n",
      "train loss:0.0016218191616405404\n",
      "train loss:0.005832498665775252\n",
      "train loss:0.0034611611542798987\n",
      "train loss:0.0007854248219539977\n",
      "train loss:0.0028960545602199793\n",
      "train loss:0.06704404221137408\n",
      "train loss:0.009484399231984846\n",
      "train loss:0.003443913418088938\n",
      "train loss:0.006986025171078863\n",
      "train loss:0.003401386645365831\n",
      "train loss:0.0030622122158014005\n",
      "train loss:0.0033146390494653193\n",
      "train loss:0.003946283716159447\n",
      "train loss:0.001873768865511839\n",
      "train loss:0.0009476676418341917\n",
      "train loss:0.002159769858151371\n",
      "train loss:0.00559346693705574\n",
      "train loss:0.006042621838260474\n",
      "train loss:0.004340554483088149\n",
      "train loss:0.06151049339171654\n",
      "train loss:0.00586136745584576\n",
      "train loss:0.003922692155033464\n",
      "train loss:0.0031796140256976253\n",
      "train loss:0.0037211453115923877\n",
      "train loss:0.0013512423547212542\n",
      "train loss:0.01758187878420119\n",
      "train loss:0.006897315719466234\n",
      "train loss:0.028278881364708113\n",
      "train loss:0.011913462703575916\n",
      "train loss:0.0024365749005423763\n",
      "train loss:0.0062479306635525355\n",
      "train loss:0.0032835304665607638\n",
      "train loss:0.002510001239964753\n",
      "train loss:0.010106709558036393\n",
      "train loss:0.010109610072959057\n",
      "train loss:0.001014319624547212\n",
      "train loss:0.002288553327070822\n",
      "train loss:0.007100084611241795\n",
      "train loss:0.025900888502168266\n",
      "train loss:0.002445930071748329\n",
      "train loss:0.0014056479727342585\n",
      "train loss:0.010287938330203819\n",
      "train loss:0.0023062708751473713\n",
      "train loss:0.00336815088650137\n",
      "train loss:0.019402986060309744\n",
      "train loss:0.027681321738035072\n",
      "train loss:0.041682416984291884\n",
      "train loss:0.003646554628662721\n",
      "train loss:0.009003256871554153\n",
      "train loss:0.004764774803563412\n",
      "train loss:0.0358903067503\n",
      "train loss:0.003575283647109674\n",
      "train loss:0.014146657099023694\n",
      "train loss:0.01138277866624628\n",
      "train loss:0.006120629303750867\n",
      "train loss:0.014461315586475563\n",
      "train loss:0.003940417668946091\n",
      "train loss:0.004070754005628231\n",
      "train loss:0.048459741493028285\n",
      "train loss:0.0005446682544715638\n",
      "train loss:0.0025361351955013774\n",
      "train loss:0.006237949289332326\n",
      "train loss:0.01634837359771724\n",
      "train loss:0.016449353129048126\n",
      "train loss:0.014089455775871224\n",
      "train loss:0.0028058018604671564\n",
      "train loss:0.001169535729965131\n",
      "train loss:0.0072414084633381825\n",
      "train loss:0.009787032325741784\n",
      "train loss:0.013486057788582171\n",
      "train loss:0.015844625894336727\n",
      "train loss:0.002495332782627319\n",
      "train loss:0.001433024579939525\n",
      "train loss:0.018272633980025713\n",
      "train loss:0.008357653181613366\n",
      "train loss:0.012690531933268823\n",
      "train loss:0.0021994848450879604\n",
      "train loss:0.001757588888241308\n",
      "train loss:0.006650335722751806\n",
      "train loss:0.00585932730953386\n",
      "train loss:0.001557435539765386\n",
      "train loss:0.002516204170162858\n",
      "train loss:0.023806618486566622\n",
      "train loss:0.0008207673341077983\n",
      "train loss:0.014435834145033657\n",
      "train loss:0.00783274054785481\n",
      "train loss:0.0010196654336894172\n",
      "train loss:0.016267717883541123\n",
      "train loss:0.0058230834593496796\n",
      "train loss:0.005696747879244279\n",
      "train loss:0.004311049296316249\n",
      "train loss:0.010116517311591426\n",
      "train loss:0.014556855568549389\n",
      "train loss:0.0202854525809464\n",
      "train loss:0.007703746681177686\n",
      "train loss:0.0004938865160854099\n",
      "train loss:0.005125397416140936\n",
      "train loss:0.002768952960027332\n",
      "train loss:0.026917216883833407\n",
      "train loss:0.014904011133768\n",
      "train loss:0.01714244697436541\n",
      "train loss:0.017109267162205823\n",
      "train loss:0.00828668338747222\n",
      "train loss:0.02285242747705488\n",
      "train loss:0.0026853317716935125\n",
      "train loss:0.0011379626049959012\n",
      "train loss:0.0015409752079523908\n",
      "train loss:0.002205127642306598\n",
      "train loss:0.0012510927487729493\n",
      "train loss:0.006810415600924673\n",
      "train loss:0.0038096996419253793\n",
      "train loss:0.015359084728404764\n",
      "train loss:0.02387450917664543\n",
      "train loss:0.0063263864446635254\n",
      "train loss:0.0025204474970767555\n",
      "train loss:0.002555604699762989\n",
      "train loss:0.007714530125385373\n",
      "train loss:0.010891065558337916\n",
      "train loss:0.017974488394959354\n",
      "train loss:0.01112818844643503\n",
      "train loss:0.008349934241113698\n",
      "train loss:0.005274117915061261\n",
      "train loss:0.00425181709161619\n",
      "train loss:0.010479905423890733\n",
      "train loss:0.009348620840956083\n",
      "train loss:0.0038939741942050172\n",
      "train loss:0.012728366328830017\n",
      "train loss:0.0028190999604592475\n",
      "train loss:0.003529865851626375\n",
      "train loss:0.007445367690004242\n",
      "train loss:0.005902798209599633\n",
      "train loss:0.0012736824813369407\n",
      "train loss:0.00608608467178441\n",
      "train loss:0.003629748865676782\n",
      "train loss:0.0030482789561152314\n",
      "train loss:0.007177825015132386\n",
      "train loss:0.010114808449052912\n",
      "train loss:0.004396702567810367\n",
      "train loss:0.0014897005610607869\n",
      "train loss:0.015832797330359777\n",
      "train loss:0.002193717294001819\n",
      "train loss:0.004529377033764963\n",
      "train loss:0.005997896649910258\n",
      "train loss:0.0013593084494975783\n",
      "train loss:0.0032969497205844857\n",
      "train loss:0.0010169006859208022\n",
      "train loss:0.016047128310791938\n",
      "train loss:0.004313939831331598\n",
      "train loss:0.011281272316629036\n",
      "train loss:0.0072907169007914\n",
      "train loss:0.0044996559359064036\n",
      "train loss:0.008213762506562814\n",
      "train loss:0.008971240859871183\n",
      "train loss:0.0052167538908235375\n",
      "train loss:0.003368752307829619\n",
      "=== epoch:11, train acc:0.992, test acc:0.985 ===\n",
      "train loss:0.002768482734590491\n",
      "train loss:0.025722068206345785\n",
      "train loss:0.008222597604417075\n",
      "train loss:0.005418815608759234\n",
      "train loss:0.002155344602568051\n",
      "train loss:0.010217813217955951\n",
      "train loss:0.004214960369410872\n",
      "train loss:0.0021935730844785907\n",
      "train loss:0.005034922178116435\n",
      "train loss:0.005486407595877846\n",
      "train loss:0.024238212932411365\n",
      "train loss:0.0036950712661872475\n",
      "train loss:0.0010452584286786359\n",
      "train loss:0.0058215495367157115\n",
      "train loss:0.007307244392912488\n",
      "train loss:0.00220698615178509\n",
      "train loss:0.0022291328623519594\n",
      "train loss:0.004147968448700416\n",
      "train loss:0.0056931969002723595\n",
      "train loss:0.006833852827438447\n",
      "train loss:0.011356151935001517\n",
      "train loss:0.014691513087441089\n",
      "train loss:0.0017090011144761303\n",
      "train loss:0.004406529530986067\n",
      "train loss:0.00409625487466726\n",
      "train loss:0.004408808339853495\n",
      "train loss:0.0020742170888300147\n",
      "train loss:0.012477425568513487\n",
      "train loss:0.015140101482707346\n",
      "train loss:0.0033742120138892965\n",
      "train loss:0.006922118748149908\n",
      "train loss:0.003964789364320168\n",
      "train loss:0.0009141656488529747\n",
      "train loss:0.004082063775674868\n",
      "train loss:0.002691473083448444\n",
      "train loss:0.0019457088462079472\n",
      "train loss:0.012944024601823706\n",
      "train loss:0.0073923005101583636\n",
      "train loss:0.004820829900498334\n",
      "train loss:0.0064959833434018\n",
      "train loss:0.00840978349714229\n",
      "train loss:0.00867623794235703\n",
      "train loss:0.003332730247654637\n",
      "train loss:0.0076344416894014765\n",
      "train loss:0.0015656941809191285\n",
      "train loss:0.0054770273417216785\n",
      "train loss:0.0008526524776216024\n",
      "train loss:0.01603025962779797\n",
      "train loss:0.0027754378384523067\n",
      "train loss:0.004732061661797264\n",
      "train loss:0.0027885871379757675\n",
      "train loss:0.007740845253405673\n",
      "train loss:0.004103082830643364\n",
      "train loss:0.01075110385014815\n",
      "train loss:0.007227741703751012\n",
      "train loss:0.009945206658810076\n",
      "train loss:0.0009499260279872475\n",
      "train loss:0.020345748011556607\n",
      "train loss:0.001709552348634663\n",
      "train loss:0.0026493838062115276\n",
      "train loss:0.001118759835011362\n",
      "train loss:0.0027480085846520686\n",
      "train loss:0.004066854242604117\n",
      "train loss:0.01997191536093935\n",
      "train loss:0.008302233548685997\n",
      "train loss:0.002413385912752978\n",
      "train loss:0.006007538117212148\n",
      "train loss:0.0019056099278007901\n",
      "train loss:0.019386415323273343\n",
      "train loss:0.007019688978481555\n",
      "train loss:0.024744437958120657\n",
      "train loss:0.0036942574614233655\n",
      "train loss:0.04537987285786091\n",
      "train loss:0.003197050665350367\n",
      "train loss:0.008374073220091222\n",
      "train loss:0.005981205445339715\n",
      "train loss:0.003554893883476307\n",
      "train loss:0.0065870212853537755\n",
      "train loss:0.007623840851695197\n",
      "train loss:0.008837141677911711\n",
      "train loss:0.005528379757679919\n",
      "train loss:0.016309802404558402\n",
      "train loss:0.005437393110259918\n",
      "train loss:0.0025849083472294756\n",
      "train loss:0.006037179002676544\n",
      "train loss:0.008149684716737772\n",
      "train loss:0.00403915937503947\n",
      "train loss:0.002582254449362323\n",
      "train loss:0.0942807596255066\n",
      "train loss:0.011148060840612001\n",
      "train loss:0.0007559187902151213\n",
      "train loss:0.0012923177804703531\n",
      "train loss:0.004420228404986012\n",
      "train loss:0.009405669285649626\n",
      "train loss:0.0014243543271915088\n",
      "train loss:0.011001120894094307\n",
      "train loss:0.002675688347854784\n",
      "train loss:0.0048117215534700325\n",
      "train loss:0.0032274238992623535\n",
      "train loss:0.0019801177291087495\n",
      "train loss:0.008865239251542747\n",
      "train loss:0.0007076091489766484\n",
      "train loss:0.005697050161195451\n",
      "train loss:0.012599363638542433\n",
      "train loss:0.004188217874224891\n",
      "train loss:0.0013068393851053894\n",
      "train loss:0.005823711659797658\n",
      "train loss:0.0014529850562774462\n",
      "train loss:0.022669492624896564\n",
      "train loss:0.004751708792638929\n",
      "train loss:0.004242339856178214\n",
      "train loss:0.0014695322292613442\n",
      "train loss:0.010041874432182461\n",
      "train loss:0.011610883989144583\n",
      "train loss:0.0015093689037900884\n",
      "train loss:0.0017084750657891253\n",
      "train loss:0.003915163605627411\n",
      "train loss:0.021767180704320044\n",
      "train loss:0.03753690650130043\n",
      "train loss:0.0014615951175576613\n",
      "train loss:0.049859333398469374\n",
      "train loss:0.006140225177188204\n",
      "train loss:0.008800197296301927\n",
      "train loss:0.0017179461567576127\n",
      "train loss:0.006873424433098696\n",
      "train loss:0.0036155948179821358\n",
      "train loss:0.03344617399499221\n",
      "train loss:0.0005337365705980362\n",
      "train loss:0.0015872518774754654\n",
      "train loss:0.004441293146327119\n",
      "train loss:0.004529821779724449\n",
      "train loss:0.025646222723262405\n",
      "train loss:0.00798473115688408\n",
      "train loss:0.003495757106339483\n",
      "train loss:0.0025265676074579936\n",
      "train loss:0.014065071954835771\n",
      "train loss:0.0017411348851398558\n",
      "train loss:0.010835678723544207\n",
      "train loss:0.007128928138820287\n",
      "train loss:0.008172105454855931\n",
      "train loss:0.009208664717925107\n",
      "train loss:0.03482041781523558\n",
      "train loss:0.004679807443732561\n",
      "train loss:0.004394908084379184\n",
      "train loss:0.009755187834722177\n",
      "train loss:0.0034770342853433166\n",
      "train loss:0.005351701901108912\n",
      "train loss:0.005317976471258066\n",
      "train loss:0.005462172958519871\n",
      "train loss:0.008788089875179032\n",
      "train loss:0.003525942766618541\n",
      "train loss:0.0074923564554293075\n",
      "train loss:0.0016890352308885927\n",
      "train loss:0.0009934373453051103\n",
      "train loss:0.00393200738591161\n",
      "train loss:0.04168571326937624\n",
      "train loss:0.003517532409844266\n",
      "train loss:0.007274961618951165\n",
      "train loss:0.020617387534648077\n",
      "train loss:0.0038078037056352328\n",
      "train loss:0.0053992080048695015\n",
      "train loss:0.0014782306821818352\n",
      "train loss:0.0028235064732884925\n",
      "train loss:0.006162228862123951\n",
      "train loss:0.0008886612401845759\n",
      "train loss:0.002948177006528816\n",
      "train loss:0.002997222029822392\n",
      "train loss:0.0007829063607685239\n",
      "train loss:0.0076885803384060215\n",
      "train loss:0.005312762917478751\n",
      "train loss:0.0466962317980703\n",
      "train loss:0.03162111665313307\n",
      "train loss:0.007759200303865518\n",
      "train loss:0.005535265040331181\n",
      "train loss:0.0044552578428852805\n",
      "train loss:0.0021480980827693922\n",
      "train loss:0.008047286584407759\n",
      "train loss:0.002585275775909261\n",
      "train loss:0.0005102746918217385\n",
      "train loss:0.003653574053377941\n",
      "train loss:0.005994411839465025\n",
      "train loss:0.025827492628901733\n",
      "train loss:0.007192897140003551\n",
      "train loss:0.00605766005731381\n",
      "train loss:0.006129718686592777\n",
      "train loss:0.005828681316692741\n",
      "train loss:0.00216128840537644\n",
      "train loss:0.013757955495205067\n",
      "train loss:0.01045731659878179\n",
      "train loss:0.006350672412284602\n",
      "train loss:0.003349757836502321\n",
      "train loss:0.013457545527588521\n",
      "train loss:0.0037835743308481714\n",
      "train loss:0.007547493582442961\n",
      "train loss:0.0059923650108583025\n",
      "train loss:0.003356479359170861\n",
      "train loss:0.001718668150888317\n",
      "train loss:0.009316367669962033\n",
      "train loss:0.009994884040264935\n",
      "train loss:0.0017453567532930414\n",
      "train loss:0.0067586393671828626\n",
      "train loss:0.0022918255269745572\n",
      "train loss:0.0025180810342374255\n",
      "train loss:0.00529733074958892\n",
      "train loss:0.06490323011330563\n",
      "train loss:0.0036135601398324594\n",
      "train loss:0.0013614122076690697\n",
      "train loss:0.004593947858140274\n",
      "train loss:0.0020461922240246734\n",
      "train loss:0.022927914235307507\n",
      "train loss:0.0007338965280702529\n",
      "train loss:0.002633805176168193\n",
      "train loss:0.009141155956074497\n",
      "train loss:0.004199196183107467\n",
      "train loss:0.0034913671789339835\n",
      "train loss:0.003226270366687145\n",
      "train loss:0.004718592839790816\n",
      "train loss:0.06611743076411464\n",
      "train loss:0.002718876387180196\n",
      "train loss:0.006108773766835833\n",
      "train loss:0.00044299756134366007\n",
      "train loss:0.005948520957552141\n",
      "train loss:0.0521858136614752\n",
      "train loss:0.005122115752045463\n",
      "train loss:0.0017814841308867852\n",
      "train loss:0.025764550996696868\n",
      "train loss:0.001448188116459074\n",
      "train loss:0.005849402541670006\n",
      "train loss:0.0025108190675876526\n",
      "train loss:0.0007928537318645909\n",
      "train loss:0.022517457570844626\n",
      "train loss:0.007195172212231522\n",
      "train loss:0.010521182381186753\n",
      "train loss:0.00543077312648671\n",
      "train loss:0.010380412206634613\n",
      "train loss:0.0019020964917966518\n",
      "train loss:0.0015162045374681168\n",
      "train loss:0.007910832346443644\n",
      "train loss:0.012763852463715572\n",
      "train loss:0.002867248907037803\n",
      "train loss:0.003417683859486295\n",
      "train loss:0.0038476917052931957\n",
      "train loss:0.006636115869742223\n",
      "train loss:0.008760214452717347\n",
      "train loss:0.008304444782652423\n",
      "train loss:0.0029461229710110175\n",
      "train loss:0.007574647878255536\n",
      "train loss:0.007890598511375586\n",
      "train loss:0.00100505080171598\n",
      "train loss:0.006414883761194807\n",
      "train loss:0.0028178076847045304\n",
      "train loss:0.004919652855750898\n",
      "train loss:0.005952352187969107\n",
      "train loss:0.0015440298386473691\n",
      "train loss:0.001566744317590337\n",
      "train loss:0.0027951528772732683\n",
      "train loss:0.005922864454269147\n",
      "train loss:0.0015634139014059278\n",
      "train loss:0.008400836556482329\n",
      "train loss:0.001188607607713265\n",
      "train loss:0.001662340204467109\n",
      "train loss:0.03617669580689829\n",
      "train loss:0.016854113992370308\n",
      "train loss:0.0008930975551915032\n",
      "train loss:0.0012893035432071614\n",
      "train loss:0.004824125954866614\n",
      "train loss:0.006237619864208998\n",
      "train loss:0.003484998162278677\n",
      "train loss:0.016571334467097427\n",
      "train loss:0.005627039681740974\n",
      "train loss:0.004030168143810354\n",
      "train loss:0.0038100201221854383\n",
      "train loss:0.002566182091362933\n",
      "train loss:0.0060105335068891905\n",
      "train loss:0.0013626359772296501\n",
      "train loss:0.006216625596187011\n",
      "train loss:0.019084304092098672\n",
      "train loss:0.0029396654445748923\n",
      "train loss:0.0324517508611617\n",
      "train loss:0.0013097714376677358\n",
      "train loss:0.0120307009243687\n",
      "train loss:0.00993341479932567\n",
      "train loss:0.004338836322165278\n",
      "train loss:0.013959731632694768\n",
      "train loss:0.009839115501484365\n",
      "train loss:0.0027620342423622856\n",
      "train loss:0.0004456293512936612\n",
      "train loss:0.002493450414752645\n",
      "train loss:0.018710342898556838\n",
      "train loss:0.013742581250511254\n",
      "train loss:0.007170114024748303\n",
      "train loss:0.01156499504148241\n",
      "train loss:0.0063690980505739965\n",
      "train loss:0.005697746445049144\n",
      "train loss:0.027223592339228393\n",
      "train loss:0.009142775794420056\n",
      "train loss:0.003871592891321886\n",
      "train loss:0.0030336010554396185\n",
      "train loss:0.0015546417401513368\n",
      "train loss:0.0015256628671971412\n",
      "train loss:0.010092010870983043\n",
      "train loss:0.016195846372220227\n",
      "train loss:0.0040433578666274825\n",
      "train loss:0.0021850436146226607\n",
      "train loss:0.006559397873067831\n",
      "train loss:0.009681000744623471\n",
      "train loss:0.01828337785028558\n",
      "train loss:0.0005801963330223432\n",
      "train loss:0.0016524700663607117\n",
      "train loss:0.0013191709714268295\n",
      "train loss:0.004233931713319847\n",
      "train loss:0.0024589198108151346\n",
      "train loss:0.0010883470600061807\n",
      "train loss:0.0034507504009105134\n",
      "train loss:0.0027137828346063698\n",
      "train loss:0.03719614492673619\n",
      "train loss:0.005645670122430224\n",
      "train loss:0.005283138298296096\n",
      "train loss:0.001983785276743154\n",
      "train loss:0.0031385078697243733\n",
      "train loss:0.011206987834067468\n",
      "train loss:0.03424350911198365\n",
      "train loss:0.0004908877454878756\n",
      "train loss:0.0032476612779260873\n",
      "train loss:0.002252770134123984\n",
      "train loss:0.0020330290438628387\n",
      "train loss:0.0014295373169449421\n",
      "train loss:0.0007960747360386881\n",
      "train loss:0.016598649673339756\n",
      "train loss:0.003726001562680123\n",
      "train loss:0.00601679596819632\n",
      "train loss:0.009155147237399061\n",
      "train loss:0.02830450409186388\n",
      "train loss:0.002660170476814006\n",
      "train loss:0.004170849309768139\n",
      "train loss:0.00881132885789079\n",
      "train loss:0.0011215753980686463\n",
      "train loss:0.010598089649102116\n",
      "train loss:0.022138196817346266\n",
      "train loss:0.010434032393988345\n",
      "train loss:0.03470991005038533\n",
      "train loss:0.003009398974438751\n",
      "train loss:0.0017588970285364993\n",
      "train loss:0.013441732043974136\n",
      "train loss:0.05659718145412955\n",
      "train loss:0.0006919508586774474\n",
      "train loss:0.0017504122845702877\n",
      "train loss:0.006154813584993598\n",
      "train loss:0.0078039305121447465\n",
      "train loss:0.0010645608929664562\n",
      "train loss:0.020058625865983754\n",
      "train loss:0.001066703551862392\n",
      "train loss:0.04223806260965987\n",
      "train loss:0.004756126076694499\n",
      "train loss:0.0013806513677697729\n",
      "train loss:0.00022004936605637428\n",
      "train loss:0.006954202934860753\n",
      "train loss:0.0010722310961053568\n",
      "train loss:0.010901696406854988\n",
      "train loss:0.01843723801143837\n",
      "train loss:0.0006295442186758559\n",
      "train loss:0.00974683128018386\n",
      "train loss:0.005103834485069641\n",
      "train loss:0.006997324599969332\n",
      "train loss:0.011384121889007854\n",
      "train loss:0.014062705675401991\n",
      "train loss:0.00525053353185286\n",
      "train loss:0.003305536300991287\n",
      "train loss:0.025880204875139604\n",
      "train loss:0.0015311706470557318\n",
      "train loss:0.005653500944780291\n",
      "train loss:0.004049129407217203\n",
      "train loss:0.006295185562132657\n",
      "train loss:0.007588926696541947\n",
      "train loss:0.0017474919654814236\n",
      "train loss:0.002799866894561834\n",
      "train loss:0.009753589275302198\n",
      "train loss:0.0035233025218523056\n",
      "train loss:0.003517096985703383\n",
      "train loss:0.020080681488078997\n",
      "train loss:0.002429379534162642\n",
      "train loss:0.00030751303973409506\n",
      "train loss:0.004274629816089423\n",
      "train loss:0.005224295474024428\n",
      "train loss:0.0011307905683353649\n",
      "train loss:0.0031192621025455504\n",
      "train loss:0.011842704931453276\n",
      "train loss:0.0024242634579987915\n",
      "train loss:0.008433581756776972\n",
      "train loss:0.006357480144267807\n",
      "train loss:0.002632479432764917\n",
      "train loss:0.0031544455550237107\n",
      "train loss:0.0026644941903811274\n",
      "train loss:0.0002238871071651543\n",
      "train loss:0.0019041787500107136\n",
      "train loss:0.0011720945099976793\n",
      "train loss:0.006507933212938965\n",
      "train loss:0.0045505751448680545\n",
      "train loss:0.0003992016284925775\n",
      "train loss:0.017634235551172658\n",
      "train loss:0.00900017105840823\n",
      "train loss:0.0011771475400908264\n",
      "train loss:0.0006919627348354285\n",
      "train loss:0.008467022417299457\n",
      "train loss:0.0022877004214091287\n",
      "train loss:0.0009305233469558159\n",
      "train loss:0.003164461533733493\n",
      "train loss:0.003559816334640593\n",
      "train loss:0.001320692351768297\n",
      "train loss:0.002524821967390789\n",
      "train loss:0.0006233262127508538\n",
      "train loss:0.0015403493709195124\n",
      "train loss:0.028164420814838068\n",
      "train loss:0.013588586680781225\n",
      "train loss:0.0035721999972790535\n",
      "train loss:0.0020625172910522503\n",
      "train loss:0.0008102024423775671\n",
      "train loss:0.0009157227708299734\n",
      "train loss:0.01404922863179617\n",
      "train loss:0.006471433717488301\n",
      "train loss:0.006221659283081753\n",
      "train loss:0.005400459921335079\n",
      "train loss:0.005187485783328589\n",
      "train loss:0.004899139362130352\n",
      "train loss:0.002393375094951617\n",
      "train loss:0.002028292248647334\n",
      "train loss:0.02997732290392106\n",
      "train loss:0.0008165183617050559\n",
      "train loss:0.0073648705389282336\n",
      "train loss:0.002439741993363194\n",
      "train loss:0.07553549575305381\n",
      "train loss:0.007185742026929695\n",
      "train loss:0.004870576830435562\n",
      "train loss:0.004372379287668104\n",
      "train loss:0.0017941981147063333\n",
      "train loss:0.004623400373409334\n",
      "train loss:0.0013682243390018614\n",
      "train loss:0.0076417656603254384\n",
      "train loss:0.0004362338437470191\n",
      "train loss:0.004266760079579329\n",
      "train loss:0.005149248279174949\n",
      "train loss:0.011792990054462821\n",
      "train loss:0.013922122976233204\n",
      "train loss:0.0023543295781998114\n",
      "train loss:0.003666434205322077\n",
      "train loss:0.011222957790142683\n",
      "train loss:0.0005204690482154692\n",
      "train loss:0.001827993840286816\n",
      "train loss:0.004741369287814096\n",
      "train loss:0.0004474064380267076\n",
      "train loss:0.01220108359248071\n",
      "train loss:0.0006520508264555016\n",
      "train loss:0.0026367798945003762\n",
      "train loss:0.0007170075097409326\n",
      "train loss:0.000645038288929663\n",
      "train loss:0.0167833248481203\n",
      "train loss:0.0011930615435025256\n",
      "train loss:0.0009686476217817868\n",
      "train loss:0.007081722411357755\n",
      "train loss:0.007353218240910509\n",
      "train loss:0.004054118299988275\n",
      "train loss:0.005476064425493036\n",
      "train loss:0.004226103936904982\n",
      "train loss:0.025419835967686547\n",
      "train loss:0.002029794989073046\n",
      "train loss:0.014737925391757993\n",
      "train loss:0.0007638789901511314\n",
      "train loss:0.0017845280796516339\n",
      "train loss:0.004501926673661099\n",
      "train loss:0.0054784441881724575\n",
      "train loss:0.012570821715123439\n",
      "train loss:0.006844875072383309\n",
      "train loss:0.004812674034564114\n",
      "train loss:0.00351061801784529\n",
      "train loss:0.0048423931807646285\n",
      "train loss:0.006875893522331812\n",
      "train loss:0.0038371327292997214\n",
      "train loss:0.006555025298650044\n",
      "train loss:0.00284799280749538\n",
      "train loss:0.004581062522797778\n",
      "train loss:0.001457594397330963\n",
      "train loss:0.001338449981105584\n",
      "train loss:0.016216806041734092\n",
      "train loss:0.0014697030617662485\n",
      "train loss:0.018428551345688153\n",
      "train loss:0.000878808998246289\n",
      "train loss:0.017671700908685473\n",
      "train loss:0.007817702952622282\n",
      "train loss:0.010087787055027742\n",
      "train loss:0.012425980908451565\n",
      "train loss:0.0013189505784739002\n",
      "train loss:0.004246801514291969\n",
      "train loss:0.0020992315585686436\n",
      "train loss:0.0024674542239271876\n",
      "train loss:0.009574013834487125\n",
      "train loss:0.005980562089174052\n",
      "train loss:0.007776238079872705\n",
      "train loss:0.002328684696460319\n",
      "train loss:0.008030039595508128\n",
      "train loss:0.0340197349386947\n",
      "train loss:0.05407444062190124\n",
      "train loss:0.005116401273184424\n",
      "train loss:0.011300084758494665\n",
      "train loss:0.0029762560407660087\n",
      "train loss:0.0017212605308936032\n",
      "train loss:0.0006945430256552768\n",
      "train loss:0.0010834845924844664\n",
      "train loss:0.002241837125356843\n",
      "train loss:0.011788826187341492\n",
      "train loss:0.0029757975259854298\n",
      "train loss:0.007417867825588318\n",
      "train loss:0.010458488384381268\n",
      "train loss:0.00799524043193456\n",
      "train loss:0.026046722055159188\n",
      "train loss:0.10388406326333886\n",
      "train loss:0.002448751869378025\n",
      "train loss:0.003756427419806571\n",
      "train loss:0.0033099814015676416\n",
      "train loss:0.011512711601924908\n",
      "train loss:0.0060678916492721904\n",
      "train loss:0.002142263455301074\n",
      "train loss:0.019783466260509537\n",
      "train loss:0.002406581757786744\n",
      "train loss:0.005207701295019692\n",
      "train loss:0.002430066625067261\n",
      "train loss:0.0015804866453700756\n",
      "train loss:0.0055208537510652\n",
      "train loss:0.005781495552345799\n",
      "train loss:0.0056495335603753616\n",
      "train loss:0.00325368308957851\n",
      "train loss:0.00602889373707439\n",
      "train loss:0.0040142720121693195\n",
      "train loss:0.006594791918484427\n",
      "train loss:0.005655136140684183\n",
      "train loss:0.0007431287074310362\n",
      "train loss:0.016876076576913455\n",
      "train loss:0.03415063108314486\n",
      "train loss:0.003572645134910919\n",
      "train loss:0.011344767174046016\n",
      "train loss:0.0040479026393486425\n",
      "train loss:0.0022421873055623546\n",
      "train loss:0.0034742717684744977\n",
      "train loss:0.005819785703860363\n",
      "train loss:0.002106615431276981\n",
      "train loss:0.008987303478850732\n",
      "train loss:0.0006530047896264434\n",
      "train loss:0.00977161433110021\n",
      "train loss:0.009850844984651884\n",
      "train loss:0.0025047384677209833\n",
      "train loss:0.004126098482392253\n",
      "train loss:0.0031681265912320644\n",
      "train loss:0.0042101567433943535\n",
      "train loss:0.004365605129636388\n",
      "train loss:0.003135465967323408\n",
      "train loss:0.007219979127866705\n",
      "train loss:0.002089034023298311\n",
      "train loss:0.0005341693856795675\n",
      "train loss:0.0032817874566745593\n",
      "train loss:0.0019324806868819405\n",
      "train loss:0.00395149548341334\n",
      "train loss:0.009905520743534915\n",
      "train loss:0.006107998881874478\n",
      "train loss:0.0036125903175675787\n",
      "train loss:0.027514429271347535\n",
      "train loss:0.005213194111331262\n",
      "train loss:0.004019982650181216\n",
      "train loss:0.014227292938534362\n",
      "train loss:0.005793519417085109\n",
      "train loss:0.0006449533426963381\n",
      "train loss:0.0007450335605122498\n",
      "train loss:0.004038133659159837\n",
      "train loss:0.0014836803814266839\n",
      "train loss:0.002534281646435957\n",
      "train loss:0.00412368435416324\n",
      "train loss:0.00603472227776729\n",
      "train loss:0.001602588124012943\n",
      "train loss:0.001930532452793495\n",
      "train loss:0.0001534379709067181\n",
      "train loss:0.0014946775623006917\n",
      "train loss:0.00804263679706727\n",
      "train loss:0.007095967363010126\n",
      "train loss:0.0021113257277066526\n",
      "train loss:0.005582676836728103\n",
      "train loss:0.0022715065159622013\n",
      "train loss:0.010642257089639798\n",
      "train loss:0.002890683314892763\n",
      "train loss:0.001039373222308063\n",
      "train loss:0.0060638285271891\n",
      "train loss:0.002914047844445834\n",
      "train loss:0.00628690957586202\n",
      "train loss:0.0036961736110191087\n",
      "train loss:0.0011959278776051984\n",
      "train loss:0.001354555847050001\n",
      "train loss:0.001885736373709867\n",
      "train loss:0.002170773459316269\n",
      "train loss:0.0019554095546755355\n",
      "train loss:0.001026835345078866\n",
      "train loss:0.0015548604503403578\n",
      "train loss:0.006579884545408623\n",
      "train loss:0.0023226722335948774\n",
      "=== epoch:12, train acc:0.997, test acc:0.984 ===\n",
      "train loss:0.005463383670203285\n",
      "train loss:0.002451311393772089\n",
      "train loss:0.007088897667508202\n",
      "train loss:0.003922485204491017\n",
      "train loss:0.004234096267698858\n",
      "train loss:0.0012638021965804237\n",
      "train loss:0.0006923721176833081\n",
      "train loss:0.0026918464577908325\n",
      "train loss:0.007376063635480102\n",
      "train loss:0.0016390675261017664\n",
      "train loss:0.0014956928336164973\n",
      "train loss:0.004319086834076025\n",
      "train loss:0.005588965916924189\n",
      "train loss:0.0024421522126798273\n",
      "train loss:0.007914209207907509\n",
      "train loss:0.008806292818477907\n",
      "train loss:0.0026985148375202207\n",
      "train loss:0.0016721059833330176\n",
      "train loss:0.006989442037132697\n",
      "train loss:0.0020681487019575417\n",
      "train loss:0.02516374479848176\n",
      "train loss:0.0014127501373805132\n",
      "train loss:0.002569838733902316\n",
      "train loss:0.0024111386107042803\n",
      "train loss:0.004287512576964934\n",
      "train loss:0.004107470094185752\n",
      "train loss:0.008684049302504675\n",
      "train loss:0.005963985742754162\n",
      "train loss:0.00266546174722721\n",
      "train loss:0.0015100365189494723\n",
      "train loss:0.012145792673458953\n",
      "train loss:0.0005600488464734825\n",
      "train loss:0.07390822637777655\n",
      "train loss:0.0055469666238156905\n",
      "train loss:0.002764535730214419\n",
      "train loss:0.004106759481860939\n",
      "train loss:0.011254524981576483\n",
      "train loss:0.004683151063500964\n",
      "train loss:0.007788634307520277\n",
      "train loss:0.012076699487895661\n",
      "train loss:0.0021644534184586013\n",
      "train loss:0.0007544059284416405\n",
      "train loss:0.005833164684148831\n",
      "train loss:0.014643136295556263\n",
      "train loss:0.0035842325151703163\n",
      "train loss:0.001413777470042509\n",
      "train loss:0.0018317010090400407\n",
      "train loss:0.004359775510006842\n",
      "train loss:0.0011171331975040793\n",
      "train loss:0.010858734262959246\n",
      "train loss:0.0010560278230578597\n",
      "train loss:0.005449688485691903\n",
      "train loss:0.006944095302447074\n",
      "train loss:0.0040403997521408245\n",
      "train loss:0.006218650989036187\n",
      "train loss:0.01886759107785109\n",
      "train loss:0.023192182227605315\n",
      "train loss:0.01062795238828167\n",
      "train loss:0.03247512704431303\n",
      "train loss:0.0014978781564450136\n",
      "train loss:0.011520198548711351\n",
      "train loss:0.008857050998506321\n",
      "train loss:0.0028413990367803493\n",
      "train loss:0.0020727446556166066\n",
      "train loss:0.007014891855000232\n",
      "train loss:0.007421309914655566\n",
      "train loss:0.0044305172573899845\n",
      "train loss:0.002477759775498176\n",
      "train loss:0.009713577917001132\n",
      "train loss:0.0040429119806430144\n",
      "train loss:0.009119912446533516\n",
      "train loss:0.005874246654380537\n",
      "train loss:0.005214349359722105\n",
      "train loss:0.001975818213613053\n",
      "train loss:0.0008614744419176616\n",
      "train loss:0.001352581473098297\n",
      "train loss:0.01872932259375375\n",
      "train loss:0.0014671304643376227\n",
      "train loss:0.005462316544154803\n",
      "train loss:0.0031490119029372737\n",
      "train loss:0.0018327394369375288\n",
      "train loss:0.000592977395723392\n",
      "train loss:0.002461238483515125\n",
      "train loss:0.0012784615028210919\n",
      "train loss:0.004595399084762189\n",
      "train loss:0.001044460819870563\n",
      "train loss:0.010491625944440489\n",
      "train loss:0.002490456514388669\n",
      "train loss:0.002524582978271638\n",
      "train loss:0.0008970670908512937\n",
      "train loss:0.008210659534840794\n",
      "train loss:0.003676485699199381\n",
      "train loss:0.008130927528281507\n",
      "train loss:0.0014553451506568581\n",
      "train loss:0.002098520383970377\n",
      "train loss:0.006659646636588936\n",
      "train loss:0.002782673244499944\n",
      "train loss:0.003806244849264155\n",
      "train loss:0.0011225480896001185\n",
      "train loss:0.004747405316949461\n",
      "train loss:0.0031270382936169575\n",
      "train loss:0.0004931422902249809\n",
      "train loss:0.0010927009507782808\n",
      "train loss:0.005570816984648237\n",
      "train loss:0.013570088726952988\n",
      "train loss:0.007847397159877721\n",
      "train loss:0.016712333958948337\n",
      "train loss:0.0030334586419089394\n",
      "train loss:0.0017288043483751404\n",
      "train loss:0.004962698324472672\n",
      "train loss:0.009228452217930578\n",
      "train loss:0.0022972373651892262\n",
      "train loss:0.0019553644715088\n",
      "train loss:0.0252723951312267\n",
      "train loss:0.0030857310160934638\n",
      "train loss:0.0019787342942961255\n",
      "train loss:0.00030453931187143205\n",
      "train loss:0.01573521420495562\n",
      "train loss:0.03372872425560497\n",
      "train loss:0.009333876959630309\n",
      "train loss:0.007566961784256143\n",
      "train loss:0.000719449995681159\n",
      "train loss:0.001255935542775345\n",
      "train loss:0.05464310116291162\n",
      "train loss:0.002021935840895781\n",
      "train loss:0.0010474449710690427\n",
      "train loss:0.000572836275736268\n",
      "train loss:0.0002543716256211182\n",
      "train loss:0.004306166151677664\n",
      "train loss:0.016411396164667566\n",
      "train loss:0.002721521974992524\n",
      "train loss:0.005862409763605772\n",
      "train loss:0.0009531993637726087\n",
      "train loss:0.005701838035193949\n",
      "train loss:0.0388880289746076\n",
      "train loss:0.006260177972087753\n",
      "train loss:0.0052185917778981815\n",
      "train loss:0.004994336716731006\n",
      "train loss:0.013373871921302925\n",
      "train loss:0.0009392362061251467\n",
      "train loss:0.002572552523727857\n",
      "train loss:0.001259073094879362\n",
      "train loss:0.005794631621620457\n",
      "train loss:0.016885350111760965\n",
      "train loss:0.002028750302622672\n",
      "train loss:0.0043942383743865885\n",
      "train loss:0.000870105450951938\n",
      "train loss:0.005869522824223296\n",
      "train loss:0.0011025090835637818\n",
      "train loss:0.001567379052773031\n",
      "train loss:0.004947888714244014\n",
      "train loss:0.0016791304069075962\n",
      "train loss:0.0033178743064147705\n",
      "train loss:0.04275418982659633\n",
      "train loss:0.0003316709657213241\n",
      "train loss:0.0009713799090337979\n",
      "train loss:0.002255232799316946\n",
      "train loss:0.00270385405639296\n",
      "train loss:0.002200100160935022\n",
      "train loss:0.001220235603436982\n",
      "train loss:0.01895448385067761\n",
      "train loss:0.0033067083720921286\n",
      "train loss:0.002882639106798473\n",
      "train loss:0.0015160338464636897\n",
      "train loss:0.003817429224392412\n",
      "train loss:0.007321682495793915\n",
      "train loss:0.003497938728487391\n",
      "train loss:0.001852857695491945\n",
      "train loss:0.0019146721159226804\n",
      "train loss:0.007478099204397288\n",
      "train loss:0.000856545931363303\n",
      "train loss:0.01835966725755874\n",
      "train loss:0.0031866114037786696\n",
      "train loss:0.0026371069689780312\n",
      "train loss:0.0007647778785126786\n",
      "train loss:0.0042172145375015705\n",
      "train loss:0.009131562878812099\n",
      "train loss:0.005853274570059127\n",
      "train loss:0.0042648854351503545\n",
      "train loss:0.00875650714164686\n",
      "train loss:0.0010834960375914148\n",
      "train loss:0.0026499731505485674\n",
      "train loss:0.001958428337178862\n",
      "train loss:0.0010184175301274968\n",
      "train loss:0.011943417194353791\n",
      "train loss:0.0015101118067211566\n",
      "train loss:0.025994878866468805\n",
      "train loss:0.0012695023425296431\n",
      "train loss:0.0017953321550495623\n",
      "train loss:0.0030723298772665475\n",
      "train loss:0.0005886778342055926\n",
      "train loss:0.02468830156895155\n",
      "train loss:0.004300055047345977\n",
      "train loss:0.0011123620342879943\n",
      "train loss:0.002656894985085453\n",
      "train loss:0.0004327314982649568\n",
      "train loss:0.0008424850418972456\n",
      "train loss:0.010488646559722654\n",
      "train loss:0.006694098418985804\n",
      "train loss:0.008986575883761559\n",
      "train loss:0.001643480138862877\n",
      "train loss:0.0014004110380838152\n",
      "train loss:0.007862021076403164\n",
      "train loss:0.0018841838361739775\n",
      "train loss:0.007111550593391119\n",
      "train loss:0.0024200241272086943\n",
      "train loss:0.00950671100876003\n",
      "train loss:0.0004998625598891204\n",
      "train loss:0.019838438358968934\n",
      "train loss:0.021657941418372132\n",
      "train loss:0.005595244109822575\n",
      "train loss:0.004282583446021045\n",
      "train loss:0.009117929214060976\n",
      "train loss:0.001708256783252963\n",
      "train loss:0.015079609152995398\n",
      "train loss:0.0017801807491014913\n",
      "train loss:0.010294972783608752\n",
      "train loss:0.0048669156712747835\n",
      "train loss:0.0007468341922951961\n",
      "train loss:0.004579543958912547\n",
      "train loss:0.004118051119557574\n",
      "train loss:0.002099807842204646\n",
      "train loss:0.006875023501593771\n",
      "train loss:0.0023934285099218434\n",
      "train loss:0.0011324310646095043\n",
      "train loss:0.003854483023270502\n",
      "train loss:0.0028521283379956547\n",
      "train loss:0.0005054079475174814\n",
      "train loss:0.004067199267339747\n",
      "train loss:0.004326114020619801\n",
      "train loss:0.022036798782700075\n",
      "train loss:0.005824985308097473\n",
      "train loss:0.003302320865037216\n",
      "train loss:0.025963703617459196\n",
      "train loss:0.0010731664098862824\n",
      "train loss:0.00161099151022733\n",
      "train loss:0.0013495836969124974\n",
      "train loss:0.001566292584972393\n",
      "train loss:0.0036959186509307198\n",
      "train loss:0.01269836628152918\n",
      "train loss:0.0013167619938013386\n",
      "train loss:0.012173328341355462\n",
      "train loss:0.0007630793797261253\n",
      "train loss:0.0014328097239333993\n",
      "train loss:0.006753060449804845\n",
      "train loss:0.0016077763580704901\n",
      "train loss:0.0008546502965027344\n",
      "train loss:0.004604324377249015\n",
      "train loss:0.004951417297974881\n",
      "train loss:0.05988833984191064\n",
      "train loss:0.002661307318583361\n",
      "train loss:0.003006062600714116\n",
      "train loss:0.024679511703707815\n",
      "train loss:0.001591517252129646\n",
      "train loss:0.0014622893415538677\n",
      "train loss:0.020987933190193833\n",
      "train loss:0.009669489600077453\n",
      "train loss:0.0015929366138528803\n",
      "train loss:0.01625970035244908\n",
      "train loss:0.0010848280243068772\n",
      "train loss:0.0019482078034515132\n",
      "train loss:0.000460885883288026\n",
      "train loss:0.026253461399356276\n",
      "train loss:0.0023085897349589806\n",
      "train loss:0.002270188502088854\n",
      "train loss:0.0011917711611100122\n",
      "train loss:0.02132779260663663\n",
      "train loss:0.0048996573810588485\n",
      "train loss:0.025249006085550484\n",
      "train loss:0.002020685474532907\n",
      "train loss:0.002450279559147837\n",
      "train loss:0.018277578128847012\n",
      "train loss:0.005460360499090785\n",
      "train loss:0.01502272147264274\n",
      "train loss:0.006080614858361759\n",
      "train loss:0.005839050285269859\n",
      "train loss:0.002385681951818027\n",
      "train loss:0.0015129914160497894\n",
      "train loss:0.02740429686478252\n",
      "train loss:0.00036205227561817175\n",
      "train loss:0.009315742980038524\n",
      "train loss:0.003145964228306211\n",
      "train loss:0.005077710916262384\n",
      "train loss:0.005287523474122028\n",
      "train loss:0.003169394241904405\n",
      "train loss:0.001485877239137741\n",
      "train loss:0.003003080357860298\n",
      "train loss:0.004313851015193439\n",
      "train loss:0.006801702335873075\n",
      "train loss:0.004398867760431642\n",
      "train loss:0.0028034940005326413\n",
      "train loss:0.001006900229313837\n",
      "train loss:0.005825167235112089\n",
      "train loss:0.007923681137608404\n",
      "train loss:0.0007760793333275084\n",
      "train loss:0.0039013853914248386\n",
      "train loss:0.0014885001871060074\n",
      "train loss:0.002969740819616789\n",
      "train loss:0.0032464404684202823\n",
      "train loss:0.004822703298358297\n",
      "train loss:0.003672506912948739\n",
      "train loss:0.00032110646662399046\n",
      "train loss:0.005921690082906997\n",
      "train loss:0.0025586482061258635\n",
      "train loss:0.0015467435919063216\n",
      "train loss:0.0013171670619355072\n",
      "train loss:0.0016103784047727687\n",
      "train loss:0.0017690052971415565\n",
      "train loss:0.011187287996960851\n",
      "train loss:0.0038643863216277557\n",
      "train loss:0.0016836788096405897\n",
      "train loss:0.013402875349593139\n",
      "train loss:0.02048465315891175\n",
      "train loss:0.0013742517147586448\n",
      "train loss:0.008049254086354459\n",
      "train loss:0.0009388191525708702\n",
      "train loss:0.005559138777880457\n",
      "train loss:0.0025385103274050197\n",
      "train loss:0.01684891670295581\n",
      "train loss:0.003271091348268777\n",
      "train loss:0.005851964489802259\n",
      "train loss:0.0005951365944600116\n",
      "train loss:0.012351416682338644\n",
      "train loss:0.002203379783498086\n",
      "train loss:0.014529161536808253\n",
      "train loss:0.010780748227975624\n",
      "train loss:0.001993562620623475\n",
      "train loss:0.005608587664089033\n",
      "train loss:0.0013678906326003092\n",
      "train loss:0.0004621561788741412\n",
      "train loss:0.0025833584953070614\n",
      "train loss:0.007344613981624209\n",
      "train loss:0.017990529551559945\n",
      "train loss:0.006514349705799124\n",
      "train loss:0.0017717388740168165\n",
      "train loss:0.006717086482307748\n",
      "train loss:0.004797317281783076\n",
      "train loss:0.00761935528049602\n",
      "train loss:0.004100078457059635\n",
      "train loss:0.0024426952071568524\n",
      "train loss:0.01483913935922576\n",
      "train loss:0.009710549486677334\n",
      "train loss:0.007747857771429253\n",
      "train loss:0.008678396667032233\n",
      "train loss:0.005668624306643235\n",
      "train loss:0.0006688668236908311\n",
      "train loss:0.010866764956740205\n",
      "train loss:0.0015351720716211491\n",
      "train loss:0.004556017794165122\n",
      "train loss:0.008448499657382766\n",
      "train loss:0.019569951722744557\n",
      "train loss:0.0033182226912391376\n",
      "train loss:0.008420039562709201\n",
      "train loss:0.006059586382199508\n",
      "train loss:0.0002992588545101239\n",
      "train loss:0.00069831922551345\n",
      "train loss:0.01842602279687096\n",
      "train loss:0.0012235227142283573\n",
      "train loss:0.0014500469717454545\n",
      "train loss:0.0027040100753345352\n",
      "train loss:0.0018272986486802861\n",
      "train loss:0.007280815667953193\n",
      "train loss:0.03007447801433364\n",
      "train loss:0.005300519276689291\n",
      "train loss:0.000911209286506989\n",
      "train loss:0.0022918948760788115\n",
      "train loss:0.002173176445889417\n",
      "train loss:0.0034483024941006097\n",
      "train loss:0.02863819455320829\n",
      "train loss:0.009422869943343973\n",
      "train loss:0.007895603953164916\n",
      "train loss:0.0018653568959309083\n",
      "train loss:0.006459526669712044\n",
      "train loss:0.00387191975327355\n",
      "train loss:0.006290852542134065\n",
      "train loss:0.01746065258626976\n",
      "train loss:0.0026356047922929337\n",
      "train loss:0.0022485012543160088\n",
      "train loss:0.0018969681934235185\n",
      "train loss:0.0003427453398591321\n",
      "train loss:0.0007963346956277078\n",
      "train loss:0.0017527112110579223\n",
      "train loss:0.006085014042833214\n",
      "train loss:0.0025657307659236765\n",
      "train loss:0.00504515471459853\n",
      "train loss:0.00255583372405244\n",
      "train loss:0.002138901915416049\n",
      "train loss:0.0038229740466808933\n",
      "train loss:0.006644286211829467\n",
      "train loss:0.003855560519586526\n",
      "train loss:0.0005704473358258184\n",
      "train loss:0.001240766199235854\n",
      "train loss:0.017032003229634895\n",
      "train loss:0.006849661468859195\n",
      "train loss:0.008912887332270907\n",
      "train loss:0.007207807119658205\n",
      "train loss:0.0010021827822396055\n",
      "train loss:0.004745039036292984\n",
      "train loss:0.0161500556503285\n",
      "train loss:0.012904644014119847\n",
      "train loss:0.0053273729834009634\n",
      "train loss:0.04251913892552741\n",
      "train loss:0.004082433500349325\n",
      "train loss:0.0015648300368690594\n",
      "train loss:0.000639253527349004\n",
      "train loss:0.004767217686741723\n",
      "train loss:0.0036391944449729813\n",
      "train loss:0.007646736566348372\n",
      "train loss:0.0034317796659933653\n",
      "train loss:0.002344078411541122\n",
      "train loss:0.00226861895277064\n",
      "train loss:0.000978484161221188\n",
      "train loss:0.004708086159261264\n",
      "train loss:0.0009405473707570881\n",
      "train loss:0.002310819884207021\n",
      "train loss:0.0015494047126951465\n",
      "train loss:0.014797480202926643\n",
      "train loss:0.008079301666030835\n",
      "train loss:0.007119703124642967\n",
      "train loss:0.005047469641579314\n",
      "train loss:0.004946857711540513\n",
      "train loss:0.004117777242121794\n",
      "train loss:0.0067050119308069474\n",
      "train loss:0.008820640042624842\n",
      "train loss:0.004994248626059475\n",
      "train loss:0.025945024736028256\n",
      "train loss:0.0020919382201915197\n",
      "train loss:0.00939866104183952\n",
      "train loss:0.0045994738473828884\n",
      "train loss:0.007097745915011274\n",
      "train loss:0.008614560685411258\n",
      "train loss:0.0004878701147385208\n",
      "train loss:0.0009752153883353585\n",
      "train loss:0.004802074852351238\n",
      "train loss:0.00499346147018141\n",
      "train loss:0.00296746750611365\n",
      "train loss:0.0017637157004151826\n",
      "train loss:0.01088783060304334\n",
      "train loss:0.0022170380175607985\n",
      "train loss:0.0013622530092470674\n",
      "train loss:0.008211219548320776\n",
      "train loss:0.022318584208525838\n",
      "train loss:0.0013770535645174784\n",
      "train loss:0.0005510704213256126\n",
      "train loss:0.028843172735033104\n",
      "train loss:0.0009915455152396933\n",
      "train loss:0.0027742690435277077\n",
      "train loss:0.0008687340045540759\n",
      "train loss:0.013771770779513198\n",
      "train loss:0.0015006507991934643\n",
      "train loss:0.010226342781906504\n",
      "train loss:0.013940007802668953\n",
      "train loss:0.01498657085143918\n",
      "train loss:0.0022270625030234924\n",
      "train loss:0.0023445519108100336\n",
      "train loss:0.0008658650741025753\n",
      "train loss:0.003948396922910595\n",
      "train loss:0.0008612503599020008\n",
      "train loss:0.011267280910479736\n",
      "train loss:0.0009025894144334326\n",
      "train loss:0.0030389092545670834\n",
      "train loss:0.002647768838487497\n",
      "train loss:0.007789223164317783\n",
      "train loss:0.0030716861528452067\n",
      "train loss:0.007451184646495304\n",
      "train loss:0.010479413762572063\n",
      "train loss:0.01169854053385619\n",
      "train loss:0.0013571231691258373\n",
      "train loss:0.007944663722805383\n",
      "train loss:0.00753717134361504\n",
      "train loss:0.0015925197929011056\n",
      "train loss:0.0025503881256352845\n",
      "train loss:0.00862301857464504\n",
      "train loss:0.002261590890438538\n",
      "train loss:0.008984624423593051\n",
      "train loss:0.0019374573077029905\n",
      "train loss:0.005005028938665312\n",
      "train loss:0.007260911020412994\n",
      "train loss:0.0009441157847955438\n",
      "train loss:0.005974200333432562\n",
      "train loss:0.003828169566770889\n",
      "train loss:0.009698440696275408\n",
      "train loss:0.02388790407970075\n",
      "train loss:0.009670839278014135\n",
      "train loss:0.0013695912705684373\n",
      "train loss:0.00224076768281172\n",
      "train loss:0.003479209916005011\n",
      "train loss:0.0037453853233463236\n",
      "train loss:0.005290602595213031\n",
      "train loss:0.003083727375693862\n",
      "train loss:0.002623324866861426\n",
      "train loss:0.006902187083704012\n",
      "train loss:0.0007316510160539067\n",
      "train loss:0.0006310851443640454\n",
      "train loss:0.0011802787513972438\n",
      "train loss:0.0011832468902832204\n",
      "train loss:0.0023707788307872502\n",
      "train loss:0.00047745720252446175\n",
      "train loss:0.0023827213718347743\n",
      "train loss:0.01079303000228436\n",
      "train loss:0.0021584123440976603\n",
      "train loss:0.0015607197035196344\n",
      "train loss:0.004131041575974404\n",
      "train loss:0.001093256541943391\n",
      "train loss:0.003521932187669306\n",
      "train loss:0.002435040967166441\n",
      "train loss:0.01709777164286174\n",
      "train loss:0.021967008466986133\n",
      "train loss:0.0017607397930744033\n",
      "train loss:0.005470323160195463\n",
      "train loss:0.006443395426034568\n",
      "train loss:0.0016348856573430387\n",
      "train loss:0.0006481705520844298\n",
      "train loss:0.0012286808644448597\n",
      "train loss:0.0024139230970654847\n",
      "train loss:0.0016739263914267951\n",
      "train loss:0.006077117267548176\n",
      "train loss:0.00251887411338674\n",
      "train loss:0.0003292563185215234\n",
      "train loss:0.0028780539254140446\n",
      "train loss:0.004634179820668059\n",
      "train loss:0.003107987061595289\n",
      "train loss:0.0018227783370339406\n",
      "train loss:0.004144000470473173\n",
      "train loss:0.02061049728084612\n",
      "train loss:0.0028256012451154705\n",
      "train loss:0.028987643202411296\n",
      "train loss:0.007258141704956866\n",
      "train loss:0.005288122516705957\n",
      "train loss:0.0007563155449235245\n",
      "train loss:0.0007687531856843919\n",
      "train loss:0.004236719114665938\n",
      "train loss:0.0028980279745846487\n",
      "train loss:0.013833784475352627\n",
      "train loss:0.0008736060752470592\n",
      "train loss:0.002378906528511426\n",
      "train loss:0.0005251758616913918\n",
      "train loss:0.005519638255386084\n",
      "train loss:0.00598297384760883\n",
      "train loss:0.0006011992995628134\n",
      "train loss:0.002634707653450892\n",
      "train loss:0.003880764291270423\n",
      "train loss:0.0025482300783513366\n",
      "train loss:0.0013313787843151558\n",
      "train loss:0.0017585048171195423\n",
      "train loss:0.0006972135455809526\n",
      "train loss:0.0012641436359554056\n",
      "train loss:0.0014138592817788788\n",
      "train loss:0.005166537167772858\n",
      "train loss:0.005432022183539368\n",
      "train loss:0.0032547366634863243\n",
      "train loss:0.0035541349066367267\n",
      "train loss:0.0048622446648817486\n",
      "train loss:0.0006743716098888602\n",
      "train loss:0.0034870219274698595\n",
      "train loss:0.0037766610601250128\n",
      "train loss:0.00029301547455190085\n",
      "train loss:0.008482743045012443\n",
      "train loss:0.00395063225666251\n",
      "train loss:0.00103325890440375\n",
      "train loss:0.00045599138177955805\n",
      "train loss:0.0047031167848754505\n",
      "train loss:0.012919303260646569\n",
      "train loss:0.03945557565135574\n",
      "train loss:0.0005273207341976084\n",
      "train loss:0.0035084597007151003\n",
      "train loss:0.00844541325053222\n",
      "train loss:0.0017096241736038595\n",
      "train loss:0.0008523101464432456\n",
      "train loss:0.0003830586731524466\n",
      "train loss:0.0018735878659741146\n",
      "train loss:0.0014508167103825715\n",
      "train loss:0.00786436585488355\n",
      "train loss:0.0074316854456603\n",
      "train loss:0.0028469680368802\n",
      "train loss:0.010964460423418407\n",
      "train loss:0.0007028706175926535\n",
      "train loss:0.0036640562794278664\n",
      "train loss:0.0024114303322749133\n",
      "train loss:0.00244369622912288\n",
      "train loss:0.0018772940429419573\n",
      "train loss:0.005834431763308236\n",
      "train loss:0.011944192148574641\n",
      "train loss:0.0009622309696358626\n",
      "train loss:0.00026944351513052126\n",
      "train loss:0.0018127480710806265\n",
      "train loss:0.008019785481009562\n",
      "train loss:0.003305897133022161\n",
      "train loss:0.00021978295771117424\n",
      "train loss:0.008318041964418207\n",
      "train loss:0.0019397437121191452\n",
      "train loss:0.0006988057746875005\n",
      "train loss:0.0035925149996809446\n",
      "train loss:0.008077577663682495\n",
      "train loss:0.0036271870526372284\n",
      "train loss:0.0011469398397458111\n",
      "train loss:0.007881361647801077\n",
      "train loss:0.011791435712197573\n",
      "train loss:0.0012073617490879806\n",
      "train loss:0.004083155425845916\n",
      "=== epoch:13, train acc:0.998, test acc:0.983 ===\n",
      "train loss:0.05308438716468085\n",
      "train loss:0.0026780039624869517\n",
      "train loss:0.0003505518773433832\n",
      "train loss:0.002326220684198373\n",
      "train loss:0.001964516296018816\n",
      "train loss:0.0009264257408204206\n",
      "train loss:0.0031743494087460365\n",
      "train loss:0.001226142810197616\n",
      "train loss:0.002267410410382611\n",
      "train loss:0.007809191217162175\n",
      "train loss:0.005072103591260482\n",
      "train loss:0.005761069640735592\n",
      "train loss:0.0036466426637641173\n",
      "train loss:0.0022295883978760505\n",
      "train loss:0.008747153796843281\n",
      "train loss:0.013991778674193416\n",
      "train loss:0.0029823609420899567\n",
      "train loss:0.001415760189703421\n",
      "train loss:0.004478103213011779\n",
      "train loss:0.00684612505677192\n",
      "train loss:0.010451812942252897\n",
      "train loss:0.003015024225135563\n",
      "train loss:0.011573183539737568\n",
      "train loss:0.002780099041125707\n",
      "train loss:0.0037401691242352985\n",
      "train loss:0.0029067075325883767\n",
      "train loss:0.02817742846714671\n",
      "train loss:0.001291901333217521\n",
      "train loss:0.0012837791272361304\n",
      "train loss:0.0005697071432480105\n",
      "train loss:0.004808111465708748\n",
      "train loss:0.008256142094720734\n",
      "train loss:0.006208981121065068\n",
      "train loss:0.0010455613849967924\n",
      "train loss:0.011444198575081896\n",
      "train loss:0.001459791727579937\n",
      "train loss:0.003869448476387462\n",
      "train loss:0.0005480113964474007\n",
      "train loss:0.0006376472274213184\n",
      "train loss:0.0011984217257780634\n",
      "train loss:0.0009022526933432301\n",
      "train loss:0.004090045687155255\n",
      "train loss:0.0011079531310340571\n",
      "train loss:0.002192174254195347\n",
      "train loss:0.0044587105758983545\n",
      "train loss:0.0020470308509845016\n",
      "train loss:0.004262525305068905\n",
      "train loss:0.0025241127285946107\n",
      "train loss:0.003840837712012445\n",
      "train loss:0.0019142061760634554\n",
      "train loss:0.0018359063738539344\n",
      "train loss:0.0027221027849862623\n",
      "train loss:7.364858199591001e-05\n",
      "train loss:0.006910390161772374\n",
      "train loss:0.0017909378275007288\n",
      "train loss:0.0007945782062973976\n",
      "train loss:0.002618135062303135\n",
      "train loss:0.0021277892251798853\n",
      "train loss:0.003309341812602738\n",
      "train loss:0.0025665987919603287\n",
      "train loss:0.006236587708641875\n",
      "train loss:0.0016610232581984602\n",
      "train loss:0.0017041682493218937\n",
      "train loss:0.0003862224724375465\n",
      "train loss:0.006093844528963602\n",
      "train loss:0.00021830637375732265\n",
      "train loss:0.0001276812679276512\n",
      "train loss:0.004766671376058335\n",
      "train loss:0.010292562950966049\n",
      "train loss:0.0028074373660459872\n",
      "train loss:0.00471953887384752\n",
      "train loss:0.0021495644023412194\n",
      "train loss:0.007181241829030547\n",
      "train loss:0.006237129324108387\n",
      "train loss:0.0005088663082064722\n",
      "train loss:0.0033893442581247346\n",
      "train loss:0.0041115171957017745\n",
      "train loss:0.007456492960431998\n",
      "train loss:0.001725445957308774\n",
      "train loss:0.00215630364530766\n",
      "train loss:0.0005727122644631944\n",
      "train loss:0.03155379258309712\n",
      "train loss:0.004531615853999442\n",
      "train loss:0.003991544327423405\n",
      "train loss:0.0015026479387792696\n",
      "train loss:0.001547925881070278\n",
      "train loss:0.015672203531951024\n",
      "train loss:0.016673210531477564\n",
      "train loss:0.0008802777683132175\n",
      "train loss:0.0003480795821801891\n",
      "train loss:0.014339095766155288\n",
      "train loss:0.00941788531851384\n",
      "train loss:0.004192617396190242\n",
      "train loss:0.0024215606190829677\n",
      "train loss:0.014812907893873486\n",
      "train loss:0.00083851522337226\n",
      "train loss:0.006887256953002689\n",
      "train loss:0.004448630437019934\n",
      "train loss:0.008173627592928686\n",
      "train loss:0.030554754809510795\n",
      "train loss:0.006234137363675508\n",
      "train loss:0.007304512349939815\n",
      "train loss:0.0004196110665557946\n",
      "train loss:0.0018958356486471705\n",
      "train loss:0.005781326381566909\n",
      "train loss:0.0008224748987619027\n",
      "train loss:0.001047568548952882\n",
      "train loss:0.05024143639752964\n",
      "train loss:0.002341060657960885\n",
      "train loss:0.003781436175862637\n",
      "train loss:0.006280628477386054\n",
      "train loss:0.0010042589504286868\n",
      "train loss:0.0017445557406263474\n",
      "train loss:0.0009363131139784911\n",
      "train loss:0.005655895732011367\n",
      "train loss:0.002478165125762439\n",
      "train loss:0.006786781547318334\n",
      "train loss:0.018574948246858233\n",
      "train loss:0.009250473688297818\n",
      "train loss:0.004896877418488618\n",
      "train loss:0.0004119381227300406\n",
      "train loss:0.012982824979452237\n",
      "train loss:0.004971806903514876\n",
      "train loss:0.002770844729706783\n",
      "train loss:0.0019358424544032608\n",
      "train loss:0.006312018809631778\n",
      "train loss:0.0026779892558050277\n",
      "train loss:0.002555401487282818\n",
      "train loss:0.01478205739709771\n",
      "train loss:0.007568543438233915\n",
      "train loss:0.0014073546172851895\n",
      "train loss:0.0038527160150663175\n",
      "train loss:0.0038507573570557784\n",
      "train loss:0.0012022328735829244\n",
      "train loss:0.019219716187299837\n",
      "train loss:0.0007572267664315463\n",
      "train loss:0.01339305512761595\n",
      "train loss:0.000735538109371826\n",
      "train loss:0.0010820580438955301\n",
      "train loss:0.006280851628437896\n",
      "train loss:0.0011206079369458501\n",
      "train loss:0.01814112425804887\n",
      "train loss:0.007190381247832008\n",
      "train loss:0.004856593177390596\n",
      "train loss:0.0073355848016939396\n",
      "train loss:0.005802001517113999\n",
      "train loss:0.0027626793969530504\n",
      "train loss:0.0026266184680995798\n",
      "train loss:0.006724291908119697\n",
      "train loss:0.0019458421460967759\n",
      "train loss:0.0030218684697992226\n",
      "train loss:0.023582506778164435\n",
      "train loss:0.007182902897695781\n",
      "train loss:0.006826583081083292\n",
      "train loss:0.0007762157242728014\n",
      "train loss:0.001437623632069534\n",
      "train loss:0.006767157491302317\n",
      "train loss:0.009998393050062716\n",
      "train loss:0.006374100044262232\n",
      "train loss:0.0010661683786984436\n",
      "train loss:0.0022879552275516684\n",
      "train loss:0.0012283749916678162\n",
      "train loss:0.002549576322221979\n",
      "train loss:0.0011029882903860193\n",
      "train loss:0.0013228745474497428\n",
      "train loss:0.001415935994558813\n",
      "train loss:0.0043415652035065245\n",
      "train loss:0.009804307473505304\n",
      "train loss:0.016552233483237547\n",
      "train loss:0.008937086482733643\n",
      "train loss:0.0007993424650084721\n",
      "train loss:0.0076740529657852875\n",
      "train loss:0.0010741623613695205\n",
      "train loss:0.0036479321458326706\n",
      "train loss:0.0023216192248305166\n",
      "train loss:0.0008154326991322506\n",
      "train loss:0.004443425476669474\n",
      "train loss:0.0034214178450226594\n",
      "train loss:0.00040292652012424235\n",
      "train loss:0.0009088887270350037\n",
      "train loss:0.003689117596381495\n",
      "train loss:0.0035078678797231468\n",
      "train loss:0.001014236451124246\n",
      "train loss:0.004483205949801428\n",
      "train loss:0.0033429262020685706\n",
      "train loss:0.022004465102504332\n",
      "train loss:0.0030890703736889784\n",
      "train loss:0.002648379974868129\n",
      "train loss:0.002295559668793422\n",
      "train loss:0.000929756068617893\n",
      "train loss:0.00019856673184509048\n",
      "train loss:0.037081418863509234\n",
      "train loss:0.0013928234307619921\n",
      "train loss:0.011064587292235875\n",
      "train loss:0.00207685585607063\n",
      "train loss:0.0004356549482834407\n",
      "train loss:0.004688538908957446\n",
      "train loss:0.003801819499737299\n",
      "train loss:0.006757471863179609\n",
      "train loss:0.004102377456376322\n",
      "train loss:0.0013572168619361705\n",
      "train loss:0.0005825936732859205\n",
      "train loss:0.006033211703787301\n",
      "train loss:0.0009230523712405619\n",
      "train loss:0.01147718202725315\n",
      "train loss:0.00680038713887809\n",
      "train loss:0.0031709879083873494\n",
      "train loss:0.00909153788256219\n",
      "train loss:0.0064361822303167495\n",
      "train loss:0.0012003264377607819\n",
      "train loss:0.0017017910313113984\n",
      "train loss:0.0018679433764183454\n",
      "train loss:0.002375268384643364\n",
      "train loss:0.008397606086334287\n",
      "train loss:0.0009772298259888288\n",
      "train loss:0.0015919064228081617\n",
      "train loss:0.0008708298464244242\n",
      "train loss:0.0001927055624322881\n",
      "train loss:0.0026967214067880672\n",
      "train loss:0.0030539831138424634\n",
      "train loss:0.0018854431404955148\n",
      "train loss:0.008735427854914697\n",
      "train loss:0.0037893736657084935\n",
      "train loss:0.03433962706239164\n",
      "train loss:0.0006432711598768284\n",
      "train loss:0.012774348347765337\n",
      "train loss:0.001173157492174361\n",
      "train loss:0.0030638458635742494\n",
      "train loss:0.003801116313732512\n",
      "train loss:0.00034349851200017037\n",
      "train loss:0.004115377566397389\n",
      "train loss:0.00503652357903033\n",
      "train loss:0.0084317225364096\n",
      "train loss:0.0020602323004318243\n",
      "train loss:0.004183347970604745\n",
      "train loss:0.0008372736668305703\n",
      "train loss:0.009108630321956359\n",
      "train loss:0.002595524517717658\n",
      "train loss:0.009559812111270072\n",
      "train loss:0.0015304837818272924\n",
      "train loss:0.008005263004205551\n",
      "train loss:0.0017748944842621486\n",
      "train loss:0.0007427588895766958\n",
      "train loss:0.005946730615934623\n",
      "train loss:0.00014359501983753368\n",
      "train loss:0.001012702293404983\n",
      "train loss:0.0002658273534824932\n",
      "train loss:0.002751228601452567\n",
      "train loss:0.003775904624377328\n",
      "train loss:0.008808223354961044\n",
      "train loss:0.001044972930896035\n",
      "train loss:0.0019080319859883408\n",
      "train loss:0.008066964709036178\n",
      "train loss:0.00044385405437931034\n",
      "train loss:0.0032396974997830363\n",
      "train loss:0.006139770999861076\n",
      "train loss:0.005578118385195607\n",
      "train loss:0.0030901409535879177\n",
      "train loss:0.007905967421329246\n",
      "train loss:0.0003432732942176218\n",
      "train loss:0.0011057837354151588\n",
      "train loss:0.0006920753625457506\n",
      "train loss:0.0017597412680773778\n",
      "train loss:0.003709426463607002\n",
      "train loss:0.016769472754958794\n",
      "train loss:0.003764077437961917\n",
      "train loss:0.0005605013950787921\n",
      "train loss:0.003250845740947308\n",
      "train loss:0.02340625882781775\n",
      "train loss:0.0018512373943185033\n",
      "train loss:0.005146573348415079\n",
      "train loss:0.008328951681148502\n",
      "train loss:0.006599450399177233\n",
      "train loss:0.0032217586046569113\n",
      "train loss:0.02804678287350241\n",
      "train loss:0.012172376991454492\n",
      "train loss:0.005677085393055928\n",
      "train loss:0.0008351153065913629\n",
      "train loss:0.003331544923939219\n",
      "train loss:0.003250006224647394\n",
      "train loss:9.919400896443182e-05\n",
      "train loss:0.007564119317538831\n",
      "train loss:0.006413536214180592\n",
      "train loss:0.0026083514860050505\n",
      "train loss:0.0034028036549457134\n",
      "train loss:0.00192309127555038\n",
      "train loss:0.003760704068006544\n",
      "train loss:0.003785485907640623\n",
      "train loss:0.0018607811424531165\n",
      "train loss:0.0014259582817596982\n",
      "train loss:0.0036880238319336\n",
      "train loss:0.0012153648778692142\n",
      "train loss:0.0014640572999590601\n",
      "train loss:0.0013209228626957187\n",
      "train loss:0.009693433906390079\n",
      "train loss:0.0044652240206040465\n",
      "train loss:0.0004130357848310641\n",
      "train loss:0.0017452621380967103\n",
      "train loss:0.002679453410299675\n",
      "train loss:0.0032534318724208194\n",
      "train loss:0.0035769821306894235\n",
      "train loss:0.00021240828381247103\n",
      "train loss:0.0031579173746703985\n",
      "train loss:0.0010714531426849157\n",
      "train loss:0.003204544593858964\n",
      "train loss:0.0038253639446119525\n",
      "train loss:0.0029004315336296728\n",
      "train loss:0.0005849299195362073\n",
      "train loss:0.00619335217786488\n",
      "train loss:0.0027974087662684787\n",
      "train loss:0.006148319132290069\n",
      "train loss:0.00024124875599641532\n",
      "train loss:0.0015182266661979854\n",
      "train loss:0.003849258056202787\n",
      "train loss:0.003690312987050347\n",
      "train loss:0.004599083565342453\n",
      "train loss:0.002141225600483798\n",
      "train loss:0.005069620612042635\n",
      "train loss:0.0023690364666005535\n",
      "train loss:0.02014023405481844\n",
      "train loss:0.00490382928006272\n",
      "train loss:0.015757574009254507\n",
      "train loss:0.01419888676913507\n",
      "train loss:0.0016867780441980698\n",
      "train loss:0.00036265775210697106\n",
      "train loss:0.008762114909820769\n",
      "train loss:0.0005548494494866922\n",
      "train loss:0.005702250910422289\n",
      "train loss:0.007876514664135829\n",
      "train loss:0.0069518528651637355\n",
      "train loss:0.0008504423246737995\n",
      "train loss:0.0001934641084514954\n",
      "train loss:0.003264217066532712\n",
      "train loss:0.0001679231452667824\n",
      "train loss:0.0019982997581332643\n",
      "train loss:0.0022643159999408604\n",
      "train loss:0.0005517940542464916\n",
      "train loss:0.010090970253086062\n",
      "train loss:0.0012176570057415978\n",
      "train loss:0.0013781894925729583\n",
      "train loss:0.00040318764236271863\n",
      "train loss:0.0010803124328238138\n",
      "train loss:0.0028549859624320746\n",
      "train loss:0.0005977536384215553\n",
      "train loss:0.0009799441338704657\n",
      "train loss:0.0011481832526067262\n",
      "train loss:0.006579422878712013\n",
      "train loss:0.0023168730915505\n",
      "train loss:0.0004980197734216896\n",
      "train loss:0.004176031176922806\n",
      "train loss:0.003015696498476948\n",
      "train loss:0.0019182037143610597\n",
      "train loss:0.00028212154869617175\n",
      "train loss:0.00019842621985843108\n",
      "train loss:0.006003674208381292\n",
      "train loss:0.0036737151104261536\n",
      "train loss:0.0002501910678887871\n",
      "train loss:0.002135828215980044\n",
      "train loss:0.0018529454387267046\n",
      "train loss:0.005125337466960889\n",
      "train loss:0.002417031231205149\n",
      "train loss:0.002379880550446719\n",
      "train loss:0.0001999287947447247\n",
      "train loss:0.001047504573355363\n",
      "train loss:0.001608654340313413\n",
      "train loss:0.005452644062681278\n",
      "train loss:0.0006894511932320499\n",
      "train loss:0.004296496082755771\n",
      "train loss:0.003049081963577141\n",
      "train loss:0.0008233054149259394\n",
      "train loss:0.0009241106281174821\n",
      "train loss:0.006806277692226348\n",
      "train loss:0.0008392837737775234\n",
      "train loss:0.0008650925666976151\n",
      "train loss:0.0033646840530826027\n",
      "train loss:0.0007927283149109503\n",
      "train loss:0.0006772609948677992\n",
      "train loss:0.00026906404987350914\n",
      "train loss:0.0041968672464441185\n",
      "train loss:0.0024844079681970656\n",
      "train loss:0.007132527298980882\n",
      "train loss:0.0017589716288881944\n",
      "train loss:0.0054572888841941496\n",
      "train loss:0.007755415885991386\n",
      "train loss:0.0008424010615441111\n",
      "train loss:0.0010042345278537998\n",
      "train loss:0.01597257498524084\n",
      "train loss:0.0019409781555360434\n",
      "train loss:0.002545307200853274\n",
      "train loss:0.0034216951832775977\n",
      "train loss:0.0028236813817272555\n",
      "train loss:0.0035701265280345647\n",
      "train loss:0.00031095999277144814\n",
      "train loss:0.0028284082111875546\n",
      "train loss:0.009395603668800163\n",
      "train loss:0.005142881141123466\n",
      "train loss:0.003944618213827848\n",
      "train loss:0.0008770526642612572\n",
      "train loss:0.004726123457458535\n",
      "train loss:0.0009488352828600957\n",
      "train loss:0.0015106282060739296\n",
      "train loss:0.0008237025690401671\n",
      "train loss:0.001227509281911251\n",
      "train loss:0.001426222785151051\n",
      "train loss:0.005161339270629065\n",
      "train loss:0.0019070852287220226\n",
      "train loss:0.003104344943741174\n",
      "train loss:0.0026849001616634544\n",
      "train loss:0.0017678041465650197\n",
      "train loss:0.0044662428433655975\n",
      "train loss:0.002414625042366729\n",
      "train loss:0.003090597605552941\n",
      "train loss:0.007209537561019413\n",
      "train loss:0.0034349048168543965\n",
      "train loss:0.01194031996323574\n",
      "train loss:0.0029383617045565186\n",
      "train loss:0.001156035513958233\n",
      "train loss:0.0006051449101448974\n",
      "train loss:0.0012311873969950505\n",
      "train loss:0.003258572908586747\n",
      "train loss:0.00427148394971134\n",
      "train loss:0.006114994018921642\n",
      "train loss:0.004184653028633977\n",
      "train loss:0.0026834060044781454\n",
      "train loss:0.0004472955126147563\n",
      "train loss:0.0002579443111133112\n",
      "train loss:0.003545230523165188\n",
      "train loss:0.004316848270716219\n",
      "train loss:0.0011664382933519713\n",
      "train loss:0.0025292158940833863\n",
      "train loss:0.00135337225897042\n",
      "train loss:0.002544880449576046\n",
      "train loss:0.0005330704433001396\n",
      "train loss:0.002495224616515899\n",
      "train loss:0.0005161191265576762\n",
      "train loss:0.0005706202726966841\n",
      "train loss:0.0014277031291883052\n",
      "train loss:0.0005986848760609155\n",
      "train loss:0.0007957539083623896\n",
      "train loss:0.004278640674398725\n",
      "train loss:0.0006838895743447384\n",
      "train loss:0.0008017912982476156\n",
      "train loss:0.0033858756112539134\n",
      "train loss:0.001277547941899587\n",
      "train loss:0.001940430713792088\n",
      "train loss:0.0010177879287221463\n",
      "train loss:0.0014808717889369491\n",
      "train loss:0.008945990723897831\n",
      "train loss:0.0036153595772344597\n",
      "train loss:0.003584390927458359\n",
      "train loss:0.0037569437466530658\n",
      "train loss:0.002503968797751854\n",
      "train loss:0.0021187728439292074\n",
      "train loss:0.004709075016974989\n",
      "train loss:0.02882557098484597\n",
      "train loss:0.0008816858680483581\n",
      "train loss:0.004083480335350884\n",
      "train loss:0.006591052288407615\n",
      "train loss:0.002297516249849964\n",
      "train loss:0.005880936994390063\n",
      "train loss:0.00028965638773159705\n",
      "train loss:0.002770753496640107\n",
      "train loss:0.0013422907794536237\n",
      "train loss:0.004056142844411807\n",
      "train loss:0.00548201402522634\n",
      "train loss:0.0017089510948881013\n",
      "train loss:0.006145844848483173\n",
      "train loss:0.00297311215940277\n",
      "train loss:0.0024740317508668576\n",
      "train loss:0.0007309825971723985\n",
      "train loss:0.0024578093541341877\n",
      "train loss:0.001186564934277446\n",
      "train loss:0.023763308724191724\n",
      "train loss:0.00026344843298010636\n",
      "train loss:0.001050698603588306\n",
      "train loss:0.0024239533218383628\n",
      "train loss:0.002664551814593628\n",
      "train loss:0.000661199055582867\n",
      "train loss:0.0003030086280285377\n",
      "train loss:0.00027583459379796135\n",
      "train loss:0.0006764063089179922\n",
      "train loss:0.0012844939348250197\n",
      "train loss:0.00021005263239353485\n",
      "train loss:0.0018516807553646127\n",
      "train loss:0.001405584112618844\n",
      "train loss:0.0029672308107461655\n",
      "train loss:0.0013136666515314041\n",
      "train loss:0.001227188678213688\n",
      "train loss:0.0008103354750844125\n",
      "train loss:0.0012122567251165205\n",
      "train loss:0.00016810653798609632\n",
      "train loss:0.00035861424285484956\n",
      "train loss:0.0009348557813321916\n",
      "train loss:0.0024285718131452304\n",
      "train loss:0.0010225152427911339\n",
      "train loss:0.003481713542009796\n",
      "train loss:0.0024826144754079506\n",
      "train loss:0.0011755143181404343\n",
      "train loss:0.00040113804418366844\n",
      "train loss:0.021098043291043842\n",
      "train loss:0.00014746727871165705\n",
      "train loss:0.0018054528975287218\n",
      "train loss:0.004618120033445769\n",
      "train loss:0.001941286172773282\n",
      "train loss:0.00031149131881509266\n",
      "train loss:0.0023427540041388363\n",
      "train loss:0.0013649785006769261\n",
      "train loss:0.0009313498502087473\n",
      "train loss:0.006652548856184936\n",
      "train loss:0.0036505038566116686\n",
      "train loss:0.001773452773654389\n",
      "train loss:0.002307074220367697\n",
      "train loss:0.0023672462605286945\n",
      "train loss:0.001704507014792901\n",
      "train loss:0.01954222284364494\n",
      "train loss:0.0017022274568450145\n",
      "train loss:0.00014285187602705075\n",
      "train loss:0.002682373677714995\n",
      "train loss:0.0027824777269161716\n",
      "train loss:0.002399997621696205\n",
      "train loss:0.0023064453423753957\n",
      "train loss:0.0007665025111652304\n",
      "train loss:0.0018561574019512908\n",
      "train loss:0.0015703195920167604\n",
      "train loss:0.002602711328671774\n",
      "train loss:0.0073270411884443646\n",
      "train loss:0.0018116494340700074\n",
      "train loss:0.0026018844086707306\n",
      "train loss:0.0089932777323729\n",
      "train loss:0.002376117620239719\n",
      "train loss:0.012850221564934842\n",
      "train loss:0.002084599741955685\n",
      "train loss:0.0008259358588170074\n",
      "train loss:0.06433182815869333\n",
      "train loss:0.0046557652370243\n",
      "train loss:0.0006690576600937438\n",
      "train loss:0.0007069833322415968\n",
      "train loss:0.011965744593459629\n",
      "train loss:0.0014805207636920247\n",
      "train loss:0.0016695779539980748\n",
      "train loss:0.004901495203346321\n",
      "train loss:0.0024750942786407565\n",
      "train loss:0.00022353407140498908\n",
      "train loss:0.0006973860236462705\n",
      "train loss:0.0007629288708498731\n",
      "train loss:6.982960773920369e-05\n",
      "train loss:0.0009935109639695036\n",
      "train loss:0.0019373789139369951\n",
      "train loss:0.0023195769199129378\n",
      "train loss:0.00020398966493839828\n",
      "train loss:0.00394586825728299\n",
      "train loss:0.000587135246084861\n",
      "train loss:0.0010755135717850385\n",
      "train loss:0.0014771062686962865\n",
      "train loss:0.00035162443442327365\n",
      "train loss:0.0009891648343539144\n",
      "train loss:0.0009865748168158468\n",
      "train loss:0.0003205737074182865\n",
      "train loss:0.02239237701625104\n",
      "train loss:0.00669715479246927\n",
      "train loss:0.001953602342531466\n",
      "train loss:0.003899292753383223\n",
      "train loss:0.002030829748393799\n",
      "train loss:0.012051763136148292\n",
      "train loss:0.0037754061367686457\n",
      "train loss:0.0019830251614959627\n",
      "train loss:0.004703391426377042\n",
      "train loss:0.0022752028546204534\n",
      "train loss:0.0008733239474019108\n",
      "train loss:0.0038383137654997633\n",
      "train loss:0.005900671428084159\n",
      "train loss:0.003363753137494258\n",
      "train loss:0.013790928038243642\n",
      "train loss:0.008402219926838126\n",
      "train loss:0.005525109488500223\n",
      "train loss:0.0021067099701297318\n",
      "train loss:0.0027609319936709375\n",
      "train loss:0.0021172446820710254\n",
      "train loss:0.00621959449424139\n",
      "train loss:0.008888241465091035\n",
      "train loss:0.003336433998392158\n",
      "train loss:0.00185239064464955\n",
      "train loss:0.0016958669057829858\n",
      "train loss:0.004018868689765675\n",
      "train loss:0.005067816888618627\n",
      "train loss:0.006458506220689093\n",
      "train loss:0.001261627043729583\n",
      "train loss:0.00018314127062053537\n",
      "train loss:0.011488310500540673\n",
      "train loss:0.008657349161229216\n",
      "train loss:0.0050009008636571475\n",
      "train loss:0.001923812223019651\n",
      "train loss:3.2592424592678036e-05\n",
      "train loss:0.0008703373309303891\n",
      "train loss:8.351282628455877e-05\n",
      "train loss:0.0023535691150317426\n",
      "train loss:0.005795723972538508\n",
      "train loss:0.0006487321165220828\n",
      "train loss:0.002488056582318714\n",
      "train loss:0.00019058435593591102\n",
      "=== epoch:14, train acc:0.995, test acc:0.978 ===\n",
      "train loss:0.0022741904436719006\n",
      "train loss:0.00207458438710882\n",
      "train loss:0.000979831233542271\n",
      "train loss:0.00723083400381787\n",
      "train loss:0.008741971213202283\n",
      "train loss:0.004677875091327024\n",
      "train loss:0.0012994930277725313\n",
      "train loss:0.003301356036885128\n",
      "train loss:0.000838503408755837\n",
      "train loss:0.0015908503755129987\n",
      "train loss:0.004636872656682063\n",
      "train loss:0.0004015373052582989\n",
      "train loss:0.00874608672657256\n",
      "train loss:0.0003411669821110462\n",
      "train loss:0.004673075671273109\n",
      "train loss:0.00544097369932259\n",
      "train loss:0.03707245995185725\n",
      "train loss:0.0012812080253563252\n",
      "train loss:0.0012133890095618555\n",
      "train loss:0.004971399111766583\n",
      "train loss:0.003941911806551997\n",
      "train loss:0.0015754214121048425\n",
      "train loss:0.0006238987527957946\n",
      "train loss:0.005906439666116219\n",
      "train loss:0.002147444454356345\n",
      "train loss:0.0008023868537936365\n",
      "train loss:0.0032941799849084763\n",
      "train loss:0.006506740525544206\n",
      "train loss:0.002211217575206981\n",
      "train loss:0.0006650000529828956\n",
      "train loss:0.002328842551703727\n",
      "train loss:0.006426871975597892\n",
      "train loss:0.014015583734908745\n",
      "train loss:0.011549871426818115\n",
      "train loss:0.001758121886587058\n",
      "train loss:0.0007578396188104674\n",
      "train loss:0.0032995440059435622\n",
      "train loss:0.002951321688180158\n",
      "train loss:0.000840202283330893\n",
      "train loss:0.019221888900643545\n",
      "train loss:0.15049411077963043\n",
      "train loss:0.006852197358267797\n",
      "train loss:0.0024944952325315285\n",
      "train loss:0.0014316035230211117\n",
      "train loss:0.0029902724697240014\n",
      "train loss:0.0016009376550231524\n",
      "train loss:0.0013697244817161703\n",
      "train loss:0.0019656476687701574\n",
      "train loss:0.0006827791754055602\n",
      "train loss:0.001648565004411118\n",
      "train loss:0.0013568730668514337\n",
      "train loss:0.0033020432431251244\n",
      "train loss:0.007495046556986598\n",
      "train loss:0.003321947148628399\n",
      "train loss:0.006072679452201233\n",
      "train loss:0.00189595043882845\n",
      "train loss:0.006648688726969666\n",
      "train loss:0.00452363119575512\n",
      "train loss:0.0007885282387044478\n",
      "train loss:0.0006743959858727276\n",
      "train loss:0.004309125761220382\n",
      "train loss:0.0006089631986181439\n",
      "train loss:0.001527488506433131\n",
      "train loss:0.004237994876388337\n",
      "train loss:0.004127683642362157\n",
      "train loss:0.005489954837979505\n",
      "train loss:0.00023071542247910814\n",
      "train loss:0.0011996346315273842\n",
      "train loss:0.007045645433008788\n",
      "train loss:0.010669417273447996\n",
      "train loss:0.0026859593247756807\n",
      "train loss:0.0008992246920471155\n",
      "train loss:0.010202448408860086\n",
      "train loss:0.008417682668774889\n",
      "train loss:0.005970881445409364\n",
      "train loss:0.003172722752272626\n",
      "train loss:0.01114704585493977\n",
      "train loss:0.00024565021679165714\n",
      "train loss:0.0011482279327916479\n",
      "train loss:0.0018380210373778643\n",
      "train loss:0.030315794640023885\n",
      "train loss:0.0028384828757850567\n",
      "train loss:0.007900664096665178\n",
      "train loss:0.0014305708120319048\n",
      "train loss:0.011810764238947282\n",
      "train loss:0.011720988659982577\n",
      "train loss:0.07894872489650473\n",
      "train loss:0.0016338462380821052\n",
      "train loss:0.000747273884694374\n",
      "train loss:0.0052098947399007965\n",
      "train loss:0.0052660601300512835\n",
      "train loss:0.0017613681910531058\n",
      "train loss:0.0021385473929214738\n",
      "train loss:0.0016178116661993433\n",
      "train loss:0.004122607531761247\n",
      "train loss:0.0014536666923279532\n",
      "train loss:0.008249077745408508\n",
      "train loss:0.0025311653556730263\n",
      "train loss:0.004873076390163342\n",
      "train loss:0.003403682491767985\n",
      "train loss:0.0018680828780930686\n",
      "train loss:0.0004748023546823407\n",
      "train loss:0.00029992508906041186\n",
      "train loss:0.0011044460197889943\n",
      "train loss:0.004460735839367957\n",
      "train loss:0.0023755797658396426\n",
      "train loss:0.0007860621655303977\n",
      "train loss:0.003484520411564993\n",
      "train loss:0.001978547565014837\n",
      "train loss:0.010138481323010862\n",
      "train loss:0.001252624465599043\n",
      "train loss:0.0017676209069236914\n",
      "train loss:0.0040205745617049\n",
      "train loss:0.000356611250155015\n",
      "train loss:0.000924211601367423\n",
      "train loss:0.0034236837206168937\n",
      "train loss:0.0015579921436071264\n",
      "train loss:0.001789281944420268\n",
      "train loss:0.0019120432503204234\n",
      "train loss:0.011100409671219301\n",
      "train loss:0.0014614704541779703\n",
      "train loss:0.003471173546092744\n",
      "train loss:0.0005480939693551637\n",
      "train loss:0.012261377144834572\n",
      "train loss:0.0361496213085956\n",
      "train loss:0.00243180238783434\n",
      "train loss:0.012423493519005593\n",
      "train loss:0.0005712266342931909\n",
      "train loss:0.011797318293171122\n",
      "train loss:0.0033774425419131945\n",
      "train loss:0.002392787676505919\n",
      "train loss:0.0035855263472183902\n",
      "train loss:0.0025010253990935933\n",
      "train loss:0.0010142261280914216\n",
      "train loss:0.0005089911618148125\n",
      "train loss:0.006971025109163352\n",
      "train loss:0.00032282647969194563\n",
      "train loss:0.0036272582885594007\n",
      "train loss:0.0004455696533824362\n",
      "train loss:0.018440222983201505\n",
      "train loss:0.0036638896512315063\n",
      "train loss:0.002558169692446163\n",
      "train loss:0.002780443114067679\n",
      "train loss:0.0008127640811226505\n",
      "train loss:0.00022250530129624174\n",
      "train loss:0.0009714920372763873\n",
      "train loss:0.00229508888258521\n",
      "train loss:0.0017399427281865798\n",
      "train loss:0.00013927898499736728\n",
      "train loss:0.013549295857861483\n",
      "train loss:0.005528948858282855\n",
      "train loss:0.005081565293286786\n",
      "train loss:0.008109544622822979\n",
      "train loss:0.003460811377087322\n",
      "train loss:0.0038186015134804717\n",
      "train loss:0.007438440707162949\n",
      "train loss:0.0012853561317368958\n",
      "train loss:0.0020402280765790845\n",
      "train loss:0.00196898432966352\n",
      "train loss:0.012275738867764601\n",
      "train loss:0.005168868619992228\n",
      "train loss:0.0005141030861571553\n",
      "train loss:0.0012872595687180822\n",
      "train loss:0.0013721383699628403\n",
      "train loss:0.0013017123834747606\n",
      "train loss:0.004501242558679709\n",
      "train loss:0.0016307498152688784\n",
      "train loss:0.004536287345399398\n",
      "train loss:0.00039163715250696107\n",
      "train loss:0.0010141084874804385\n",
      "train loss:0.009594485461848927\n",
      "train loss:0.0030223138936416897\n",
      "train loss:0.0030261453633721935\n",
      "train loss:0.005009479533222898\n",
      "train loss:0.0005908323862572098\n",
      "train loss:8.040662353861358e-05\n",
      "train loss:0.03117201011756467\n",
      "train loss:0.004295957971049182\n",
      "train loss:0.0017196441220975577\n",
      "train loss:0.0029923520333463766\n",
      "train loss:0.001179191078209771\n",
      "train loss:0.0008776375030917391\n",
      "train loss:0.0007655125433432458\n",
      "train loss:0.004237873155753364\n",
      "train loss:0.005003967912904814\n",
      "train loss:0.006743134201180777\n",
      "train loss:0.0035227850077705304\n",
      "train loss:0.0027918130421011817\n",
      "train loss:0.0012187645640248524\n",
      "train loss:0.00030743132732897143\n",
      "train loss:0.0034621348492726136\n",
      "train loss:0.011176337395089116\n",
      "train loss:0.003208821449892785\n",
      "train loss:0.0006948656061170146\n",
      "train loss:0.0016688503615002073\n",
      "train loss:0.0036707962454509734\n",
      "train loss:0.001696365144884765\n",
      "train loss:0.004356329028306742\n",
      "train loss:0.0028981440865307735\n",
      "train loss:0.0014557051795354423\n",
      "train loss:0.00012598132475256457\n",
      "train loss:0.04920102718141539\n",
      "train loss:0.0024475644340074187\n",
      "train loss:0.021578158597066688\n",
      "train loss:0.0024574940332006997\n",
      "train loss:0.005261071432759143\n",
      "train loss:0.0025535519260637242\n",
      "train loss:0.010862797859102165\n",
      "train loss:0.009767948912335405\n",
      "train loss:0.008707801912935048\n",
      "train loss:0.0013375012082494817\n",
      "train loss:0.00027820186918319704\n",
      "train loss:0.0023541793580781935\n",
      "train loss:0.0008520888766128914\n",
      "train loss:0.0011943701168206362\n",
      "train loss:0.0003678807625261231\n",
      "train loss:0.025151092998126977\n",
      "train loss:0.0031002486776471228\n",
      "train loss:0.002843520852607864\n",
      "train loss:0.0061757192048788444\n",
      "train loss:0.0023638005890370324\n",
      "train loss:0.0006562023335708243\n",
      "train loss:0.0021727072192405184\n",
      "train loss:0.009652940272815609\n",
      "train loss:0.022685684265882515\n",
      "train loss:0.03904664065293485\n",
      "train loss:0.011034380959106211\n",
      "train loss:0.001760760492905883\n",
      "train loss:0.01776374510381637\n",
      "train loss:0.04696631070350006\n",
      "train loss:0.00826080715666582\n",
      "train loss:0.0010043349299018484\n",
      "train loss:0.0058271164461751734\n",
      "train loss:0.0006995470131576522\n",
      "train loss:0.0006333523620998186\n",
      "train loss:0.003993419149181286\n",
      "train loss:0.019513262911377737\n",
      "train loss:0.002907223224295741\n",
      "train loss:0.003475125217686099\n",
      "train loss:0.0009469547444219018\n",
      "train loss:0.0022754652121719753\n",
      "train loss:0.003966069261166257\n",
      "train loss:0.0011639708911292878\n",
      "train loss:0.004247709877879117\n",
      "train loss:0.006112639902555617\n",
      "train loss:0.004063171333844027\n",
      "train loss:0.004124725915422709\n",
      "train loss:0.003366730584223327\n",
      "train loss:0.00255239918178896\n",
      "train loss:0.000981113513675414\n",
      "train loss:0.0006172017884095375\n",
      "train loss:0.015612209905075194\n",
      "train loss:0.02387060046598298\n",
      "train loss:0.0008748581656235242\n",
      "train loss:0.003393950815418509\n",
      "train loss:0.0005084038246209947\n",
      "train loss:0.0011371458938242481\n",
      "train loss:0.0038488996650967566\n",
      "train loss:0.006665410926792641\n",
      "train loss:0.008579776297221321\n",
      "train loss:0.0035080186259030272\n",
      "train loss:0.040235571516342473\n",
      "train loss:0.012436103980206519\n",
      "train loss:0.0005395383533047435\n",
      "train loss:0.0003411645293548505\n",
      "train loss:0.0011669314127586477\n",
      "train loss:0.0009131242585064496\n",
      "train loss:0.0012898166544555317\n",
      "train loss:0.006159062631941874\n",
      "train loss:0.004328328968869571\n",
      "train loss:0.00861247910339954\n",
      "train loss:0.0023322971592569185\n",
      "train loss:0.0057050775823740485\n",
      "train loss:0.0009090037241862366\n",
      "train loss:0.0002033946416086123\n",
      "train loss:0.001276934806105251\n",
      "train loss:0.023707108906767183\n",
      "train loss:0.02926290073084373\n",
      "train loss:0.002912658391166314\n",
      "train loss:0.0012019785870705105\n",
      "train loss:0.014578739698817272\n",
      "train loss:0.017676902747232357\n",
      "train loss:0.0010729480525441682\n",
      "train loss:0.0012147091761721192\n",
      "train loss:0.0021759350532348978\n",
      "train loss:0.0002960444892497607\n",
      "train loss:0.0006665026610870594\n",
      "train loss:0.005049191731585134\n",
      "train loss:0.0015621350570395546\n",
      "train loss:0.0022725834737784985\n",
      "train loss:0.003342856292404514\n",
      "train loss:0.012108564094213665\n",
      "train loss:0.017178648823327466\n",
      "train loss:0.0014787318994249916\n",
      "train loss:0.0007289745169937701\n",
      "train loss:0.000779936662680869\n",
      "train loss:0.0006222687152055028\n",
      "train loss:0.002124172374731157\n",
      "train loss:0.011304054686711923\n",
      "train loss:0.0010697109174854222\n",
      "train loss:0.0005371898951890253\n",
      "train loss:0.003667419351872239\n",
      "train loss:0.0032641085199692724\n",
      "train loss:0.002658565108158224\n",
      "train loss:0.0032399828339164417\n",
      "train loss:0.008841022946102318\n",
      "train loss:0.00459532947898978\n",
      "train loss:0.0033722697394841196\n",
      "train loss:0.002822440579626456\n",
      "train loss:0.009122832579752877\n",
      "train loss:0.015624010060015205\n",
      "train loss:0.0014798832454887508\n",
      "train loss:0.0016142688658258315\n",
      "train loss:0.00017224387217785225\n",
      "train loss:0.0014603831716498436\n",
      "train loss:0.0006478467754922071\n",
      "train loss:0.008033259353420773\n",
      "train loss:0.0009868563778015285\n",
      "train loss:0.0019558829765397422\n",
      "train loss:0.004351317991740008\n",
      "train loss:0.0013449020214151403\n",
      "train loss:0.002176059433628861\n",
      "train loss:0.05174821672084413\n",
      "train loss:0.009341257526509193\n",
      "train loss:0.003221751416689872\n",
      "train loss:0.005436291906263539\n",
      "train loss:0.01417281487981807\n",
      "train loss:0.0012316057146481833\n",
      "train loss:0.013348592009673237\n",
      "train loss:0.006280024364285969\n",
      "train loss:0.003774653289501277\n",
      "train loss:0.0019753738946767753\n",
      "train loss:0.0027519690849894672\n",
      "train loss:0.002689350777209434\n",
      "train loss:0.005741624980486753\n",
      "train loss:0.003052645280646187\n",
      "train loss:0.019859731840592438\n",
      "train loss:0.0014563688554178034\n",
      "train loss:0.006830558068067713\n",
      "train loss:0.0031258200449774238\n",
      "train loss:0.00829159479033737\n",
      "train loss:0.0008446760906986081\n",
      "train loss:0.004314570920656891\n",
      "train loss:0.0016385649039310122\n",
      "train loss:0.008485277445451495\n",
      "train loss:0.0007679139961584702\n",
      "train loss:0.0002429754678450594\n",
      "train loss:0.01708952575759898\n",
      "train loss:0.0021683520246031317\n",
      "train loss:0.0011154135794574135\n",
      "train loss:0.0030270395202939377\n",
      "train loss:0.001808217840451376\n",
      "train loss:0.0004756869488276878\n",
      "train loss:0.006444903305627164\n",
      "train loss:0.0008284239512837077\n",
      "train loss:0.0027883677905303533\n",
      "train loss:0.002542470922484803\n",
      "train loss:0.016234094020236213\n",
      "train loss:0.0012619970002976449\n",
      "train loss:0.006268675242411076\n",
      "train loss:0.0015083029457310564\n",
      "train loss:0.0013202448859581182\n",
      "train loss:0.0021106532525523893\n",
      "train loss:0.004289469275774309\n",
      "train loss:0.0004395574528419348\n",
      "train loss:0.001085413530471409\n",
      "train loss:0.003217347854639627\n",
      "train loss:0.008614194054949582\n",
      "train loss:0.0012418227738628617\n",
      "train loss:0.0048966458545860285\n",
      "train loss:0.0003341885051848265\n",
      "train loss:0.003964491892528434\n",
      "train loss:0.003258946306581666\n",
      "train loss:0.0016888033050049573\n",
      "train loss:0.0016598357856819454\n",
      "train loss:0.0007633122645864643\n",
      "train loss:0.006513783448579469\n",
      "train loss:0.0013251729773380084\n",
      "train loss:0.0019374137860143038\n",
      "train loss:0.0008152262014795697\n",
      "train loss:0.01373196151678903\n",
      "train loss:0.017824682972079776\n",
      "train loss:0.0010964777914542728\n",
      "train loss:0.0014921495571208108\n",
      "train loss:0.004067034816695601\n",
      "train loss:0.00021204692567867105\n",
      "train loss:0.003417225621917661\n",
      "train loss:0.0034775185284327903\n",
      "train loss:0.0009750872213599064\n",
      "train loss:0.0009574235287494201\n",
      "train loss:0.00021253188322560795\n",
      "train loss:0.0015362983466312423\n",
      "train loss:0.003817591846441967\n",
      "train loss:0.0007967800085240147\n",
      "train loss:0.0001671483993596733\n",
      "train loss:0.0019794965078744715\n",
      "train loss:0.003224115989067996\n",
      "train loss:0.0017657082412920724\n",
      "train loss:0.0002774496227928832\n",
      "train loss:0.004084067555693085\n",
      "train loss:0.0005995680772700115\n",
      "train loss:0.00462030432617297\n",
      "train loss:0.0018286059751697775\n",
      "train loss:0.001694806092270685\n",
      "train loss:0.0003729847114159448\n",
      "train loss:0.0009585484005108387\n",
      "train loss:0.001671924436593339\n",
      "train loss:0.0037342907620727807\n",
      "train loss:0.0011558636391833974\n",
      "train loss:0.004947853857312386\n",
      "train loss:0.0014117407078700114\n",
      "train loss:0.002254181324709838\n",
      "train loss:0.0009316035974067578\n",
      "train loss:0.00037198006973487803\n",
      "train loss:0.010510393969392143\n",
      "train loss:0.0008090534163916468\n",
      "train loss:0.0007220081471959927\n",
      "train loss:0.0007222711181599894\n",
      "train loss:0.002942596293391804\n",
      "train loss:0.0012516303868288824\n",
      "train loss:0.002457957638701593\n",
      "train loss:0.0009211172061176511\n",
      "train loss:0.0008167163652691562\n",
      "train loss:0.0059604417336245495\n",
      "train loss:0.0030711045082171496\n",
      "train loss:0.003186352811842624\n",
      "train loss:0.0030919208270390173\n",
      "train loss:0.0017706870821324215\n",
      "train loss:0.0008470590031102887\n",
      "train loss:0.0026684680715773484\n",
      "train loss:0.0017173432043926151\n",
      "train loss:0.0008113367519220433\n",
      "train loss:0.001541711189831444\n",
      "train loss:0.002239133532893878\n",
      "train loss:0.0034990585285236877\n",
      "train loss:0.000377396308622521\n",
      "train loss:0.0003628561679517988\n",
      "train loss:0.001226992202362399\n",
      "train loss:0.00120263629470978\n",
      "train loss:0.0014471166231763974\n",
      "train loss:0.0028099733436624218\n",
      "train loss:0.0012858179753716184\n",
      "train loss:0.0003522037181373056\n",
      "train loss:0.0021436650596047334\n",
      "train loss:0.0009923053452640803\n",
      "train loss:0.0004289135866127125\n",
      "train loss:0.0036016832940803335\n",
      "train loss:0.0019456342394125086\n",
      "train loss:0.002539767179627379\n",
      "train loss:0.002646567238190532\n",
      "train loss:0.0037853238465202863\n",
      "train loss:0.0018965365574531547\n",
      "train loss:0.0011163168238236749\n",
      "train loss:0.0058093654653992135\n",
      "train loss:0.004824167170649624\n",
      "train loss:0.0019683605286670474\n",
      "train loss:0.0019159554954913608\n",
      "train loss:0.00043850299391917576\n",
      "train loss:0.0021778802104123352\n",
      "train loss:0.0022596757464964884\n",
      "train loss:0.00048490679032950226\n",
      "train loss:0.005354627915394766\n",
      "train loss:0.001897094253956265\n",
      "train loss:0.0007157083501459589\n",
      "train loss:0.0001646533885644854\n",
      "train loss:0.000267575436177623\n",
      "train loss:0.00044369896647593386\n",
      "train loss:0.0004893848100142685\n",
      "train loss:0.0030490630791971634\n",
      "train loss:0.001685408492044818\n",
      "train loss:0.0009002843655351638\n",
      "train loss:0.0026327422100325903\n",
      "train loss:0.00018562909967915797\n",
      "train loss:0.0013316682143735836\n",
      "train loss:0.009259860052359606\n",
      "train loss:0.02816638149347085\n",
      "train loss:0.004087380180532489\n",
      "train loss:0.0026737193438511695\n",
      "train loss:0.0027114427652923444\n",
      "train loss:0.00016912398918511557\n",
      "train loss:0.004718230978176796\n",
      "train loss:0.0009707271562390545\n",
      "train loss:0.0004197818577465259\n",
      "train loss:0.0002927523789889963\n",
      "train loss:0.000178280712858552\n",
      "train loss:0.006770107386736271\n",
      "train loss:0.000536114280462755\n",
      "train loss:0.004739883101739032\n",
      "train loss:0.004496765319579934\n",
      "train loss:0.00010916888175185271\n",
      "train loss:0.00044514552908237414\n",
      "train loss:0.0015503954781247537\n",
      "train loss:0.0011826019589142693\n",
      "train loss:0.00042320726081201553\n",
      "train loss:0.001395731201047088\n",
      "train loss:0.0005428217387093554\n",
      "train loss:0.0010719739351621451\n",
      "train loss:0.00034180438184879496\n",
      "train loss:0.008429479554495734\n",
      "train loss:0.008044958371591814\n",
      "train loss:0.002548410808837054\n",
      "train loss:0.0004975098549447856\n",
      "train loss:0.00333257807580568\n",
      "train loss:0.0010695591816181648\n",
      "train loss:0.0005240789400927902\n",
      "train loss:0.017137932535329824\n",
      "train loss:0.003393896516940094\n",
      "train loss:0.00568167647418579\n",
      "train loss:0.0028665241409728936\n",
      "train loss:0.0002157607876546964\n",
      "train loss:0.0032108915096732836\n",
      "train loss:0.012818254183802485\n",
      "train loss:0.013592461649418986\n",
      "train loss:0.0033345630906163803\n",
      "train loss:0.015426415370659492\n",
      "train loss:0.0013707097114106493\n",
      "train loss:0.0005660594671981131\n",
      "train loss:0.003026268076944017\n",
      "train loss:0.007648384972315999\n",
      "train loss:0.0002263428493514499\n",
      "train loss:0.0034396219115321665\n",
      "train loss:0.0030762242985199854\n",
      "train loss:0.0012449500252337147\n",
      "train loss:0.003638386405310617\n",
      "train loss:0.0007402992042654178\n",
      "train loss:0.004286005455103111\n",
      "train loss:0.004148497291033711\n",
      "train loss:0.0018003511826542957\n",
      "train loss:0.0033463060564568763\n",
      "train loss:0.0010107845702852951\n",
      "train loss:0.0012727752862442781\n",
      "train loss:0.0014695794117689938\n",
      "train loss:0.0017391994035842078\n",
      "train loss:0.00031589858003131806\n",
      "train loss:0.0004110426157023632\n",
      "train loss:0.027420826577913178\n",
      "train loss:0.00514034323325604\n",
      "train loss:0.0004166099489447998\n",
      "train loss:0.002815309638484369\n",
      "train loss:0.0036628936062141565\n",
      "train loss:0.0004512405751308564\n",
      "train loss:0.0007665058854748852\n",
      "train loss:0.002348544627647229\n",
      "train loss:0.00904946834298343\n",
      "train loss:0.002842969762742085\n",
      "train loss:0.009810179344412666\n",
      "train loss:0.02157626397296395\n",
      "train loss:0.0037873459637899963\n",
      "train loss:0.0006361144271566777\n",
      "train loss:0.0005928341478549684\n",
      "train loss:0.0015459144209827697\n",
      "train loss:0.0016147727533453071\n",
      "train loss:0.0008928638084503058\n",
      "train loss:0.004065377592982142\n",
      "train loss:0.0014169434582037383\n",
      "train loss:0.027159448597976178\n",
      "train loss:0.0013349507711048517\n",
      "train loss:0.0019819948953257137\n",
      "train loss:0.0003549756967276593\n",
      "train loss:0.0008600119068181601\n",
      "train loss:0.0028898092540066765\n",
      "train loss:0.0005309873377305604\n",
      "train loss:0.0021049763043301693\n",
      "train loss:0.0014130797044053908\n",
      "train loss:0.0009406804152930647\n",
      "train loss:0.0014511286576786827\n",
      "train loss:0.00247497064328716\n",
      "train loss:0.0011366702309248832\n",
      "train loss:0.0005712229373938062\n",
      "train loss:0.06039480065767323\n",
      "train loss:0.0005366764417803879\n",
      "train loss:0.009268760508939907\n",
      "train loss:0.023203680031371365\n",
      "train loss:0.0008588149870098072\n",
      "train loss:0.0006739167405222899\n",
      "train loss:0.0003269869433279313\n",
      "train loss:0.0010237172108497217\n",
      "train loss:0.002440349964254861\n",
      "train loss:0.002203192935748501\n",
      "train loss:0.010413335559241826\n",
      "train loss:0.012376441705968879\n",
      "train loss:0.000949493419754972\n",
      "train loss:0.00031010100242568147\n",
      "train loss:0.002373260682821914\n",
      "train loss:0.0020202886763260766\n",
      "train loss:0.003175619533334336\n",
      "train loss:0.0006547801964510784\n",
      "train loss:0.0052482772002724375\n",
      "train loss:0.02629791032233864\n",
      "train loss:0.006722043150714843\n",
      "train loss:0.0004282727350327258\n",
      "train loss:0.0016532882995920258\n",
      "train loss:0.001626321391629777\n",
      "train loss:0.0011574821825524832\n",
      "train loss:0.0007491698207195076\n",
      "train loss:0.04732062727987048\n",
      "train loss:0.008260631580639709\n",
      "train loss:0.0031807409482654068\n",
      "train loss:0.008919197003233981\n",
      "train loss:0.0007918409625968042\n",
      "=== epoch:15, train acc:0.999, test acc:0.986 ===\n",
      "train loss:0.0012713878782916101\n",
      "train loss:0.0018127275369638244\n",
      "train loss:0.0051878808040039205\n",
      "train loss:0.0017683646144897682\n",
      "train loss:0.0014239751164971132\n",
      "train loss:0.0002432664667492987\n",
      "train loss:0.00798347447794072\n",
      "train loss:0.008238416477037266\n",
      "train loss:0.0016041843830964578\n",
      "train loss:0.0009256882817095166\n",
      "train loss:0.0004319494903492458\n",
      "train loss:0.0011698842313528249\n",
      "train loss:0.0037800776549080754\n",
      "train loss:0.0007497410065170206\n",
      "train loss:0.003208627487322291\n",
      "train loss:0.002792528749250828\n",
      "train loss:0.0008543808510010947\n",
      "train loss:0.0005987634672904463\n",
      "train loss:0.0035916554661117282\n",
      "train loss:0.0006958994757420889\n",
      "train loss:0.0013239916852924602\n",
      "train loss:0.0022925939183409873\n",
      "train loss:0.011052694452915356\n",
      "train loss:0.0016093532344538001\n",
      "train loss:0.009171222222346474\n",
      "train loss:0.006552384469416404\n",
      "train loss:0.00025661766287009665\n",
      "train loss:0.0010337289329428612\n",
      "train loss:0.0007008237861219945\n",
      "train loss:0.0032760898359390366\n",
      "train loss:0.000648564432977773\n",
      "train loss:0.0007751067489208004\n",
      "train loss:0.008805955532521843\n",
      "train loss:0.003370373269042182\n",
      "train loss:0.0029071508806815\n",
      "train loss:0.0027573921004126556\n",
      "train loss:0.00036573452555872517\n",
      "train loss:0.002304373522399798\n",
      "train loss:0.005520376251928223\n",
      "train loss:0.003882046445349513\n",
      "train loss:0.0004925864164858682\n",
      "train loss:0.003369434686680517\n",
      "train loss:0.000816220968580277\n",
      "train loss:0.0014040964458982245\n",
      "train loss:0.002906081081772503\n",
      "train loss:0.009252774326453836\n",
      "train loss:0.001306519934400484\n",
      "train loss:0.0009395045143741704\n",
      "train loss:0.0006856699912805011\n",
      "train loss:0.0007052935918043313\n",
      "train loss:0.006254370264178858\n",
      "train loss:0.005220857711785359\n",
      "train loss:0.00029992761337195454\n",
      "train loss:0.0005413650792692612\n",
      "train loss:0.00446869571952046\n",
      "train loss:0.001511318430802129\n",
      "train loss:0.0011013556415483934\n",
      "train loss:0.0005211991782996949\n",
      "train loss:0.0018728194036423127\n",
      "train loss:0.0008830911624480268\n",
      "train loss:0.002160667276698388\n",
      "train loss:0.0003532558611380007\n",
      "train loss:0.0020951357635905997\n",
      "train loss:0.0026809449068150486\n",
      "train loss:0.001580151602597023\n",
      "train loss:0.001222578796855073\n",
      "train loss:0.0024230450647721403\n",
      "train loss:0.00019326354276928137\n",
      "train loss:0.002825365471796347\n",
      "train loss:0.011231456645572962\n",
      "train loss:0.0017879510364871309\n",
      "train loss:0.0032590703473846117\n",
      "train loss:0.0004034533826349232\n",
      "train loss:0.0007486404223151444\n",
      "train loss:0.0005658040199268496\n",
      "train loss:0.0025918043536377194\n",
      "train loss:0.0036139841591229234\n",
      "train loss:0.0013540654503938802\n",
      "train loss:0.0003252062059487534\n",
      "train loss:0.0013089701692002523\n",
      "train loss:0.004448980172447962\n",
      "train loss:0.0013885908468188118\n",
      "train loss:0.001178306880385447\n",
      "train loss:0.00025383492905683134\n",
      "train loss:0.0007865191320715583\n",
      "train loss:0.0004885809819588624\n",
      "train loss:0.0010671922994587154\n",
      "train loss:0.0109108097597777\n",
      "train loss:0.0005594413149170344\n",
      "train loss:0.0013534273456234918\n",
      "train loss:0.0017812241658317434\n",
      "train loss:0.0007292736789146565\n",
      "train loss:0.0007161697130943724\n",
      "train loss:0.001909786675344016\n",
      "train loss:0.005723541874291381\n",
      "train loss:0.0007170615633757116\n",
      "train loss:0.0007208029956486736\n",
      "train loss:0.0023786348416076535\n",
      "train loss:0.00799633145729278\n",
      "train loss:0.005317859202573633\n",
      "train loss:0.0008292734068866221\n",
      "train loss:0.0007939076852628012\n",
      "train loss:0.005331031806415711\n",
      "train loss:0.0007654433150548495\n",
      "train loss:0.0014249473850287782\n",
      "train loss:0.007934907242800817\n",
      "train loss:0.0021015754897380605\n",
      "train loss:0.0033709849509433757\n",
      "train loss:0.0110078151584208\n",
      "train loss:0.0020459853685241463\n",
      "train loss:0.002187051931337482\n",
      "train loss:0.00014681139823205757\n",
      "train loss:0.00029869131274696306\n",
      "train loss:0.003797545220817584\n",
      "train loss:0.002203664125734449\n",
      "train loss:0.001346105151155747\n",
      "train loss:0.007835103585146861\n",
      "train loss:0.005334815246475349\n",
      "train loss:0.0018603116184029431\n",
      "train loss:0.00014708619697499975\n",
      "train loss:0.016587380107210028\n",
      "train loss:0.0004477049772140946\n",
      "train loss:0.0006214904852937634\n",
      "train loss:0.0008370930131870684\n",
      "train loss:0.00011995219006986393\n",
      "train loss:0.039641400702373625\n",
      "train loss:0.00040748869897594577\n",
      "train loss:0.001836619800576031\n",
      "train loss:0.0009861578073763904\n",
      "train loss:0.0025646457247525682\n",
      "train loss:0.004015145103291683\n",
      "train loss:0.0883991139057063\n",
      "train loss:0.040652917863244674\n",
      "train loss:0.0015983469605830964\n",
      "train loss:0.0003840994126516599\n",
      "train loss:0.0007103587521920403\n",
      "train loss:0.004185393530418103\n",
      "train loss:0.0005979331653531621\n",
      "train loss:0.0021944920648171128\n",
      "train loss:0.00010502127047816762\n",
      "train loss:0.012573398177818662\n",
      "train loss:0.000312385343825702\n",
      "train loss:0.0001601627251127749\n",
      "train loss:0.0030524924812761257\n",
      "train loss:0.015167293511814436\n",
      "train loss:0.0024506805546325922\n",
      "train loss:0.0013210718803406886\n",
      "train loss:0.006005933336641749\n",
      "train loss:0.0005547796096755819\n",
      "train loss:0.002336305310483634\n",
      "train loss:0.0003383152770292224\n",
      "train loss:0.0008564029692012006\n",
      "train loss:0.00022267714408804316\n",
      "train loss:0.00048690371816496864\n",
      "train loss:0.0012436495770812828\n",
      "train loss:0.0003501604009107822\n",
      "train loss:0.0010571134552905463\n",
      "train loss:0.0011526850020625924\n",
      "train loss:0.002741311857552063\n",
      "train loss:0.015486389608397448\n",
      "train loss:0.0019032533075077085\n",
      "train loss:0.0005101552921884221\n",
      "train loss:0.0012261916227805094\n",
      "train loss:0.0065698819885185115\n",
      "train loss:0.0012074173312843644\n",
      "train loss:0.004596363947419003\n",
      "train loss:0.02417417449340238\n",
      "train loss:0.0004562515485558377\n",
      "train loss:0.0006121607319078855\n",
      "train loss:0.0014271375598074868\n",
      "train loss:0.001684351524355204\n",
      "train loss:0.004821965433770381\n",
      "train loss:0.0028047878048351304\n",
      "train loss:0.0011596410522960857\n",
      "train loss:0.001975668232628205\n",
      "train loss:0.0011188981890974882\n",
      "train loss:0.0033323898947314563\n",
      "train loss:0.0019226320504476776\n",
      "train loss:0.011785316045123815\n",
      "train loss:0.0021668863911786067\n",
      "train loss:0.0028069954359930273\n",
      "train loss:0.0006520513532826292\n",
      "train loss:0.0013972029347564252\n",
      "train loss:0.013924198156896167\n",
      "train loss:0.007612646872939238\n",
      "train loss:0.0028167035306797665\n",
      "train loss:0.0007017859908873932\n",
      "train loss:0.0030579761916020996\n",
      "train loss:0.004805148395622166\n",
      "train loss:0.0038454237316414923\n",
      "train loss:0.000537025971572202\n",
      "train loss:0.0030570774352254013\n",
      "train loss:0.0003696753407608368\n",
      "train loss:0.003530361924483327\n",
      "train loss:0.006991514593160953\n",
      "train loss:0.0006949173792964745\n",
      "train loss:0.0006081169062338642\n",
      "train loss:0.00387967089490882\n",
      "train loss:0.0015225030382064642\n",
      "train loss:0.0008634876350821109\n",
      "train loss:0.0016721522577692535\n",
      "train loss:0.006642815253665763\n",
      "train loss:0.007517030746862009\n",
      "train loss:0.0016206505567760354\n",
      "train loss:0.0008477270800652283\n",
      "train loss:0.00017518504399532242\n",
      "train loss:0.003036369741822902\n",
      "train loss:0.0008334556575926874\n",
      "train loss:0.001002363655210171\n",
      "train loss:0.005083326677351852\n",
      "train loss:0.0006394460267401475\n",
      "train loss:7.537242036407394e-05\n",
      "train loss:0.0012484468160174117\n",
      "train loss:0.006001862887943002\n",
      "train loss:0.0032768831298067504\n",
      "train loss:0.0008328883607289189\n",
      "train loss:0.0005797714649197179\n",
      "train loss:0.000427536967514323\n",
      "train loss:0.0027665203569368097\n",
      "train loss:0.011124699716256682\n",
      "train loss:0.0021597287268559904\n",
      "train loss:0.0018663426681807262\n",
      "train loss:0.0017973371522520384\n",
      "train loss:0.0011752862133729224\n",
      "train loss:0.01237835275498339\n",
      "train loss:0.002775162601038354\n",
      "train loss:0.0003559953269254395\n",
      "train loss:0.00812853662145916\n",
      "train loss:0.0016742849742929279\n",
      "train loss:0.0018730294371258347\n",
      "train loss:0.0019658291187067685\n",
      "train loss:0.00515802959330744\n",
      "train loss:0.0027278092951609\n",
      "train loss:0.0012466235975249363\n",
      "train loss:0.0007340518485290546\n",
      "train loss:0.006345241234312572\n",
      "train loss:0.0003833247516428765\n",
      "train loss:0.0009818588320146167\n",
      "train loss:0.0001252257494299331\n",
      "train loss:0.0015385034615920364\n",
      "train loss:0.007023713085702761\n",
      "train loss:0.0013352179644149887\n",
      "train loss:0.014815579707268963\n",
      "train loss:0.00018840755523725136\n",
      "train loss:0.005519482805256889\n",
      "train loss:0.011197894252239745\n",
      "train loss:0.00218164103734416\n",
      "train loss:0.0018371998051297986\n",
      "train loss:0.003992928925923893\n",
      "train loss:0.000256942472666534\n",
      "train loss:0.001116220409619046\n",
      "train loss:0.010266904145501991\n",
      "train loss:0.012074016620666969\n",
      "train loss:0.0060952783069374026\n",
      "train loss:0.0018427972853140744\n",
      "train loss:0.002304838848444423\n",
      "train loss:0.0006639224091059844\n",
      "train loss:0.001207556240308898\n",
      "train loss:0.0019163245981819853\n",
      "train loss:0.011603705822961148\n",
      "train loss:0.006672982780893779\n",
      "train loss:0.00675675796913968\n",
      "train loss:0.0025590705970804876\n",
      "train loss:0.017733285448007473\n",
      "train loss:0.0007143144198793203\n",
      "train loss:0.003292775399542383\n",
      "train loss:0.005222657978275774\n",
      "train loss:0.002123470567696741\n",
      "train loss:0.0022593654917822067\n",
      "train loss:0.0012845957966253494\n",
      "train loss:0.0012450396066118973\n",
      "train loss:0.001688564757204507\n",
      "train loss:0.005108316538267789\n",
      "train loss:0.01662801037814969\n",
      "train loss:0.0001893096148120191\n",
      "train loss:0.010864902254430335\n",
      "train loss:0.004421575814802115\n",
      "train loss:0.006451125177695739\n",
      "train loss:0.001167109456709726\n",
      "train loss:0.0008787663285446458\n",
      "train loss:0.004541438818898267\n",
      "train loss:0.0011933462139908186\n",
      "train loss:0.0009011231181728992\n",
      "train loss:0.0005945023411069645\n",
      "train loss:0.0006974532536251581\n",
      "train loss:0.0037855584021913476\n",
      "train loss:0.003675279691034576\n",
      "train loss:0.00885948223419286\n",
      "train loss:0.0001905877856473295\n",
      "train loss:0.002443000450050819\n",
      "train loss:0.0019427157312570664\n",
      "train loss:0.003646451851935013\n",
      "train loss:0.014217677871898286\n",
      "train loss:0.0034125316534194066\n",
      "train loss:0.0012429779455172326\n",
      "train loss:0.001411500259174451\n",
      "train loss:0.0014124219236430985\n",
      "train loss:0.0007008195403071528\n",
      "train loss:0.0014016453721750984\n",
      "train loss:0.002702752908273913\n",
      "train loss:0.0013133682349145165\n",
      "train loss:0.0027016057263696573\n",
      "train loss:0.0021237777636298146\n",
      "train loss:0.002148090152426946\n",
      "train loss:0.0058953307247661055\n",
      "train loss:0.001644168505792484\n",
      "train loss:0.0010224393714794511\n",
      "train loss:0.0028155360441337205\n",
      "train loss:0.0802263603880436\n",
      "train loss:0.02238827979937324\n",
      "train loss:0.004375339274556613\n",
      "train loss:0.003662984181193927\n",
      "train loss:0.0021309314740578476\n",
      "train loss:0.002251092970394173\n",
      "train loss:0.0054071555637141\n",
      "train loss:0.001725947449986942\n",
      "train loss:0.000377505075435427\n",
      "train loss:0.004816312649355092\n",
      "train loss:0.001621288907234104\n",
      "train loss:0.005533903255123917\n",
      "train loss:0.0008660252410927784\n",
      "train loss:0.0004202464371685354\n",
      "train loss:0.0007809208675526322\n",
      "train loss:0.00034839299455837727\n",
      "train loss:0.0021927676248374365\n",
      "train loss:0.0019642448069004366\n",
      "train loss:0.00042620021585049634\n",
      "train loss:0.0009370657934236876\n",
      "train loss:0.0061060815818971045\n",
      "train loss:0.003794651513525573\n",
      "train loss:0.001182818377692386\n",
      "train loss:0.010526257053863538\n",
      "train loss:0.0017095800523252117\n",
      "train loss:0.005962928845779168\n",
      "train loss:0.0027159417487970464\n",
      "train loss:0.0013090674038014202\n",
      "train loss:0.0015328929142018808\n",
      "train loss:0.0041858993486918825\n",
      "train loss:0.0033182787941477138\n",
      "train loss:0.0024251381496389907\n",
      "train loss:0.0039858765418999105\n",
      "train loss:0.00045048598397403694\n",
      "train loss:0.0005043551666963442\n",
      "train loss:0.0036162764723235833\n",
      "train loss:0.0008566342256278\n",
      "train loss:0.0009523447050257103\n",
      "train loss:0.0017972064304974287\n",
      "train loss:0.0010708518238729237\n",
      "train loss:0.0005793679144682241\n",
      "train loss:0.0020189307206463307\n",
      "train loss:0.002533211412383932\n",
      "train loss:0.0024729436314749175\n",
      "train loss:0.005664848861085521\n",
      "train loss:0.002533070861956515\n",
      "train loss:0.0015435822011830216\n",
      "train loss:0.00019434148350701869\n",
      "train loss:0.0012154510780570083\n",
      "train loss:0.008734300503390292\n",
      "train loss:0.0011000809119712936\n",
      "train loss:0.005735756339124825\n",
      "train loss:0.0006997074745578219\n",
      "train loss:0.005473799814337072\n",
      "train loss:0.00023295385168084804\n",
      "train loss:0.009737310181182927\n",
      "train loss:0.0010830604571369586\n",
      "train loss:0.0004179920880877125\n",
      "train loss:0.0011778497315951698\n",
      "train loss:0.001648254670795635\n",
      "train loss:0.005467152279521821\n",
      "train loss:0.0019543343628931975\n",
      "train loss:0.0003472072245938858\n",
      "train loss:0.002472152421216968\n",
      "train loss:0.0012583034240399417\n",
      "train loss:0.00041055350876311494\n",
      "train loss:0.0011627933885591832\n",
      "train loss:0.0013530900026939058\n",
      "train loss:0.0012742267480264802\n",
      "train loss:0.006964651124527456\n",
      "train loss:0.001687944112009672\n",
      "train loss:0.0021153975753030515\n",
      "train loss:0.001526171136069721\n",
      "train loss:0.0013110501242909118\n",
      "train loss:0.00033016152625835844\n",
      "train loss:0.0008607322064407533\n",
      "train loss:0.007008781614035024\n",
      "train loss:0.0030749025659175537\n",
      "train loss:0.02432674271809568\n",
      "train loss:0.004620824174654768\n",
      "train loss:0.0022618409708752285\n",
      "train loss:0.0004953715028073382\n",
      "train loss:0.005278398291205407\n",
      "train loss:0.00019950053921523358\n",
      "train loss:0.0076530824093824276\n",
      "train loss:0.01708105858966371\n",
      "train loss:0.0004509495347494982\n",
      "train loss:0.002050136495250922\n",
      "train loss:0.0019432139137392206\n",
      "train loss:0.0005460727454777004\n",
      "train loss:0.0005111477433580977\n",
      "train loss:0.01013953290426767\n",
      "train loss:0.001544339747977743\n",
      "train loss:0.001316184583019474\n",
      "train loss:0.0005467035944672942\n",
      "train loss:0.002709813157471065\n",
      "train loss:0.0006526682898100871\n",
      "train loss:0.00015500419214452355\n",
      "train loss:0.0005007394536637642\n",
      "train loss:0.003635194604111836\n",
      "train loss:0.0005592778554218816\n",
      "train loss:0.004196076226892354\n",
      "train loss:0.0007387823824110507\n",
      "train loss:0.00011023946319277072\n",
      "train loss:0.0008732361970650423\n",
      "train loss:0.0002925510720443579\n",
      "train loss:0.0008835859512826347\n",
      "train loss:0.0007386886870855715\n",
      "train loss:0.0004698815274882211\n",
      "train loss:0.00280379344077168\n",
      "train loss:0.00011558953532687146\n",
      "train loss:0.0009051635339220073\n",
      "train loss:0.007858298819149644\n",
      "train loss:0.001710948140439857\n",
      "train loss:0.0005481643905732543\n",
      "train loss:0.010063099408750243\n",
      "train loss:0.00017242747969919666\n",
      "train loss:0.002657394696439362\n",
      "train loss:0.0045221634510426755\n",
      "train loss:0.000926348521136097\n",
      "train loss:0.0054062803145202174\n",
      "train loss:0.0013205260426237839\n",
      "train loss:0.00031307392034985446\n",
      "train loss:0.00019382737874774417\n",
      "train loss:0.003136236653245118\n",
      "train loss:0.0014574105670451102\n",
      "train loss:0.0008648758074280963\n",
      "train loss:0.004864234324435312\n",
      "train loss:0.0030775928523549857\n",
      "train loss:0.0010956664388714421\n",
      "train loss:0.0009912865066418308\n",
      "train loss:0.0019030817658383448\n",
      "train loss:0.0065770691604423925\n",
      "train loss:0.00018499626542730542\n",
      "train loss:0.0021320723812815125\n",
      "train loss:0.0026439082231778364\n",
      "train loss:0.0006989226280923933\n",
      "train loss:0.001918781826066065\n",
      "train loss:0.0036391279758278563\n",
      "train loss:0.0016905559487039026\n",
      "train loss:0.0011035151519364177\n",
      "train loss:0.0589169538182745\n",
      "train loss:0.0010481590323143683\n",
      "train loss:0.0010245628352878308\n",
      "train loss:0.0031968412938516103\n",
      "train loss:0.0019877215926365453\n",
      "train loss:0.00026786162207653887\n",
      "train loss:0.011538588325441211\n",
      "train loss:0.003630169790211471\n",
      "train loss:0.0001691239097862589\n",
      "train loss:8.301037491928608e-05\n",
      "train loss:0.0007766883804034995\n",
      "train loss:0.0005485247826411682\n",
      "train loss:0.005052812671829271\n",
      "train loss:0.005966490402268115\n",
      "train loss:0.004129192483722894\n",
      "train loss:0.0010530119354784607\n",
      "train loss:0.0020879775055031593\n",
      "train loss:0.007488866926087983\n",
      "train loss:0.0036515740419827214\n",
      "train loss:0.0004462945227023771\n",
      "train loss:0.00023050619589484497\n",
      "train loss:0.0023182056365820144\n",
      "train loss:0.009150336519844503\n",
      "train loss:0.038134643791157025\n",
      "train loss:0.0018087697205096233\n",
      "train loss:0.0033936258212915343\n",
      "train loss:0.001846100627352691\n",
      "train loss:0.005906942842137942\n",
      "train loss:0.00543935153242325\n",
      "train loss:0.0010434808682471645\n",
      "train loss:0.0047936387391421965\n",
      "train loss:0.0036456329594846417\n",
      "train loss:0.0013596385022618597\n",
      "train loss:0.0035724086059428905\n",
      "train loss:0.0007067172537255216\n",
      "train loss:0.0006224914142346518\n",
      "train loss:0.0016665887280965927\n",
      "train loss:0.01858596952122617\n",
      "train loss:0.0019811745660665487\n",
      "train loss:0.0043173779648061255\n",
      "train loss:0.0016371024662444275\n",
      "train loss:0.0003244609518409646\n",
      "train loss:0.0007799346727771324\n",
      "train loss:0.015386619390852712\n",
      "train loss:0.00668729265103057\n",
      "train loss:0.0007740991157021628\n",
      "train loss:0.004228075059383239\n",
      "train loss:0.0005492569037589807\n",
      "train loss:0.00018161707212266572\n",
      "train loss:0.0034205809184923047\n",
      "train loss:0.00037897647348968127\n",
      "train loss:0.004078278019224518\n",
      "train loss:0.001813975114509244\n",
      "train loss:0.004101231400695229\n",
      "train loss:0.0003955927220221305\n",
      "train loss:0.00041053513017775525\n",
      "train loss:0.0005206667462428773\n",
      "train loss:0.0005501215101819067\n",
      "train loss:0.002610493249971852\n",
      "train loss:0.0024815373640912483\n",
      "train loss:0.002753845353498024\n",
      "train loss:0.002619329529308513\n",
      "train loss:0.006457381054298525\n",
      "train loss:0.0013662196138540452\n",
      "train loss:0.0005109964630147769\n",
      "train loss:0.01674184445381674\n",
      "train loss:0.0013404925803455294\n",
      "train loss:0.0017396210850327749\n",
      "train loss:0.0020061140376189624\n",
      "train loss:0.000913641516298181\n",
      "train loss:0.0016069864823680502\n",
      "train loss:0.004593175228691376\n",
      "train loss:0.0035941983802716994\n",
      "train loss:0.002627324586338092\n",
      "train loss:0.0013044693834120163\n",
      "train loss:0.004261357128032969\n",
      "train loss:0.005210936385961877\n",
      "train loss:0.004743416038283901\n",
      "train loss:4.428428594079708e-05\n",
      "train loss:0.004504297033312931\n",
      "train loss:0.00014877086398131122\n",
      "train loss:0.0010885001551972876\n",
      "train loss:0.01971073379118882\n",
      "train loss:0.013375899238266162\n",
      "train loss:0.0024437802531802667\n",
      "train loss:0.0006178281017269698\n",
      "train loss:0.0008969080699930004\n",
      "train loss:0.0009680543771393946\n",
      "train loss:0.000680101307162089\n",
      "train loss:0.001955680143948911\n",
      "train loss:0.003213849844615055\n",
      "train loss:0.020536199440262283\n",
      "train loss:0.004921491554296714\n",
      "train loss:0.0026110800363455013\n",
      "train loss:0.0002379060890962608\n",
      "train loss:0.0007274823431356618\n",
      "train loss:0.006222182002936921\n",
      "train loss:0.006003726016153641\n",
      "train loss:0.004944501249152652\n",
      "train loss:0.002743134772763403\n",
      "train loss:0.0011151258463224464\n",
      "train loss:0.005394149128756786\n",
      "train loss:0.0106285787970362\n",
      "train loss:0.00343942351680439\n",
      "train loss:0.004547672297270589\n",
      "train loss:0.0008432510896130305\n",
      "train loss:0.001827835769230768\n",
      "train loss:0.0009700277847904561\n",
      "train loss:0.004196424541317867\n",
      "train loss:0.0016467406251241621\n",
      "train loss:0.0008427120154427211\n",
      "train loss:0.015040612967056317\n",
      "train loss:0.0046907292871589505\n",
      "train loss:0.0034597033256505184\n",
      "train loss:0.0013173718713484343\n",
      "train loss:0.004901378003189377\n",
      "train loss:0.0036759811543693776\n",
      "train loss:0.002842439780811771\n",
      "train loss:0.0009496727249355561\n",
      "train loss:0.0010464503196122112\n",
      "train loss:0.001941600326045265\n",
      "train loss:0.001751082559346372\n",
      "train loss:0.002444441617830607\n",
      "train loss:0.0070575605073682855\n",
      "train loss:0.003454061034174617\n",
      "train loss:0.028552701263222312\n",
      "train loss:0.003270081677702812\n",
      "train loss:2.7245633367051325e-05\n",
      "train loss:0.004061835460701011\n",
      "train loss:0.0011799696697005627\n",
      "train loss:0.0005226415193066692\n",
      "train loss:0.0007374129721752003\n",
      "train loss:0.0038073476124022097\n",
      "train loss:0.0077672610938860544\n",
      "train loss:0.008822348728808292\n",
      "train loss:0.002302618925824881\n",
      "train loss:0.00011467319202796863\n",
      "train loss:0.008242420139945989\n",
      "train loss:0.0025718509947886903\n",
      "train loss:0.0009007115093554165\n",
      "train loss:0.007495832367371807\n",
      "train loss:0.0026785835321167374\n",
      "train loss:0.009122189710720928\n",
      "train loss:0.003304557348087844\n",
      "train loss:0.0009376891101760564\n",
      "train loss:0.00487374690485093\n",
      "train loss:0.002138668620017902\n",
      "train loss:0.0007946937233930513\n",
      "train loss:0.003369641603516382\n",
      "train loss:0.0015090467115440164\n",
      "train loss:0.004424493917708236\n",
      "=== epoch:16, train acc:0.998, test acc:0.985 ===\n",
      "train loss:0.0006270503998068027\n",
      "train loss:0.00035230656479426516\n",
      "train loss:0.002923329763420526\n",
      "train loss:0.003766866987014095\n",
      "train loss:0.01120701323305199\n",
      "train loss:0.003975974749306899\n",
      "train loss:0.001971075731287741\n",
      "train loss:0.0008976463259908727\n",
      "train loss:0.00036696490765767933\n",
      "train loss:0.0032173094792776625\n",
      "train loss:0.0008273150201218904\n",
      "train loss:0.0007372458076332788\n",
      "train loss:0.0016743872014172005\n",
      "train loss:0.02932904712034974\n",
      "train loss:0.0011381625488112975\n",
      "train loss:0.04199619899891742\n",
      "train loss:0.0009972327744891681\n",
      "train loss:0.00048470812239666565\n",
      "train loss:0.0009238369608458209\n",
      "train loss:0.002746747646324072\n",
      "train loss:0.0023301155927735275\n",
      "train loss:0.003505809367609434\n",
      "train loss:0.011653233996195762\n",
      "train loss:0.001054808013508701\n",
      "train loss:0.002414738332661033\n",
      "train loss:0.00047387420567272494\n",
      "train loss:0.0012703052086277021\n",
      "train loss:0.031124992694040947\n",
      "train loss:0.0002573233634441931\n",
      "train loss:0.0017111742474423732\n",
      "train loss:0.0018350627763826885\n",
      "train loss:0.027701534437722167\n",
      "train loss:0.006116070833635289\n",
      "train loss:0.002830923513163302\n",
      "train loss:0.021170724830941554\n",
      "train loss:0.0002324947435275048\n",
      "train loss:0.0005408381537086492\n",
      "train loss:0.0013896004968920628\n",
      "train loss:0.0063553296351558305\n",
      "train loss:0.0006398146488944673\n",
      "train loss:0.001748687581241641\n",
      "train loss:0.00014108472841056963\n",
      "train loss:0.0004690094253791663\n",
      "train loss:0.00930176987170528\n",
      "train loss:0.0007775603103901853\n",
      "train loss:0.0008076333013629023\n",
      "train loss:0.0011281390834107718\n",
      "train loss:0.004226060240919801\n",
      "train loss:0.0007154092713831314\n",
      "train loss:0.00026688018642055336\n",
      "train loss:0.0011232363100167426\n",
      "train loss:0.002233497604991524\n",
      "train loss:0.004922921322081972\n",
      "train loss:0.00015438908409016208\n",
      "train loss:0.0006689187961793947\n",
      "train loss:0.0011319483785964786\n",
      "train loss:0.0023076091642039573\n",
      "train loss:0.00028064451292735465\n",
      "train loss:0.0019901880995598416\n",
      "train loss:0.0020755995922632363\n",
      "train loss:0.0003368603891130479\n",
      "train loss:0.028938628899817992\n",
      "train loss:0.0016797850712222855\n",
      "train loss:0.0011137710653379524\n",
      "train loss:0.006174302539917262\n",
      "train loss:0.0008876865694046121\n",
      "train loss:0.0003537210919027637\n",
      "train loss:0.0007000549317195502\n",
      "train loss:0.000726151071207095\n",
      "train loss:0.0011270662890457788\n",
      "train loss:0.0012005682415566162\n",
      "train loss:0.0008908935909667237\n",
      "train loss:0.0028232867539327417\n",
      "train loss:0.0016833780710790607\n",
      "train loss:0.0002306618940150948\n",
      "train loss:0.02365073810975606\n",
      "train loss:0.0006596732919990575\n",
      "train loss:0.00025088812785555167\n",
      "train loss:0.0008670722538000025\n",
      "train loss:0.0004801853728421983\n",
      "train loss:0.004233121120521493\n",
      "train loss:0.00026205219328153415\n",
      "train loss:0.00012609974474208258\n",
      "train loss:0.0038413120808135463\n",
      "train loss:0.0065233745880892355\n",
      "train loss:0.00321772474275389\n",
      "train loss:0.0033089333580247943\n",
      "train loss:0.0037300844948416428\n",
      "train loss:0.0016560757921832525\n",
      "train loss:0.012365798276362097\n",
      "train loss:0.0023552117712664655\n",
      "train loss:0.0008749435103322578\n",
      "train loss:0.0005488454329359659\n",
      "train loss:0.007331501685197738\n",
      "train loss:0.00020160091906831022\n",
      "train loss:0.00045617906762736624\n",
      "train loss:0.0005895729005057844\n",
      "train loss:0.00018405557521006957\n",
      "train loss:0.005366113869747242\n",
      "train loss:0.0007065311950790317\n",
      "train loss:0.0037446418353805945\n",
      "train loss:0.0012553960883913305\n",
      "train loss:0.0009263724389122685\n",
      "train loss:0.005738265565467906\n",
      "train loss:0.004477759458030325\n",
      "train loss:0.001106685854292725\n",
      "train loss:0.002961884168724758\n",
      "train loss:0.0018290668184052753\n",
      "train loss:0.001140511550865233\n",
      "train loss:0.0010221829706579173\n",
      "train loss:0.0036367228973440435\n",
      "train loss:0.0407794369931035\n",
      "train loss:0.005097622296298866\n",
      "train loss:0.0013803444504322043\n",
      "train loss:0.0017177735925693377\n",
      "train loss:0.0025610909922213977\n",
      "train loss:0.000662005538880775\n",
      "train loss:0.0005600294776173014\n",
      "train loss:0.0009369476829632791\n",
      "train loss:0.003311071980411747\n",
      "train loss:0.006558411749743086\n",
      "train loss:0.0005776336037201072\n",
      "train loss:0.00023228248605260138\n",
      "train loss:0.00572148604507209\n",
      "train loss:0.005832999533834499\n",
      "train loss:0.0015365759499468626\n",
      "train loss:0.000772150372030172\n",
      "train loss:0.001553741702960617\n",
      "train loss:0.0005218922175749981\n",
      "train loss:0.0010364107633404076\n",
      "train loss:0.005521103058584499\n",
      "train loss:0.0019193459715603149\n",
      "train loss:0.0223413629558068\n",
      "train loss:0.0017442871050912594\n",
      "train loss:0.0006728963543589625\n",
      "train loss:0.0016667241606603488\n",
      "train loss:0.0013711351074689757\n",
      "train loss:0.0025266126047024107\n",
      "train loss:0.0012374014000565115\n",
      "train loss:0.0003155542657305666\n",
      "train loss:0.000593710052475275\n",
      "train loss:0.00236102557257483\n",
      "train loss:0.0010394902885486335\n",
      "train loss:0.00011131737334871766\n",
      "train loss:0.0032916451439207704\n",
      "train loss:0.002168383671570062\n",
      "train loss:0.007455443236376074\n",
      "train loss:0.0016603149678852175\n",
      "train loss:0.0008369501383951855\n",
      "train loss:0.0006231928488955863\n",
      "train loss:0.002069503741661617\n",
      "train loss:0.010337304495633722\n",
      "train loss:0.0002456571230244028\n",
      "train loss:0.00046474056191374963\n",
      "train loss:0.0011736729860542267\n",
      "train loss:0.0024425208766846816\n",
      "train loss:0.00032490153175828676\n",
      "train loss:0.0010365931571809177\n",
      "train loss:0.0011207625340578795\n",
      "train loss:0.0016813410264002013\n",
      "train loss:0.0022251973725504358\n",
      "train loss:0.001240401588133685\n",
      "train loss:0.001579926371621138\n",
      "train loss:0.001173686872421053\n",
      "train loss:0.0013399603800217541\n",
      "train loss:0.002421805275697511\n",
      "train loss:0.0024824463178498442\n",
      "train loss:0.008748737283844456\n",
      "train loss:0.001787293911206776\n",
      "train loss:0.003445979430727345\n",
      "train loss:0.002070408020523634\n",
      "train loss:0.005626953580386555\n",
      "train loss:0.0007717731408936742\n",
      "train loss:0.0014618414935984871\n",
      "train loss:0.0028939735528985947\n",
      "train loss:0.000904569137215516\n",
      "train loss:0.0026345179793442436\n",
      "train loss:0.0012112044907487158\n",
      "train loss:0.003928127600028061\n",
      "train loss:0.0013772954521688147\n",
      "train loss:0.0009956346457862452\n",
      "train loss:0.004640016204574505\n",
      "train loss:0.0008090917008963592\n",
      "train loss:0.0075879059901410775\n",
      "train loss:0.0005368761599556677\n",
      "train loss:0.002100777770360705\n",
      "train loss:0.0012183128749984435\n",
      "train loss:0.011143240311598851\n",
      "train loss:0.006065954992092401\n",
      "train loss:0.0028392452315153466\n",
      "train loss:0.0037378735307042636\n",
      "train loss:0.001069659312900444\n",
      "train loss:0.009683958657526245\n",
      "train loss:0.001042797935285955\n",
      "train loss:0.007447166766105336\n",
      "train loss:0.0024074290981115323\n",
      "train loss:0.010749309922624729\n",
      "train loss:0.0016942884859507156\n",
      "train loss:0.0010209185632603101\n",
      "train loss:0.004008590722047608\n",
      "train loss:0.001393943520873321\n",
      "train loss:0.0007094861379525151\n",
      "train loss:0.0006042420169166489\n",
      "train loss:0.0021761196193225618\n",
      "train loss:0.0008248588473672025\n",
      "train loss:0.0005990290064592925\n",
      "train loss:0.007098890972849243\n",
      "train loss:0.002909643934438881\n",
      "train loss:0.0016059569059288204\n",
      "train loss:0.0018139998311145506\n",
      "train loss:0.0030334843363103905\n",
      "train loss:0.00033509764821294113\n",
      "train loss:0.010085722964880061\n",
      "train loss:0.0007985169709822531\n",
      "train loss:0.005228767279010326\n",
      "train loss:0.0027205019325950517\n",
      "train loss:0.0006026743434154639\n",
      "train loss:0.007106925906081069\n",
      "train loss:0.0019560026688831126\n",
      "train loss:0.0026897916835743416\n",
      "train loss:0.00021661697896808923\n",
      "train loss:0.0211584292618165\n",
      "train loss:0.0019423898575420488\n",
      "train loss:0.0013305083202151326\n",
      "train loss:0.0017009442374435629\n",
      "train loss:0.0033790932017191346\n",
      "train loss:0.004688921796466168\n",
      "train loss:0.002859477227593553\n",
      "train loss:0.00011657057630737334\n",
      "train loss:0.001021240250033184\n",
      "train loss:0.005394292276115022\n",
      "train loss:0.0007802140555361889\n",
      "train loss:0.0004901645599472384\n",
      "train loss:0.00390207448608813\n",
      "train loss:0.002436997416869494\n",
      "train loss:0.003384174032882631\n",
      "train loss:9.973470116863183e-05\n",
      "train loss:0.0012246836926463238\n",
      "train loss:0.0022644438829121575\n",
      "train loss:0.0013732154348627395\n",
      "train loss:0.0013442609235542974\n",
      "train loss:0.0006105475606092655\n",
      "train loss:0.001388166980866118\n",
      "train loss:0.005646745064942923\n",
      "train loss:0.0037140608140400415\n",
      "train loss:0.0005477380944208457\n",
      "train loss:0.0033572167694619864\n",
      "train loss:0.0019023347663975232\n",
      "train loss:0.002363127891505257\n",
      "train loss:0.002408316354283777\n",
      "train loss:0.0023327910459165924\n",
      "train loss:0.001528175111868679\n",
      "train loss:0.00015459250098554545\n",
      "train loss:7.59150842346837e-05\n",
      "train loss:0.00024202640275892043\n",
      "train loss:0.0027852893445448057\n",
      "train loss:0.002127676242851168\n",
      "train loss:0.0025296503134736364\n",
      "train loss:0.0019067038232013006\n",
      "train loss:0.0035128613887474925\n",
      "train loss:0.004949038905440661\n",
      "train loss:0.000708515055201039\n",
      "train loss:0.0011568820693135945\n",
      "train loss:0.0017091983027976584\n",
      "train loss:0.0018415433355530762\n",
      "train loss:0.0024702004269585823\n",
      "train loss:0.002304236975581624\n",
      "train loss:0.0024529115022782614\n",
      "train loss:0.004881819121913327\n",
      "train loss:0.0013752853443298432\n",
      "train loss:0.0019266137440646421\n",
      "train loss:0.005494507332491765\n",
      "train loss:0.004403390861051948\n",
      "train loss:0.011350194546338\n",
      "train loss:0.002069611798652585\n",
      "train loss:0.0005782783994795319\n",
      "train loss:0.0003633600332867004\n",
      "train loss:0.001491391177462952\n",
      "train loss:0.0003474936708999115\n",
      "train loss:0.00025200019912456883\n",
      "train loss:0.0017677990599423796\n",
      "train loss:0.0017761905704999348\n",
      "train loss:0.01332073335842885\n",
      "train loss:0.00023422477554004256\n",
      "train loss:0.002805851774211923\n",
      "train loss:0.0005231001928559278\n",
      "train loss:0.0008928904682222291\n",
      "train loss:0.002851753322958789\n",
      "train loss:0.000462277287371376\n",
      "train loss:0.003526171542671712\n",
      "train loss:0.00012175367990845759\n",
      "train loss:0.0031834906866414544\n",
      "train loss:0.0011188162028636817\n",
      "train loss:0.0022898726556442937\n",
      "train loss:0.002091651422825531\n",
      "train loss:0.001015980964612441\n",
      "train loss:0.003143754843163577\n",
      "train loss:0.0016891805228158138\n",
      "train loss:0.00509140130900689\n",
      "train loss:0.0008777042932849639\n",
      "train loss:0.0022664277532829635\n",
      "train loss:0.0018807512809221522\n",
      "train loss:0.005507544343995323\n",
      "train loss:0.00010938504102672614\n",
      "train loss:8.107668113693666e-05\n",
      "train loss:0.013694128193763035\n",
      "train loss:0.0004896926841942114\n",
      "train loss:0.00021804592105860532\n",
      "train loss:0.004208616298457919\n",
      "train loss:0.003001670507631332\n",
      "train loss:0.0020997375252149444\n",
      "train loss:0.0003928095480315455\n",
      "train loss:0.00015247651312155495\n",
      "train loss:0.000652593239124883\n",
      "train loss:0.0011755214174441113\n",
      "train loss:5.1613191343060254e-05\n",
      "train loss:0.00017934303472743045\n",
      "train loss:0.005561025609695747\n",
      "train loss:0.0012673559111519971\n",
      "train loss:0.001766256388824594\n",
      "train loss:0.02377827632430736\n",
      "train loss:0.00018824902882936292\n",
      "train loss:0.0022092842302004903\n",
      "train loss:0.0005357821291017414\n",
      "train loss:0.0005565323914710684\n",
      "train loss:0.0008761680861273545\n",
      "train loss:0.012380926753676254\n",
      "train loss:0.0007920412702943813\n",
      "train loss:9.276387032519007e-05\n",
      "train loss:0.0015252466464958836\n",
      "train loss:0.0013191171439115767\n",
      "train loss:0.000314228208617389\n",
      "train loss:0.0013191360563740665\n",
      "train loss:0.0003458077140282996\n",
      "train loss:0.0030223707937088854\n",
      "train loss:0.000870206253085065\n",
      "train loss:0.0034530636582368645\n",
      "train loss:0.0003080295716145108\n",
      "train loss:0.019635242189620424\n",
      "train loss:0.0004660465336971695\n",
      "train loss:0.00044895939267665906\n",
      "train loss:0.0006160798761669366\n",
      "train loss:0.0011722843932108248\n",
      "train loss:0.00021051658500670378\n",
      "train loss:0.005932889305730551\n",
      "train loss:0.009052176564064667\n",
      "train loss:0.002302142292629791\n",
      "train loss:0.005596550400216014\n",
      "train loss:0.0005618968326178785\n",
      "train loss:0.001025832698286872\n",
      "train loss:0.0004080827301699855\n",
      "train loss:0.0010057365303358678\n",
      "train loss:0.030554154933323082\n",
      "train loss:0.0022743537833556254\n",
      "train loss:0.0006619744461964697\n",
      "train loss:0.00033248228529008273\n",
      "train loss:0.0008631033380305278\n",
      "train loss:0.0005607080501733465\n",
      "train loss:0.0024594583339104235\n",
      "train loss:0.036989296588798244\n",
      "train loss:0.004404197450778521\n",
      "train loss:0.004641873887794123\n",
      "train loss:0.004106659005911542\n",
      "train loss:0.003033132095981209\n",
      "train loss:0.0003932175097833566\n",
      "train loss:0.007145377963521916\n",
      "train loss:0.0027011594337962162\n",
      "train loss:0.00486834601862823\n",
      "train loss:0.00519158520369073\n",
      "train loss:0.0004936667446292712\n",
      "train loss:0.0020840942044357117\n",
      "train loss:0.0005947847528601236\n",
      "train loss:0.0020467007052228396\n",
      "train loss:0.0006665111439332775\n",
      "train loss:0.054869722162065176\n",
      "train loss:0.00045619076048405874\n",
      "train loss:0.0011075012106846489\n",
      "train loss:0.001324898394055762\n",
      "train loss:0.0003595176705876097\n",
      "train loss:0.003985140904086425\n",
      "train loss:0.00030495451144411966\n",
      "train loss:0.0005638393422821975\n",
      "train loss:0.00023632380685251767\n",
      "train loss:0.00038476680499187734\n",
      "train loss:0.0038074978545191503\n",
      "train loss:0.0008851820761119289\n",
      "train loss:0.021941344784893835\n",
      "train loss:0.004295219139585557\n",
      "train loss:0.002913489926634174\n",
      "train loss:0.0013567091841145634\n",
      "train loss:0.0006502837249397144\n",
      "train loss:0.00196671187502619\n",
      "train loss:0.0050518203822499455\n",
      "train loss:0.000729501522747671\n",
      "train loss:0.00197739615547465\n",
      "train loss:0.005980309941045952\n",
      "train loss:0.0003178376812623484\n",
      "train loss:0.0012345395973784963\n",
      "train loss:0.0011984290860895224\n",
      "train loss:0.0011982454558055644\n",
      "train loss:0.004231238587726946\n",
      "train loss:0.0015570326181509422\n",
      "train loss:0.0008355301734277098\n",
      "train loss:0.0010816588501016428\n",
      "train loss:0.0016844312301233825\n",
      "train loss:0.0019191102759513095\n",
      "train loss:0.00017440616931363887\n",
      "train loss:0.014466228119896098\n",
      "train loss:0.0012620619365114158\n",
      "train loss:0.0001975349773054344\n",
      "train loss:0.00039409387653804547\n",
      "train loss:0.024980166067563335\n",
      "train loss:0.00020711895754791786\n",
      "train loss:0.0026614418173164737\n",
      "train loss:0.008570651805763718\n",
      "train loss:0.002923182257062861\n",
      "train loss:0.00030159933570936005\n",
      "train loss:0.0030362988876001524\n",
      "train loss:0.00017343316234567517\n",
      "train loss:0.007909359640762021\n",
      "train loss:0.0010266709943341896\n",
      "train loss:0.0031393851638234073\n",
      "train loss:0.00711343347217469\n",
      "train loss:0.004601334287298581\n",
      "train loss:0.00026910232900573266\n",
      "train loss:0.0075926837624016984\n",
      "train loss:0.0013190284315235897\n",
      "train loss:0.0008326274414452663\n",
      "train loss:0.010069172032129455\n",
      "train loss:0.0006128018565883964\n",
      "train loss:0.006053790046322777\n",
      "train loss:0.018719298833820733\n",
      "train loss:0.002425973375551204\n",
      "train loss:0.00036197787303350474\n",
      "train loss:0.0021876670687158216\n",
      "train loss:0.00020078544774341278\n",
      "train loss:0.001113792394148784\n",
      "train loss:0.00971241617016364\n",
      "train loss:0.0010289962440750173\n",
      "train loss:0.0008605326079946786\n",
      "train loss:0.007574508015153697\n",
      "train loss:0.003877129712337687\n",
      "train loss:0.001654534335662163\n",
      "train loss:0.0006032587211349827\n",
      "train loss:0.00234057162725792\n",
      "train loss:0.004938532983918225\n",
      "train loss:6.290273177532479e-05\n",
      "train loss:0.0012206474676968316\n",
      "train loss:0.0013912160596744564\n",
      "train loss:0.00041744038033827936\n",
      "train loss:0.026479798327810396\n",
      "train loss:0.0010351231551631729\n",
      "train loss:0.0019273532875171057\n",
      "train loss:0.002627645565765521\n",
      "train loss:0.002275821311505979\n",
      "train loss:0.0016599377391200885\n",
      "train loss:0.0406103455782296\n",
      "train loss:0.0005720924646459743\n",
      "train loss:0.001989578610354928\n",
      "train loss:0.00010885379173089963\n",
      "train loss:0.004904582861223644\n",
      "train loss:0.002338109188973983\n",
      "train loss:0.00349287933228701\n",
      "train loss:0.0016540238415726168\n",
      "train loss:0.006086733327004102\n",
      "train loss:0.003388032227757857\n",
      "train loss:0.0024850168339825137\n",
      "train loss:0.02251252086314333\n",
      "train loss:0.003047911207526952\n",
      "train loss:0.0004958926708297165\n",
      "train loss:0.005712880098106736\n",
      "train loss:0.002597721918217038\n",
      "train loss:0.002360445241694249\n",
      "train loss:0.0009150685218223513\n",
      "train loss:0.003118509285533899\n",
      "train loss:0.0009588456135516616\n",
      "train loss:0.0034709778541118564\n",
      "train loss:0.0031264128477225327\n",
      "train loss:0.0023473321870777623\n",
      "train loss:0.0052364258305936835\n",
      "train loss:0.01638412190521517\n",
      "train loss:0.0024849536448588393\n",
      "train loss:0.0012194589024887156\n",
      "train loss:0.005121094313708421\n",
      "train loss:0.002028737155920711\n",
      "train loss:0.0017846734359085767\n",
      "train loss:0.0018586787250437743\n",
      "train loss:0.003039977085370749\n",
      "train loss:0.0014964061855069451\n",
      "train loss:0.0017628605934892985\n",
      "train loss:0.0015491176801176304\n",
      "train loss:0.004848856051343283\n",
      "train loss:0.002449095788077155\n",
      "train loss:0.002855344299346616\n",
      "train loss:0.015008676059605278\n",
      "train loss:0.015766997116356523\n",
      "train loss:0.0006831567289496136\n",
      "train loss:0.0021514114175908154\n",
      "train loss:0.00032784511862323873\n",
      "train loss:0.0018371765610774077\n",
      "train loss:0.0005156229281258308\n",
      "train loss:0.013121608520029011\n",
      "train loss:0.0014069366270253313\n",
      "train loss:0.005055679975026817\n",
      "train loss:0.00032516109214963897\n",
      "train loss:0.007527056553638967\n",
      "train loss:0.0004628251585587357\n",
      "train loss:0.0069689506064471\n",
      "train loss:0.0009351312677150478\n",
      "train loss:0.0004357408028528621\n",
      "train loss:0.002800078944127613\n",
      "train loss:0.0005843173181606932\n",
      "train loss:0.004161096588255367\n",
      "train loss:0.005916882781181345\n",
      "train loss:0.0010552441563693494\n",
      "train loss:0.0018769331211871592\n",
      "train loss:0.001400124261793978\n",
      "train loss:0.0011585039546919832\n",
      "train loss:8.584342505280252e-05\n",
      "train loss:0.010060210347155173\n",
      "train loss:0.014323386430856311\n",
      "train loss:0.001100481825516911\n",
      "train loss:0.0005791736412128539\n",
      "train loss:0.0008732782026700122\n",
      "train loss:0.002399697165613007\n",
      "train loss:0.005538018312151164\n",
      "train loss:0.0018679886167769241\n",
      "train loss:0.002640674154139377\n",
      "train loss:0.0033761594576526303\n",
      "train loss:0.01133406536913755\n",
      "train loss:0.002991598355894517\n",
      "train loss:0.009415848218409514\n",
      "train loss:0.00029037695684999915\n",
      "train loss:0.00955769515933641\n",
      "train loss:0.00645290447085631\n",
      "train loss:0.04565289590774534\n",
      "train loss:0.00034010459834138684\n",
      "train loss:0.0010245538123721083\n",
      "train loss:0.004515704074989057\n",
      "train loss:0.014965621489904877\n",
      "train loss:0.006691890459918775\n",
      "train loss:0.002296567112047403\n",
      "train loss:0.0023939654232657762\n",
      "train loss:0.008876109555675056\n",
      "train loss:0.0017739041927606885\n",
      "train loss:0.0010159444455725775\n",
      "train loss:0.03915528966451484\n",
      "train loss:0.003444892891601038\n",
      "train loss:0.0008496645122702871\n",
      "train loss:0.0027184998556439533\n",
      "train loss:0.006275360936404863\n",
      "train loss:0.0007076040775023388\n",
      "train loss:0.07143814975661876\n",
      "train loss:0.0016364375603403112\n",
      "train loss:0.0033023739785808057\n",
      "train loss:0.017265335704826305\n",
      "train loss:0.004091919490609568\n",
      "train loss:0.00038171154366514905\n",
      "train loss:0.02900848739146962\n",
      "train loss:0.005855126618147971\n",
      "train loss:0.0005152527300902402\n",
      "train loss:0.0028348852993674767\n",
      "train loss:0.010996607472746252\n",
      "train loss:0.00042160191049755714\n",
      "train loss:0.00032198521366491676\n",
      "train loss:0.002105243633098658\n",
      "train loss:0.001073865123197854\n",
      "train loss:0.0004040575633051549\n",
      "train loss:0.0008724824104308885\n",
      "train loss:0.0010454298714135972\n",
      "train loss:0.0035445862734203143\n",
      "train loss:0.002909884184970728\n",
      "train loss:0.0004108789043060293\n",
      "train loss:0.0012773273945246649\n",
      "train loss:0.0007502573754413241\n",
      "train loss:0.006536707396299993\n",
      "train loss:0.00634052475327199\n",
      "train loss:0.05861804525020998\n",
      "train loss:0.0044598757965855105\n",
      "train loss:0.0010443392571212315\n",
      "train loss:0.00043520316317822836\n",
      "train loss:0.004382652799598159\n",
      "train loss:0.007552739500196014\n",
      "train loss:0.01092572519854764\n",
      "train loss:0.0017089578071882606\n",
      "train loss:0.0006117058126295358\n",
      "train loss:0.0014411774862867753\n",
      "train loss:0.0018929060346602267\n",
      "train loss:0.01505152456529127\n",
      "train loss:0.010024123488812669\n",
      "train loss:0.0011081409801996494\n",
      "train loss:0.0017038676416120566\n",
      "train loss:0.002313900737842911\n",
      "train loss:0.00043597628372651085\n",
      "train loss:0.0025396171359651004\n",
      "train loss:0.005941526015552256\n",
      "train loss:0.002568917603553523\n",
      "train loss:0.009440991772648793\n",
      "train loss:0.00015260545968931935\n",
      "train loss:0.015596051877455821\n",
      "=== epoch:17, train acc:0.999, test acc:0.984 ===\n",
      "train loss:0.00029526139566042885\n",
      "train loss:0.0037829035873475246\n",
      "train loss:0.0010912927147107504\n",
      "train loss:0.0015434891411293928\n",
      "train loss:0.001564352061044236\n",
      "train loss:0.0015210097236821474\n",
      "train loss:0.007692151115368494\n",
      "train loss:0.0034562225802192022\n",
      "train loss:0.012977286598928644\n",
      "train loss:0.004848732330957693\n",
      "train loss:0.0012638365131766739\n",
      "train loss:0.007660471233863311\n",
      "train loss:0.0011718174861874847\n",
      "train loss:0.00034203214047849877\n",
      "train loss:0.0018984683071171559\n",
      "train loss:0.016208290416241045\n",
      "train loss:0.0026969738536030737\n",
      "train loss:0.00418586600060698\n",
      "train loss:0.0073782231396463515\n",
      "train loss:0.004247770565449862\n",
      "train loss:0.002926788039042402\n",
      "train loss:0.002073213799028301\n",
      "train loss:0.0029463716059667825\n",
      "train loss:0.0006255501236378828\n",
      "train loss:0.0005436583586486726\n",
      "train loss:0.0004342538899928526\n",
      "train loss:0.00013924342907645077\n",
      "train loss:0.00048262314998675284\n",
      "train loss:0.018500204639308175\n",
      "train loss:0.0011787144192810894\n",
      "train loss:0.004902718737903527\n",
      "train loss:0.0018358006513791133\n",
      "train loss:0.0025017114676180057\n",
      "train loss:0.0010768432906517217\n",
      "train loss:0.0024725877988859657\n",
      "train loss:0.0019834608011367622\n",
      "train loss:0.0009248035170879195\n",
      "train loss:0.0015673400842132056\n",
      "train loss:0.007193887952812511\n",
      "train loss:0.0006381342997027513\n",
      "train loss:0.0006465836122108585\n",
      "train loss:0.001432863629501076\n",
      "train loss:0.022452961567526578\n",
      "train loss:0.0031825748060608917\n",
      "train loss:0.0038032051464151405\n",
      "train loss:0.004070051422335467\n",
      "train loss:0.0021051720145750436\n",
      "train loss:0.004176431065834678\n",
      "train loss:0.0008625480606817228\n",
      "train loss:0.0037819075901983894\n",
      "train loss:0.006583261012671497\n",
      "train loss:0.005253695488597842\n",
      "train loss:0.0002754927909838145\n",
      "train loss:0.0003488653639854212\n",
      "train loss:0.00015415929750706018\n",
      "train loss:0.0004986227323063988\n",
      "train loss:1.9254565513798827e-05\n",
      "train loss:0.0023036332649070427\n",
      "train loss:0.0016086806515581307\n",
      "train loss:0.0021944384204633707\n",
      "train loss:0.001083985295483384\n",
      "train loss:0.02468375607854716\n",
      "train loss:0.0006704542275880055\n",
      "train loss:0.0006580565654583148\n",
      "train loss:0.001345349544177335\n",
      "train loss:0.00028313760321036716\n",
      "train loss:0.00016268106085985185\n",
      "train loss:0.003054911955456133\n",
      "train loss:0.0016406421098493834\n",
      "train loss:0.003199409969497933\n",
      "train loss:0.0010894637042142585\n",
      "train loss:0.003303178063191615\n",
      "train loss:0.0018326389865001482\n",
      "train loss:0.003700691125744247\n",
      "train loss:0.0032716914415891695\n",
      "train loss:0.005441842169962229\n",
      "train loss:0.003412535611868025\n",
      "train loss:0.001028603496581165\n",
      "train loss:0.0016179739653707187\n",
      "train loss:0.005566239054990641\n",
      "train loss:0.00010287520765807847\n",
      "train loss:0.002135256311798592\n",
      "train loss:0.007758576339359042\n",
      "train loss:0.002075095176040082\n",
      "train loss:0.0007234170718964403\n",
      "train loss:0.012114613347975065\n",
      "train loss:0.00024549646362740827\n",
      "train loss:0.0004842216986163369\n",
      "train loss:0.034098660001322154\n",
      "train loss:0.0023820635786236362\n",
      "train loss:0.0015346669182912465\n",
      "train loss:0.002194459953151912\n",
      "train loss:0.003782687210049795\n",
      "train loss:0.002044771467511947\n",
      "train loss:0.003559899656509832\n",
      "train loss:0.007333092772111155\n",
      "train loss:0.006302266591526815\n",
      "train loss:0.0022046234923107063\n",
      "train loss:0.0005837647290859785\n",
      "train loss:0.00044860952095031055\n",
      "train loss:0.00020386909037023993\n",
      "train loss:0.0005072886405351251\n",
      "train loss:0.01095948845280792\n",
      "train loss:0.0024361472177502966\n",
      "train loss:0.0003257198835175584\n",
      "train loss:0.0002861843188590452\n",
      "train loss:0.000307832466245876\n",
      "train loss:0.0011866694482382863\n",
      "train loss:0.0005546306123424412\n",
      "train loss:0.003891503135416208\n",
      "train loss:0.0006219195050778544\n",
      "train loss:0.0012295007348189155\n",
      "train loss:0.0025617905254651085\n",
      "train loss:0.00410104767616704\n",
      "train loss:0.001041310445318539\n",
      "train loss:0.003774833331209854\n",
      "train loss:0.0011209208551516273\n",
      "train loss:0.0011851545632973468\n",
      "train loss:0.004461946983617029\n",
      "train loss:0.0027827039086160744\n",
      "train loss:0.0004189768580525293\n",
      "train loss:0.0001802603525809226\n",
      "train loss:0.0020990941092139943\n",
      "train loss:0.002519579556138383\n",
      "train loss:0.004083734117279314\n",
      "train loss:0.0032128090051329276\n",
      "train loss:0.0025837272985558095\n",
      "train loss:0.0064532027362311905\n",
      "train loss:0.0036009387495944995\n",
      "train loss:0.0011618674531396667\n",
      "train loss:0.00011076681359673362\n",
      "train loss:0.0007271430351768767\n",
      "train loss:0.00536894911492234\n",
      "train loss:0.004887857250377089\n",
      "train loss:0.0006538631570264603\n",
      "train loss:0.00022680206127049612\n",
      "train loss:0.006903259286596797\n",
      "train loss:0.001092342332062564\n",
      "train loss:3.0131534241627452e-05\n",
      "train loss:0.0006840861910807039\n",
      "train loss:0.006681600235370283\n",
      "train loss:0.00024472281601259366\n",
      "train loss:0.001144058655207196\n",
      "train loss:0.0008483512631155846\n",
      "train loss:0.0001385419550012371\n",
      "train loss:0.0018139032064045499\n",
      "train loss:0.0015282615040873514\n",
      "train loss:0.0003919908711097633\n",
      "train loss:0.0001233045104754821\n",
      "train loss:0.0020857748570329757\n",
      "train loss:9.709231982093667e-05\n",
      "train loss:0.009933820461474407\n",
      "train loss:0.0007204757325329236\n",
      "train loss:0.0012098231185015509\n",
      "train loss:0.002194900672582361\n",
      "train loss:0.0021906564793522302\n",
      "train loss:0.0006583373340024178\n",
      "train loss:0.0004015361047059956\n",
      "train loss:0.0033845704924473623\n",
      "train loss:0.001227306743242668\n",
      "train loss:0.0005440284646209492\n",
      "train loss:0.003228513756535523\n",
      "train loss:0.005633764421925874\n",
      "train loss:0.0011538337981128375\n",
      "train loss:0.002648256649631061\n",
      "train loss:0.001048763795657907\n",
      "train loss:0.0022195819436020585\n",
      "train loss:0.0008885502946229743\n",
      "train loss:0.0034970337152860696\n",
      "train loss:0.005612307037220592\n",
      "train loss:0.00025118745271816915\n",
      "train loss:0.00016045599007760884\n",
      "train loss:0.0003137419819824724\n",
      "train loss:0.0019968863847706934\n",
      "train loss:0.0004786724682901575\n",
      "train loss:0.0005990469600160429\n",
      "train loss:0.0019540030227725063\n",
      "train loss:0.0016510801103510578\n",
      "train loss:0.000474219769615247\n",
      "train loss:9.231819731790304e-05\n",
      "train loss:0.0005383479684662417\n",
      "train loss:0.0013497147742358006\n",
      "train loss:0.002133677618018112\n",
      "train loss:0.010045001594731016\n",
      "train loss:0.00035828206777056387\n",
      "train loss:5.0106767424871756e-05\n",
      "train loss:0.0006741692776981752\n",
      "train loss:0.00023926111576754526\n",
      "train loss:0.0003833558863594392\n",
      "train loss:0.00019124759259529168\n",
      "train loss:0.004408402486658826\n",
      "train loss:0.002011908622630361\n",
      "train loss:0.001389712064253469\n",
      "train loss:0.0021344119361608274\n",
      "train loss:0.0002867667547746976\n",
      "train loss:0.005062215906893422\n",
      "train loss:0.0007511877705522631\n",
      "train loss:0.0009806168698623665\n",
      "train loss:0.005268594679610142\n",
      "train loss:0.00034931580779047557\n",
      "train loss:8.500786784955109e-05\n",
      "train loss:0.004567718412850273\n",
      "train loss:0.0010981982961529519\n",
      "train loss:0.0003012949606942704\n",
      "train loss:0.0033698854178718803\n",
      "train loss:0.005102415604795237\n",
      "train loss:0.003706317841494067\n",
      "train loss:0.0009402044375640754\n",
      "train loss:7.371467070786794e-05\n",
      "train loss:0.0002094549286239351\n",
      "train loss:0.001233147693110201\n",
      "train loss:0.003774021928678808\n",
      "train loss:0.0013483919890165399\n",
      "train loss:0.0011524858225608042\n",
      "train loss:0.006774382788607199\n",
      "train loss:0.00022637123768810504\n",
      "train loss:0.0003798701278837364\n",
      "train loss:0.00011638513310604682\n",
      "train loss:0.0005383862681417669\n",
      "train loss:0.0007664636616148606\n",
      "train loss:0.0008478502042539056\n",
      "train loss:0.00020945480367863873\n",
      "train loss:0.004153257587774635\n",
      "train loss:0.0061182755281917085\n",
      "train loss:0.0027256919256334537\n",
      "train loss:0.002633195861003932\n",
      "train loss:0.001427213697254393\n",
      "train loss:0.006260582973218256\n",
      "train loss:0.0014747820783457257\n",
      "train loss:0.0021235442638214822\n",
      "train loss:0.00015949403576326064\n",
      "train loss:0.001959992583722822\n",
      "train loss:0.004734891650330027\n",
      "train loss:3.9958606020560285e-05\n",
      "train loss:0.0003221379503332356\n",
      "train loss:0.001029098607653544\n",
      "train loss:0.000927017069749057\n",
      "train loss:0.0003649389696268964\n",
      "train loss:0.0005423898853341084\n",
      "train loss:0.00631700770181087\n",
      "train loss:0.0005191885276495248\n",
      "train loss:0.011858118966260454\n",
      "train loss:0.0024721409106149036\n",
      "train loss:0.004269551402144139\n",
      "train loss:0.0007322977448105918\n",
      "train loss:0.004583776243179938\n",
      "train loss:0.0020991972160302142\n",
      "train loss:0.00230555544362336\n",
      "train loss:0.0010474898916914893\n",
      "train loss:0.0011837956774100136\n",
      "train loss:0.00018797064802878263\n",
      "train loss:0.0019367458497545047\n",
      "train loss:0.002479215631085032\n",
      "train loss:0.0015897630223771033\n",
      "train loss:0.001841629258313964\n",
      "train loss:0.0077565080987867015\n",
      "train loss:0.0008387966086122827\n",
      "train loss:0.0012168539589616284\n",
      "train loss:0.0016638052020405975\n",
      "train loss:0.0016388697409422765\n",
      "train loss:0.0034437459921866603\n",
      "train loss:0.0023465886957792187\n",
      "train loss:0.001330657858398153\n",
      "train loss:0.007626022769492706\n",
      "train loss:0.008761576051527432\n",
      "train loss:0.0017488545172557072\n",
      "train loss:0.002415432733898628\n",
      "train loss:8.766702296185763e-05\n",
      "train loss:0.00019025113725417084\n",
      "train loss:0.0007978135390273607\n",
      "train loss:0.001686679050477568\n",
      "train loss:0.003276469096917557\n",
      "train loss:0.00492504665016214\n",
      "train loss:0.0005245614717800927\n",
      "train loss:0.00010390803529749774\n",
      "train loss:0.0018000334294868416\n",
      "train loss:0.001916789704252333\n",
      "train loss:0.009522835018245156\n",
      "train loss:0.0005230925200474348\n",
      "train loss:0.0001007423277693305\n",
      "train loss:0.0006720878738724005\n",
      "train loss:0.00021028420712717805\n",
      "train loss:0.000837435081147554\n",
      "train loss:0.0011704202054349832\n",
      "train loss:0.000517878404521243\n",
      "train loss:0.001982503868308871\n",
      "train loss:0.0034381641163072013\n",
      "train loss:0.0020318060751946523\n",
      "train loss:0.004066292562116322\n",
      "train loss:0.0024606655127461493\n",
      "train loss:0.0042279069729814905\n",
      "train loss:0.0006281105773312946\n",
      "train loss:0.0007874451297172606\n",
      "train loss:0.003261242841549689\n",
      "train loss:0.007603237206312159\n",
      "train loss:0.0008239967242290912\n",
      "train loss:0.0016307201051158128\n",
      "train loss:0.0011273365015929465\n",
      "train loss:0.005549713191935732\n",
      "train loss:0.0022967234221557818\n",
      "train loss:0.0031338727077246335\n",
      "train loss:0.003106725004044615\n",
      "train loss:0.003387151851911996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 40\u001b[0m\n\u001b[1;32m     20\u001b[0m network \u001b[38;5;241m=\u001b[39m SimpleConvNet(\n\u001b[1;32m     21\u001b[0m     input_dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m),\n\u001b[1;32m     22\u001b[0m     conv_param\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_num\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m30\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstride\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     weight_init_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     29\u001b[0m     network,\n\u001b[1;32m     30\u001b[0m     x_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     evaluate_sample_num_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[1;32m     39\u001b[0m )\n\u001b[0;32m---> 40\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# パラメータの保存\u001b[39;00m\n\u001b[1;32m     43\u001b[0m network\u001b[38;5;241m.\u001b[39msave_params(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/deep-learning-from-scratch/common/trainer.py:71\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step()\n\u001b[1;32m     73\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39maccuracy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_test)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[0;32m~/Documents/Projects/deep-learning-from-scratch/common/trainer.py:44\u001b[0m, in \u001b[0;36mTrainer.train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train[batch_mask]\n\u001b[1;32m     42\u001b[0m t_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_train[batch_mask]\n\u001b[0;32m---> 44\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mgradient(x_batch, t_batch)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparams, grads)\n\u001b[1;32m     47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mloss(x_batch, t_batch)\n",
      "File \u001b[0;32m~/Documents/Projects/deep-learning-from-scratch/common/simple_convnet.py:156\u001b[0m, in \u001b[0;36mSimpleConvNet.gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m    154\u001b[0m layers\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[0;32m--> 156\u001b[0m     dout \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mbackward(dout)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# 設定\u001b[39;00m\n\u001b[1;32m    159\u001b[0m grads \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/Projects/deep-learning-from-scratch/common/layers.py:237\u001b[0m, in \u001b[0;36mConvolution.backward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    234\u001b[0m dout \u001b[38;5;241m=\u001b[39m dout\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, FN)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dout, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol\u001b[38;5;241m.\u001b[39mT, dout)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdW\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(FN, C, FH, FW)\n\u001b[1;32m    240\u001b[0m dcol \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(dout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_W\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# データの読み込み\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 処理に時間のかかる場合はデータを削減\n",
    "# x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "# x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(\n",
    "    input_dim=(1, 28, 28),\n",
    "    conv_param={\"filter_num\": 30, \"filter_size\": 5, \"pad\": 0, \"stride\": 1},\n",
    "    hidden_size=100,\n",
    "    output_size=10,\n",
    "    weight_init_std=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    network,\n",
    "    x_train,\n",
    "    t_train,\n",
    "    x_test,\n",
    "    t_test,\n",
    "    epochs=max_epochs,\n",
    "    mini_batch_size=100,\n",
    "    optimizer=\"Adam\",\n",
    "    optimizer_param={\"lr\": 0.001},\n",
    "    evaluate_sample_num_per_epoch=1000,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# パラメータの保存\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# グラフの描画\n",
    "markers = {\"train\": \"o\", \"test\": \"s\"}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker=\"o\", label=\"train\", markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker=\"s\", label=\"test\", markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'tuple'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'tuple'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
